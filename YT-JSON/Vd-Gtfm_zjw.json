{
    "Vd-Gtfm_zjw": {
        "title": "Agency Swarm Now Supports Open Source Models",
        "thumbnail": "https://i.ytimg.com/vi/Vd-Gtfm_zjw/hqdefault.jpg",
        "author": "VRSEN",
        "date_of_release": "2024-05-08T14:00:32Z",
        "duration": "PT19M19S",
        "view_count": "12570",
        "like_count": "501",
        "comment_count": "72",
        "description": "Yes, that's right! Agency Swarm now supports open-source models üöÄ This must-watch video! ü§ñüí°\n\nüß™Agency Swarm Lab (Repo from the video):\nhttps://github.com/VRSEN/agency-swarm-lab\n\nü§ñ¬†AI Agents for Your Business:\nhttps://agents.vrsen.ai/\n\nüîã OAI-Widget (My SaaS)üëá\nhttps://www.oai-widget.com/\n\nüöÄ Custom AI Solutions:\nhttps://www.vrsen.ai/\n\nü§ù Consulting/coaching:\nhttps://calendly.com/vrsen/ai-project-consultation\n\nüí¨ Discord:\nhttps://discord.gg/hAhCNBGN45\n\n0:00 - Intro\n0:56 - Assistants V2 Updates\n08:15 - Open Source Setup\n15:36 - Testing \n\nAbout: Discover how Agency Swarm now supports open source models! Explore the latest updates in Assistance API v2, including enhanced retrieval tools and control over token usage. Learn how to seamlessly integrate open source models into your projects with step-by-step guidance. Watch now for a game-changing approach to AI implementation!",
        "transcript": "disadvantage of my framework is that it's fully based on open AI assistance API and to answer your question right now no we're not going to support any open source models right so agency swarm does support open source models now I still recommend you guys go with open AI whenever you can but you know if you want to use anthropic Google Gemini Mixr or even llama 3 Model running locally with AMA you now have the flexibility to do so and I was actually really surprised how simple it is to set up but the best part is that you can even combine different agents with different llms like for example in this video we're going to create a manager agent that uses anthropic and controls two other Google Gemini and llama 3 agents let's dive in okay before we dive into the details on how to use my framework with with open source models we definitely have to talk about assistance API V2 it released a ton of new features that all significantly improve how your agents perform in production applications so let me go through all of them one at a time and explain how you can already use them within my framework okay first of all the retrieval tool was replaced with file search that's actually huge because before as I said in my previous video the retrieval tool in open a assistance CPI is is currently now you get essentially like Enterprise level rack out of the box this has been a game changer for almost all of my clients because now you don't have to set up any data processing yourself you don't have to connect to third party Vector databases all you have to do is just attach files to your assistant and then openi will do all the processing all the chunking for you and upload that data into your own Vector store so some of the techniques that they're currently using include like cury rewriting breaking down complex queres into multiple searches that can be run in parallel using both keyword and semantic searches and additionally reranking the results so as I said this is all of the techniques that we use in production level rag applications like straight out out of the box without you having to worry about any of the details okay next huge update is that now you can finally control the maximum number of tokens that assistant uses in a specific run so what does this mean well before you know you couldn't really control how many tokens were in The Prompt when you were using a assistance API now basically what you can do is simply add Max prompt tokens parameters inside my framework so then you can set it to for example 248 although openi does recommend setting it to more than 20,000 if you're using any file searches additionally there is now a new parameter called tration strategy which allows you to select how you want those prompt tokens to be truncated so if you set it to Auto open AI says that they're using their own algorithm and from what I've observed it seems like they're keeping like the first few messages and then they're also keeping the end of the conversation but they're removing the middle of the discussion so this allows you apparently to achieve slightly better results because the first few messages typically play a crucial role in how the conversation will unfold so I do recommend you keep it at Auto because openi probably knows what they're doing but you can also set it to last messages if you want so if you make tration strategy and object and then inside you specify type to last messages you can then select how many messages will be kept in the conversation history this means that only the five last messages will be used in order to generate a response by the assistant Additionally you can of course also select the max completion tokens which will limit the number of tokens that your assistant can generate at once as you can see all of those parameters are actually under the Run endpoint not under the assistant endpoint however in my framework you can specify them directly within each assistant in my opinion it's more convenient this way because typically those parameters don't alternate between different messages as much moreover you can set all of those parameters even within the agency class so now as you can see in the latest version of my framework you can also specify the max promt tokens within the agency directly and this parameter will act sort of as a default for all your agents so for example if I set the max promt tokens parameter inside the agency class to 248 all of the agents will use 248 tokens in the conversation by default however if I set this parameter to 4,000 within the planner agent the planner agent will actually use 4,000 tokens the same principle still applies to all the other new parameters like truncation strategy and temperature by the way temperature is probably one of the most useful updates from the whole assistance V2 API release because it seems like openi actually used one for temperature by default in assistance API V1 which is in my opinion a bit too much you see in production applications especially in agentic applications we almost never set temperature to one because in my opinion creativity is a lot less important than hallucinations so if you reduce the temperature to something like zero or3 you're going to reduce the hallucinations but at the same time obviously your outputs wouldn't be as diverse in my framework currently the default is set to3 however for any coding use cases I do recommend that you set it to zero okay next we got tool Choice meaning that you can finally select which tool the assistant will use this is primarily going to be most useful for backend Integrations where you are using the get completion method so now after you specify the message you can also specify the tool Choice within this method then you can select it as Auto required or you can say set type to function and then specify the function choice so in this example as you can see I'm forcing the agent to use the send message tool which means that this agent will be required to talk to another agent when I say hi next we finally get a way to add assistant messages to threats which means that now we can finally do few short learning so let me show you how this works you can find this under Advanced usage agents section in the commun ation for agency swarm where I've added a section on how to use few short examples with my framework so essentially you just have to create an array of messages that you want your agent to remember then you can pass these examples inside the example parameter for your agent where this can be mostly useful is if for example you want to create emails or any other text in your own style of writing so then you can say for example please create an email for me that answers the following question and as the assistant response you can simply include the email yourself that you have written before this way the model will remember your style of writing and will try to replicate it in future messages however keep in mind that if the tration strategy for your agent is set to last messages and the number of last messages exceeds the number of messages in the conversation it means that your examples might not be included next we have Json mode which means that you can force your assistant to always response in Json object format if you specify type to Json object however keep in mind that you must also include in the instructions that the agent must respond using Json otherwise this parameter will not work and last but not least you can now use fine tuned models directly within each assistant you can check any fine tune models that you've created by going to the playground here under the model parameter you will see all the fine tune models you can simply then copy this model name and paste it inside the model parameter for your agent then the agent will use this fune model that's it guys for all the new assistants V2 updates keep in mind that all of them are using the exact same format in my framework as in the official open a API now finally let me show you how to use my framework with open source models or with any models as a matter of fact okay so the first step is to install my agency swarm lab repository where by the time you watch this video you'll find a new open source swarm which you can use as a starting point for your project just make sure to follow all of the steps from the readme first you need to clone this reer then install the main requirements from the main requirements.txt file in the root folder and then you're basically ready to go so after that let's navigate into the open source form repository and here you need to install additional requirements file so this requirements file actually uses agency form 017 version because currently the repository that we're going to be using to emulate assistant API is not very stable with streaming I'm hoping that it's going to change soon but for now we're going to have to use one of the previous versions agency swarm which means that also most of the assistant V2 features are currently not available once they become available I'll of course update this reposit area and send a notification in our Discord so simply run peep install dasr requirements.txt from the op Source swarm directory after the installation is completed you will find another light llm config do yaml file in this file we will set all the API keys and models that we will use with light llm so light llm is essentially a library that allows you to create an openi proxy server that you can use with any open source or commercial models so in this example I'm going to be using anthropic Gemini mistal provided by together AI Gro and of course AMA running Lo Al with llama 3 so you can copy this file and simply set all the API keys for any providers that you want to use for all Lama you obviously don't have to set any API keys so you can put 1 2 3 4 or anything else awesome so because we want to run the latest llama 3 Model locally will'll also have to install AMA the installation process is actually really simple all you have to do is just download the file and then just follow all the installation steps after the installation process is completed all you have to do is simply run or Lama run llama 3 command then you will see a chat interface like this and you can simply say hi as you can see we get this nice response and we can also for example ask what llm are you awesome so as you can see it indeed says that this is llama developed by meta AI which means that we can proceed to The Next Step so the next step is to actually run our light llm proxy server which you can do with the following command light llm config and then you insert the name of your config yaml file this will activate at our proxy server on Local Host Port 4000 with all of the models that you specified in your llama config file awesome so the next step is to pull the open Assistant API repository this is the repository that will essentially mimic the assistant's API back end on our local machine it supports almost all of the features that open AI assistance API supports natively and even provides some additional features like for example you can already use web browsing if you provide your subscription key however as I said some features are still a bit unstable for example I found a bug that prevents using this back end with custom tools so I already fixed this back and created my own Fork which hopefully is going to be merged shortly for now however all you need to do is simply pull my Fork instead of the main Reaper and then we can proceed with running this back end you will find all of those detailed instructions inside the open source form directory in agency SW lab to pull my Fork you can simply use the following git clone command after after it has been copied locally you will see this folder here on the left now the next step is to replace our URLs inside the docker compost file scroll down a bit until you see the open AI base parameter under the llm config here you need to insert the following URL HTTP host. doer. internal Port 4000 V1 we're going to be using a special host. doer. internal URL because it Maps the address from within the docker container to our Local Host URL on our host machine for the API key you can simply set anything like 1 2 3 4 because we're using light llm okay next let's navigate into this open assistants API repository and then all you have to do is simply run Docker compose app- D command this will build your container and start it as a background process it will take some time to build the first time you run it but then the opening assist API will always be running on your local machine in the background which is extremely convenient if you don't have Docker installed the installation is very simple I've already shown this in one my previous videos simply follow the link from the readme in open source swarm directory and then install it for whichever OS you use Okay cool so now that our assistant API backend is running it's time to set up our agents again navigate into the open source swarm directory and then I'm going to use the agency swarm create agent template command I'm going to start with the basic CEO agent then I'm going to create a llama agent and finally I want to create another Google Gemini agent cool so after our agent template folders have been created you can open them on the left so let's start with the CEO agent for the CEO I want to use the latest cloth model by anthropic so all you have to do is simply copy the model name that you previously set in your light LM config for the Llama agent obviously I'm going to be using AMA llama 3 model and for the Google Gemini agent I'm going to be using the Gemini Pro 1.5 latest cool so that's literally almost it that's all it takes to run my framework now with open source models and the final step is to Simply set up the agency dopy file so let's add all our agent inputs just like this then we have to initialize the opene client with a few different parameters so first we're going to be setting the base URL to the URL of our open Assistant server the API key you can literally set to anything and for the default headers we're going to be using assistance V1 API then you just have to set open client that you've initialized before using the set open client method from agency form now we are ready to initialize our agents and create our agency structure so let's initialize all the agents as variables and then simply set the agency with whatever structure you want to use so here I'm going to have a COO agent that can communicate to both llama agent and the Google gini agent awesome the final step is to Simply run the demo gradio method however here when we're not going to be using the default demo gradio method from the agency class instead we're going to use the demo gradio method that you will find inside the open source swarm directory here on the left so this demo gradio method is essentially just a previous version which does not utilize streaming by default and instead simply prints out the messages one by one again as I said this is because the current open assistance API is not as stable with streaming however I'm hoping that this is going to be fixed shortly also so now we should be ready to run this agency again navigate into the open source form folder and then simply run python agency. Pi cool so as you can see now we get the same gradio interface and now let's ask the C agent who is here as you can see it says that it's indeed an artificial intelligence developed by anthropic and the purpose of this agent is to be a helpful digital assistant it also includes thought here at the top which aren't filtered by my gradio interface but probably should be that's interesting actually I was quite surprised on how anthropic added like the special thinking prompts inside the model responses so as you can see here anthropic can actually print like a special tag and then think before answering the question so this is not filtered by the demog gradio interface which is why it might look like it's not even speaking to you on the first sentence and then it provides the response for the question that you asked before now let's tell it to ask the same question from the Llama agent as you can see it now sends the message to the Llama agent using the send message tool as you can see the Llama agent then answers the question and also includes some background capabilities and the purpose cool Theo then relays all of this information to me but again as I said it shows some of the thoughts in the beginning and then it also has like this special function output sorry search quality score parameter which is interesting because it seems like anthropic actually rates its own function calls so probably by the time you watch this video I'll actually add some filtering for that or formatting in the demog gradio interface another important thing that you do have to keep in mind is that not all of the open source or commercial models currently support function calling so for example Lama 3 by o Lama obviously does not support any function calls which means that you can only use this agent as the very end in your agency chart because if you add it anywhere in front of your agency chart and allow it to communicate with other agents it's not going to be able to do this because as you might know in my framework all the communication is handled through a special send message tool okay finally let's as Theo as the Google Gemini agent awesome as you can see it now sends message to Google Gemini agent with all the arguments correctly defined which is great I mean yeah it's anthropic seems to be actually pretty good with function calls which is why I decided to use it as the COO agent Google Gemini then says that it's a large language model created by Google and also provide some of the capabilities so yeah that's basically it guys this is how you use my framework with any open source or commercial models it's the process is actually quite simple but as I said please do keep in mind that function col is not supported by every single model and in any agentic system in my opinion function calling is obviously the most important feature so to check Which models support function calling and which don't in light LM I actually created another function calling support. Pi file where you can insert your model name and then check if the value is true or false so all you have to do is simply run this file and this will allow you to check whether this is correct or not I've also tested this with Gro and many other providers like together Ai and it seems to be working just fine as I said the read me with all of the previous setup instructions will be available inside the open source swarm directory in my agency swarm lab repository I know it was one of the most requested features on our Discord so I'm super excited to see what all you guys create thank you for watching and don't forget to subscribe"
    }
}