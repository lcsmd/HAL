{
    "8R7QOJgGyIQ": {
        "title": "Let's Build: Automate ANYTHING With AI Agent Teams (Step-by-Step)",
        "thumbnail": "https://i.ytimg.com/vi/8R7QOJgGyIQ/hqdefault.jpg",
        "author": "Matthew Berman",
        "date_of_release": "2024-02-24T16:34:59Z",
        "duration": "PT55M30S",
        "view_count": "111152",
        "like_count": "2886",
        "comment_count": "296",
        "description": "Let's build an AI agent team using CrewAI for multiple real-world use cases. In part 1, we'll set up the framework for taking in a list of URLs, having our agents scrape the websites for content, and then summarizing that content. This is something I need for my newsletter. In part 2, we'll expand on that use case to make our code more robust and production-ready.\n\nEnjoy :)\n\nCode: https://github.com/mberman84/crewai_yt\n\nCloud IDE, Fine-tuning, Inference, Data Management and more!\nTry Lightning AI Studio FREE Today: https://bit.ly/3uBiWO9\n\nJoin My Newsletter for Regular AI Updates üëáüèº\nhttps://www.matthewberman.com/\n\nNeed AI Consulting? ‚úÖ \nhttps://forwardfuture.ai/\n\nRent a GPU (MassedCompute) üöÄ\nhttps://bit.ly/matthew-berman-youtube \nUSE CODE \"MatthewBerman\" for 50% discount\n\nMy Links üîó\nüëâüèª Subscribe: https://www.youtube.com/@matthew_berman\nüëâüèª Twitter:  https://twitter.com/matthewberman\nüëâüèª Discord: https://discord.gg/xxysSXBxFW\nüëâüèª Patreon: https://patreon.com/MatthewBerman\n\nMedia/Sponsorship Inquiries üìà\nhttps://bit.ly/44TC45V\n\nDisclosures\nI'm an investor in CrewAI",
        "transcript": "let's build something with crew AI I'm going to set up teams and we're going to accomplish tasks together and this is going to be a slower paced video because I'm just going to build it all with you live and we're going to be especially focusing on tools because I really want to extract the most amount of value from allowing agents to use tools and I'm going to show you how to access the edge version of crew aai which has a bunch of native tools installed in addition to Lang chain which we can use and then custom tools which we can build ourselves so I'm going to show you how to do that also and we're going to be using lightning. a as the IDE in the cloud so everything I'm going to do is going to be coded in the cloud and then I'm going to share the code with you at the end of the video and lightning is also the sponsor of this video so thank you to lightning let's get into it so I am literally starting from nothing you are going to watch me install it you're going to watch me set up all the agents line by line so the nice thing about lightning AI is it is a cloud environment IDE and it's also so much more and I'll get to that in a bit but it's essentially vs code completely in the cloud and you could collaborate with other people on the code so right now this is from within my browser which is really cool and I opened up the terminal same thing as vs code so everything should feel super familiar to you I opened up the terminal right here and let's get started I can see we're on python 3.10.1 right there and if I click on it I can select another version but we don't need another version so what we're going to do is PIP install crew aai and that's it let's see if it goes okay downloading everything that should be good okay it's done awesome I'm also going to have the crew aai documentation open just so I can reference it whenever I need and so now that I have crew AI installed that actually should be it to get started defining our agents so I'm switching over to the documentation I'm going to copy the code from the documentation I'm going to switch back and I'm just going to print it all in here and we're going to adjust it as we need so let's delete this comment we're going to import OS which will allow us to handle our API key and we're going to be using chat GPT initially but we may end up using a local model later now the good thing about lightning AI is it's not only a cloud IDE but you can actually power models you can spin up gpus and power open- source models and directly connect them to whatever application You're Building lightning is really made for AI applications so I switched over to create new keys and open AI let's hit create new key and I'm going to type crew yt2 because I already started one and I'm starting another one create secret key copy I'm going to revoke this key before publishing the video of course and right here on line four I'm going to double click and enter my API key and I'm realizing that by habit I'm hitting save often and I probably don't need to do that with lightning because it saves automatically as I'm going so I'm going to rightclick on main.py right over here and I'm going to go down to rename and I'm going to call it crew. py okay and I realize I already made a mistake because if we just do pip install crew AI it's going to install the latest stable release but what we want to do is actually hit equals equals and then insert 0.14.0 RC so what we're going to do first is PIP uninstall crew aai and so now you can see I make mistakes all the time and then we're going to do pip install crew AI equals equals and then 0.14.0 RC and then we hit enter okay so it's installing the newest version and I got a list of the tools and they're not documented yet but I'm going to show you what they are and I'll add them as a comment in this file right here once this is done okay it's done okay so before we continue I'm just going to add a comment right here these are the tools that we will soon have access to in the main version but in the release client we can access them right now so comment those out so we have code doc Search tool CSV Search tool directory Search tool we have a txt Search tool Json all the way down we have website search Tool YouTube video search tool so we have a lot of different tools that we're going to be using now I think the first crew I want to create is something that I need personally and a lot of you ask hey AI agents are great but what is the real world use case for them and so that's what I'm going to show you today I collect links for AI news all throughout the week and I'm starting to put out a newsletter more frequently than I have in the past so first be sure to sign up for my newsletter the link is in the description below but what I want to do is create a crew that I can drop a bunch of links into they go check out what each of the articles are about and then just write a short summary of each one and that'll just save me a bunch of time when I'm creating the newsletter myself so here's an example of how to use a tool from Lang chain so from Lang chain community. tools import duck. go search run and we just set it as a Search tool but we're not going to need that so let's go ahead and delete that there and I'm going to give us a little bit more room in the code editor so the first agent being created is the researcher agent and I'm going to be changing that so we're going to call it the scraper agent and the role is to actually I'm going to change that to the summarizer agent and the role will be summarizer of websites goal let's set that to Let's see what should we set that to that'll be go to a given website scrape the content and provide a summary of the article on the website okay backstory let's give it a little bit of backstory you work at a leading Tech Think Tank that's fine your expertise lies in identifying emerging Trends that's fine you have a knack for dissecting complex data and presenting actionable insights so I don't need that and we're going to say you have a knack for taking complex topics AI topics and explaining them clearly and succinctly with a bit of wit okay we're going to keep verbos true because we want to see all the output and I don't want this summarizer agent to delegate anything and that's something really nice with crew AI is you can allow for delegation really easily now for the tool it says Search tool so we do need to change that I'm going to delete all these comments and by default it will use GPT 4 so for the Search tool rather than that we're actually going to use the website Search tool and I think the website Search tool goes and scrapes a website but we'll see again I'm doing this for the first time we'll do it together all right next we have the writer agent and that is good and the role is a tech content summarizer and writer goal craft compelling content on AI advancements and we're going to actually say craft compelling short form content on AI advancements backstory you are a renowned content creator known for your insightful and engaging articles you transform complex Concepts into compelling narratives that sounds good verbose true allow delegation true we do not want this agent to delegate actually maybe we do because the writer is going to delegate the scraping to the summarizer I think that's how it could work so let's leave delegation on now we have two tasks let's see what they are task one conduct a comprehensive analysis of the latest advancements in AI in 2024 okay so we're going to change this we're going to say for task one take a list of websites that contain AI content read SL scrape the content and then provide a short summary a short and interesting SL compelling summary of the content found on the website okay and we're going to give this to the writer actually now that I'm thinking about it the first task needs to be going and getting the content so let's do that first so I'm going to say the summarizer is actually going to be a scraper agent so that's their only job is to go get the content so let's change just a little bit scrape the content and provide the full content to the writer agent so it can then be summarized and r rather than this backstory I'll leave leading think tank but we're going to change this to be your expertise is taking URLs and getting just the text based content of them okay then for the writer craft compelling short form content on AI advancements based on long form text passed to you okay so task one take the list of websites that contain AI content read scrape the content and then provide so we're going to change this and then so read scrape the content and then pass it to the writer agent so this is going to be the scraper and then we have the writer using the text provided by the scraper agent develop an engaging blog post so I'm going to change this now develop a short and compelling slash interesting short form summary of the text provided to you about AI let's see what happens we're probably going to have to iterate on this a few times so we have task one task two we create a crew right here we're going to have two agents in the crew we're going to have the scraper agent and the writer agent we have task one task two and verbose equals two you can set it to either one or two to different logging levels and we're going to leave it as two so then we get the result and we go ahead and print the result okay so one thing we're going to have to do is figure out a way to pass in the list of Articles so let's see if we could do that right here ask the user for a list of urls then go to each given website scrape the content and provide the full content to the writer agent so it can be summarized so let's see if this works we might need to actually pass the URLs directly in here well let's see all right let's play it and see what happens so I'm going to clear everything in there let's hit play and let's watch it work okay name error website tool is not defined right okay so we still need to actually Define it up here to be able to use it so I think this is going to be how we do it so from crew aai tools and we don't actually have that so let's add that here now this is not documented at all so it's a little bit difficult to figure out but we'll try crew a crew a AI tools let's see if we just hover over it do we get any information okay I don't think this is right crew AI tools maybe okay let's try that then from crew aai tools we're going to import the website Search tool just like that and we're going to set set it to website let's see what do we call it down there website Search tool let's look at another example of how it's done real quick so right here Search tool okay so we can name it anything we want website Search tool equals okay so let's do this a little different what we need to do is put this on a separate line so we're importing the library first then we set it like this just like that I'm going to copy this make sure that it matches the tool down here so it's actually using uppercase so let's just change that just like that okay we're going to save there seems to be an error so I think we can maybe delete the parentheses off of that and that might work let's see play okay import error cannot import name crew AI tools from crew AI maybe we don't need to have crew AI tools up there feels like we do but maybe not let's see okay all right great that worked so this is how it's done so crew aai tools is already going to be built in and we just say from crew AI tools import and then the tool that we want now let's see what we got okay starting task entering new crew executor sure could you please provide me with a list of URLs you want to scrape error I didn't use the right format I must either use a tool use one at a time or give my best final answer okay so we did not do this right I'm going to stop it and it's nice because all the same keyboard Keys work with lightning AI uh that you're familiar with with vs code so I'm going to look at some of the examples so let's look at the stock analysis right there so we have tools just like that that's good okay that's how we have it backstory best financial analysis okay now let's look at the actual code so here's the code for the agents okay so all the agents are defined in one file that's cool we could do that and then we have the actual task so the financial anal financial analysis takes self and agent but where does it actually Define the stock that we want to analyze let's look okay let's look at main.py maybe we're passing it in there okay I see what's being done here so in the python script itself the first thing we're doing manually is asking for the input we save it as company and then we pass it into Financial crew and then the crew does the rest so that's what we're going to need to set up so I'm not sure how to do that but we'll figure it out together okay so I'm going to first copy this code let's just take that and we know we're going to need something like this so we'll put it in here and it's probably going to replace something around here so I'm going to leave everything in one file for now just to simplify things let's paste that code in so instead of this so this is the main part of the Python code we're going to be running so I'm going to actually change this back to main.py and then we're going to say welcome to newsletter writer okay uh and then we're going to say websites what is the company you want to analyze we'll see what is the URL you want to summarize and then Financial crew we're going to call it newsletter crew newsletter crew okay so let's call this this newsletter oops newsletter crew okay that might work let's just make sure all the capitalization is correct and then we want to do newsletter crew. run here is the result okay so I'm wondering why the newsletter crew up here has run and this one has kickoff so let's double check okay so let's look at the task here we go so stock analysis task and I really like how he keeps all of his code really modular so I might copy that but for now let's try to do it without that okay let's look at the agents okay I'm going to go back to main.py and I'm just trying to figure out how he set all this up so I can essentially mimic the same thing that he did okay so he does have crew right here and this whole thing okay I see I see so the whole thing is wrapped with this class so I think that's what we're going to have to do so I'm going to copy all of this and actually I'm just going to copy the top part I think that's all all we're going to need then we in instantiate our agents right there and task but we're going to Define them in the file itself so I'm going to hit copy and then at the very top let's add in the class we're not going to Define our agents and task like this we do need to indent this so they fall under run because that is how he did it and let me just make sure about the yeah this is also indented okay so let's go back to lightning and we do need to indent everything under this new class that we just created go ahead and indent it and now we have scraper okay we need to indent one more time everything should be within run I believe let me just double check def run okay right so this is actually outside of the class when we actually have to run it so let's make sure to do that so this is a top level piece of code and that should be good now up here we're going to change this to be newsletter crew and we don't want company but we want URL URLs I'm going to change this to the URLs and somehow we have to pass those URLs into the actual agents so let's see how we're going to do that okay self andit company right here so let's keep this as as URLs need that got it okay so now at the bottom right here newsletter crew not company but URLs okay so now it gets passed in URLs and let's make sure that the agents within the screw have access to those URLs so let's see how they defined it in here so we're going to switch over to stock analysis agents the definition because this is where this is where they would be passing in the URLs I believe or the company in this case okay but it doesn't seem to be doing it here let's see maybe it's passing it into the task yeah company okay and then that's how we do it okay so we're going to have to insert it just like that selected company by the customer so let's do that so if we add two new lines right here and then we say something like here are the URLs from the user that you need to scrape and then we say uh open curly braces and then URLs hopefully this works let's see okay so this should be done and I'm going to go ahead and clear the output in there and then let's push play okay Dent is not defined right cuz I didn't to find it anywhere Dent let's see where we actually have that dent okay let's see Dent must be right there perfect okay so we're going to find that from text drop let's go ahead and import that into our code okay then let's run it again all right there we go so it asked me for a URL that is perfect what is the URL you want to summarize now I want to be able to pass multiple in but for this first iteration I'm just going to give it one so I found this article AI startup Runway is raising a venture capital fund and this was from a couple weeks ago so that is what I'm going to start with let's switch back to the code URL I want to summarize paste it in hit enter okay name crew is not defined did you mean crew maybe let's find out so lowercase crew as compared to uppercase crew crew is not defined let's find that lowercase crew here we go right there so maybe I did mean uppercase but that oh right we don't actually need to do that we need to actually say newsletter crew and I think that is what is wrong so let's try it again push play it's going to ask me for that URL again let's get it again paste it hit enter okay type attribute or attribute error type objects newsletter crew has no attribute kickoff interesting let's find out what's we're doing wrong here ah we don't need to do that here okay so the newsletter crew is actually run from right here so I have duplicate code so let's get rid of that but I'm not quite sure if this is going to work still because I feel like it should have hit this first but maybe it only does that after loading all the other code and um exposing my lack of experience with uh python here so glad I'm doing this you guys uh should know I've only been doing python for about a year now all right let's give it another try probably going to have another error let's find out okay what is the URL we want to summarize let's grab it oops let's paste it in here hit enter none here is the result none okay so no errors but it definitely did not work here is the result so what are we doing wrong newsletter crew. run we have the newsletter crew right here run then we have the agents that get defined the tasks the new oh we don't actually kick it off here that's the problem okay so let's copy that and we want to do. kickoff I think maybe this will work let's see hit play we're going to need that article again switch back URL you want to summarize hit play all right I think that worked except is it actually inserting I I am unable to surf the Internet or access URLs directly however the tools I'm provided with do not allow me to directly scrape data from websites well that's not helpful okay yeah it's telling me it can't access the website but that is not true here is the result none so why is it telling me that so all the code looks to be correct right now but I think what we're going to have to do is give it a little nudge to actually be able to go in and scrape the website and gp4 thinks it can't but you need to use the tool I gave you so here's the website Search tool which might not actually be what we think it is but let's find out and so rather than saying then go to each given website what we're going to say is then use the website Search tool to then scrape the content let's see if that helps us let's hit play okay I'm sorry for the misunderstanding I'm sorry for the confusion but I need the URLs to be able to continue with the task okay so something I'm doing it is not passing the URLs in correctly so not everybody gets to Ping the founder and be like hey can you help me appreciate you helping out Joe is the founder of crew AI so very happy for a little bit of help from him I am currently let me actually share my screen so I'm I'm in the middle of the video I'm doing a let's build so it's a very like um kind of slow paced video going through each step all the errors are all going to be seen by the audience I'm using lightning. a as the uh Cloud IDE and I set up a crew and what I want them to do is I want to be able to pass a set of URLs one of the agents is a scraper agent that agent is going to go scrape the websites and bring the content to the writer agent the writer agent is then going to write a brief summary of each of the URLs that I passed to it now the first problem is before I had this used the website Search tool gp4 says I can't scrape website content and then I explicitly told it go ahead use the website Search tool now it work Works however where I'm a little bit stuck is I and by the way I'm using um your web uh stock analysis tool uh as kind of a reference so I'm trying to pass in the URLs here but apparently it is not getting passed in properly the URLs do get passed in I believe right here so I have them available but I'm I you know I'm not great at Python and I'm probably doing something wrong but it told me if we look down here I'm unable to proceed with the task without the URLs could you please provide the URLs so that is the issue right here got it got it all right so basically what is interpolate the URLs into that task there um where do you have those Ur where are those URLs coming from so very similar to how you did it I'm using Dent to ask a question immediately what is the URL you want to summarize so I'm starting with just one but I'm going to assume I want to kind of plug in a bunch eventually I just want to get this to work but they're coming right here all right got it and then you create this newsletter CRS and you P you pass the URLs for in all right let me look at the class newsletter crew up there uh newsletter crew all right it takes a URL all right so the only thing that I can see that you're not referencing is instead of having just URLs as you have in there and you want to do self. URLs uh in the in the task just like that and then and then you put an a before the string starts right after the Des right after the description equals ah and that will add interpolation to it exactly so that'll allow you toate that string and then you reference the the instance variable URLs that you declare upstairs okay very cool all right let's give this a try I mean I know this is very basic stuff by the way um but uh I was excited to show you this crew and I'm probably going to create a second crew for a completely different use case after this but we'll see so okay I'm going to grab a URL and by the way I assumed website Search tool is a website search or a website scraper is that correct it's actually a rag searching to on top of the website so it's going to actually search for something in that website and return specific paragraphs that are kind of like relevant to that ah so maybe this isn't the best tool to be using for scraping yes if you want to do actual scraping I don't think we have a two for that yet but uh I can get one up pretty quickly do you think or do you know of uh if Lang chain has any website scraping tools I'm sure it does otherwise I'll just have to write it myself which is fine yeah I'm not sure if it does I can look it up in the past what I have done is I basically did my own using uh unstructured like this library from U this library that basically cleans up HTML so that's what I have done in the past and I probably have it like in some example somewhere I can I can grab and send it over to you sure I mean that'd be helpful I'll I'll try to use chat GPT to help me write a a scraping tool and um we we'll see if it works but I um yeah I think that would be a good time to just create a tool for like a custom tool for this agent team to use all right well thank you I appreciate the help uh I am going to get back to building this crew and hopefully I can make it work by the end of this video have a good bye okay so I just got off a call with the founder of crew aai and he explained a few things I was doing wrong so first right here we actually have to reference self. URLs to interpolate properly and we have to add the F at the beginning of the string so that it knows we are trying to interpolate now back at the top one thing he mentioned is this website Search tool is not actually what I thought it was so what this does is it will uh use rag it will grab all the content from a website and then you can actually search through the content of that website using rag so really cool tool but not what we need what we need to do is have a website scraper so we're going to have to create a custom tool just for that let's do that now so we're going to go ahead might as well just delete this I am going to remove all of these tools commented out for now CU we're not going to need them and let's go see how to create a custom tool so in his stock analysis example we have this tools folder and if we open it up we have calculator tools browser tools so I think we're going to have to do something like this so I'm going to copy this it's not going to be a lang chain tool so we're going to have to create it from scratch but let's do that let's switch back I am going to create a new folder called tools then I'm going to create a new file within that folder called scraper dopy and I'm going to paste that code in and let's just call this scraper tools let me just make sure it all yep so that's how he did it so scraper actually if we go back it's actually called calculator tools right so let's make it match the class name so rename scraper uncore tools okay so at tool scrape website content text only okay and then we'll put a nice little comment at the top useful to to scrape content of a website and we probably don't need the triple quotes but we'll leave them there anyways and then return eval operation that is not what we need to do so what we need to do we'll say return text and rather than calculate let's call it def scrape and this will be URL okay so now I'm going to switch over over to chat GPT and I'm going to ask it to help me create a scraping tool so wrer website scraping tool using python so it looks like it's going to be using requests and beautiful soup so I'm going to have to install that so let's do that first so down here let's close this thread then I'm going to say pip install request and beautiful soup 4 and already satisfied so that's good it's already there then we're going to copy this code switch back to our tool let paste it right here and what we're going to have to do is at the top We'll add our Imports the URL we should actually get from the URL so we're going to instantiate it with a URL I think that's the best way to do it it says scrape title but that's not what we need right we don't want it to scrape the titles so let's actually ask it for a slightly different code please make the code scrape all text content from the website o it's bugging out a little bit wow it is wacky right now okay this is barely working it seems to be outputting but for some reason the scroll bar is jumping around okay so it looks like it fixed itself so now here scrape all text getting the URL parsing removing the elements okay so I'm going to copy this code let's go back to lightning and I'm going to replace all that okay so we don't need to import these again okay so I'm going to take all of that right there all of the main code and let's put it into here we'll delete this at the end and we're going to return text which seems correct but it is not so instead of printing right there we're going to just return combined text now we may have an issue that it's including a lot of text that is not necessarily relevant to summarizing the article but let's find out now I'm actually not sure if this is the proper way to pass in this variable so I'm going to double check with how he's doing it so it is not so let's delete that I don't think we need this okay and then that should be good I think I think that should work and so we're going to copy this switch back to main.py and let's just see how he Imports it so tools dot there we go okay so that's how he does it so what we're going to do is from actually we'll put that at the top from tools. scraper tools then how did he do it import scraper tools okay hopefully that works now we need to instantiate scraper tools scraper tools scraper tools is equal to scraper tools maybe that'll work and then right here I'm going to input scraper tools so let's actually capitalize that like that okay maybe this will work let's find out together so hit play all right name Tool is not defined did you mean bu where is tool at tool scrape website content text only so there's something wrong with ah I see so it is the fact that we're doing this at tool which is not relevant unless we're using laying chain so let's go ahead and delete that because we don't need that and now that that is fixed let's try it again okay what is the URL of the website you want to summarize let's grab that URL paste it in hit enter all right key error tools so we still have an issue so this is on AG agent. Pi nope not there main. Pi line 16 scraper main. Pi line 66 okay no so it's keyword key error tools so I think it's this that's causing the error so one really cool thing is I just put this session live and I'm giving it to somebody to help me out uh that is a really awesome feature of lightning and look at that now he's in here taking a look at the code in real time this is cool uh I think I like Cloud editing much more than local editing now so maybe I should think about doing live coding sessions going forward maybe I'll put it live on YouTube and actually do it live through lightning. if you want to see that let me know in the comments below okay so we can see the changes he's making in real time okay so I changed a few things so we are going to use Lang chain tools import tool as the way to actually Define the tool then we can use at tool right there and everything else is pretty much the same now one problem I'm running into is that the website I want to scrape is actually just blocking the request so I'm going to tell chat GPT this and let's see if it can give me another method to scrape the website okay so everything works and then it says failed to retrieve the web page so I'm going to copy that put it in here and I'm going to say is there a better way to retrieve the website content use headers to mimic a browser that's what we need to do okay so let's copy that code so let's make it look like we are an actual browser that's the problem so right before this we're going to enter the code we just got now we already have this stuff so let's get rid of that we don't need the URL cuz we're going to be passing that in and we will need the headers so let's put that there okay and scrape all text so we don't need to find it again response equals so we're going to be passing in the headers this time and then everything else should be the same as we have it before okay I think this may work now let's give it a try so I'm going to clear all the output in the terminal let's play it what is the URL you want to summarize okay failed to retrieve the web page again darn it okay let's see if it'll work on the crew aai website maybe it is that simple maybe it's just continuing to block my request because it thinks I'm a scraper which I am but that is besides the point what is the URL you want to summarize crew ai.com okay invalid URL crew ai.com crew ai.com perhaps you meant okay so we should definitely fix that but that's okay let's give it the full URL now okay so it should be be out scraping there we go perfect so it is working properly I'm going to go ahead and stop that so now we know it's working properly so the problem is this website is still blocking our attempt to scrape it so back to uh back to chat gbt still getting failed to retrieve website is there another way to scrape the website libraries like fake user agent can help Generate random realistic user agent strings for each request all right let's see if that works third party tools and services using API end points instead of scraping okay sample scrapey with Splash code snippet this is getting complex more complex than I was hoping let me try actually a different URL I just want to get this to work at this point all right here's another article by a website payments.com report open AI surpasses 2 billion and annualize revenue back to to lightning AI let's try it again but this time we're going to use that website and hopefully they don't have as sophisticated of scraping blockers boom let's see I think it's working yep oh it worked but then we have an error let's see what it is please reduce the length of messages ah so now we're getting an open AI issue this model this model's maximum context length is 8,000 tokens okay yeah we're passing a lot in there a ton actually okay so let me see maybe there's a way to identify the actual content of the article ah yes because this is the homepage okay so it's just a scrolling list so maybe there's a way to get the direct text okay I'm going to ask chat GPT so I've gone back to the previous scraping method on another website which works how do I make sure to only grab the topmost article text and nothing else okay so you need to First identify how the website's HTML structure distinguishes the top article from the others using specific tags so here's an example right clicking and hit inspect yeah that sounds good let's try that so we'll look for this right here we're going to right click we're we're going to hit inspect and we're going to look for some kind of tag that it might be let's see Post Feed text all right insert article that'll get rid of some stuff okay so it looks like it uses ID equals insert article let's only target text within that ah and I actually typed it wrong it's insert uppercase article I really wish I had a bigger context window right about now okay so I'm going to copy go back to the code scraper tools and let's see what the difference is so here we go article this is going to be the difference right there and I'm going to just grab this whole amount of code right there switch back okay so text element is find all article equals soup. find so I'm going to delete this we're not going to find all anymore and we're going to say insert article now this is just going to work for this website obviously so I'm going to need to mess around with the scraper tool to make it more generally applicable but for now I just want to get it to work so I'm going to say text is equal to and then it's going to do that then I'm going to delete this other part right here then I'm going to use I'm going to delete text right there okay we'll return text and we're going to join we don't really need that actually let's just see what happens just like that all right let's play it one more time I'm hoping this works what is the URL of the article you want to summarize grab it okay it should be there we go we got it Perfect all right Final Answer perfect so it grabbed the text now finish chain and it gave us a very brief summary that's good here we go summarizer of websites entering the crew delegate work to coworker now hopefully it's going to give us a an even briefer summary a re a rewrite of it ah failed to retrieve web page I already Ed a scraper tool with input blah blah blah so I already know that and I must stop using it with that same input Perfect final answer all right this is exactly what I needed finished chain hopefully it just ends now all right here is the result and the result is empty but it's right there awesome and this is not the text from the article as far as I know and so there we go we got a summary of that article now I'm going to end it here because this is already a very long video but in my next video I think I want to make this much more robust because I think it has the potential to be much more robust now this was made very easy with lightning AI because I did everything in the cloud I had someone help me live right in front of my eyes in the cloud which was super super awesome and not only that I've only scratched the surface of what's possible with lightning AI because you can load models you can fine tune models you can actually run models in the cloud powering your agents and all of this is done through lightning AI so thank you so much to the sponsor of this video lightning AI check them out I'll drop a link in the description below where you can find out more and get set up with them I highly recommend it you saw it in action it's awesome if you like this video please consider giving a like And subscribe and I'll see you in the next one"
    }
}