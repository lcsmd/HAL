{
    "wM5837pVh1g": {
        "title": "Andrew Ng STUNNING AI Architecture Revealed | \"AI agentic workflows will drive massive AI progress\"",
        "thumbnail": "https://i.ytimg.com/vi/wM5837pVh1g/hqdefault.jpg",
        "author": "Wes Roth",
        "date_of_release": "2024-03-30T01:10:06Z",
        "duration": "PT28M24S",
        "view_count": "80367",
        "like_count": "2296",
        "comment_count": "207",
        "description": "Learn AI With Me:\nhttps://www.skool.com/natural20/about\nJoin my community and classroom to learn AI and get ready for the new world.\n\nSEE FULL VIDEO HERE:\nhttps://www.youtube.com/watch?v=sal78ACtGTc\n\n\n\n\n\n\n#ai #openai #llm\n\nBUSINESS, MEDIA & SPONSORSHIPS:\nWes Roth Business @ Gmail . com\nwesrothbusiness@gmail.com\n\nJust shoot me an email to the above address.",
        "transcript": "there's been a number of great and very interesting videos that have been released on the topic of AI a lot of this is from seoa Capital so a big venture capital and investment firm and they have a few very interesting speakers some of whom I would like to highlight this is Andrew a we've talked about his tweets before where he was talking about AI agents and sort of this next step of AI Evolution and now this is like a short presentation that he gave at the sequ capital Meetup talking about AI agents so let's take a look at this and I'll pop in everyone so with some annoying commentary or helpful commentary I hope what I'm seeing with AI agents which I think is the exciting Trend that I think everyone building in AI should pay attention to and then also excited about all all the other uh WN presentations so AI agents you know today the way most of us use Lish models is like this with a non- agentic workflow where you type a prompt and generates an answer and that's a bit like if you ask a person to write an essay on a topic and I say please sit down to the keyboard and just type the essay from start to finish without ever using backspace um and despite how hard this is lm's do it remarkably well in contrast with an agentic workflow this is what it may look like have an AI have an LM say write an essay outline do you need to do any web research if so let's do that then write the first draft and then read your own first draft and think about what parts need revision and then revise your draft and you go on and on and so this workflow is much more iterative where you may have the L do some thinking um and then revise his article and then do some more thinking and iterate this through a number of times and what not many people appreciate is this delivers remarkably better results um I've actually really surprised myself working these agent workflows how well how well they work I to's do one case study at my team analyzed some data uh using a coding Benchmark called the human evalve Benchmark released by open a few years ago um but this says coding problems like given a non-empty list of integers return to sum of all the OD elements are in even positions and it turns out the answer is you know code snipper like that so today lot of us will use zero shot prompting meaning we tell the AI write the code and have it run on the first spot like who codes like that no human codes like that just type out the code and run it maybe you do I can't do that um so it turns out that if you use GPT 3.5 uh zero shot prompting it gets it 48% right uh gbd4 way better 67 7% right but if you take an agentic workflow and wrap it around GPD 3.5 say it actually does better than even GPD 4 um and if you were to wrap this type of workflow around gb4 you know it it it also um does very well and you notice that GB 3.5 with an agentic workflow actually outperforms gp4 um and I think this has and this means that this has sign consequences I think how we all approach building applications so agents is the term has been tossed around a lot there's a lot of consultant reports talk about agents the future of AI blah blah blah I want to be a bit concrete and share of you um the broad design patterns I'm seeing in agents it's a very messy chotic space tons of research tons of open there's a lot going on but I try to categorize um bit more treely what's going on agents reflection is a tool that I think many of us should just use it just works uh to use I think it's more widely appreciated but actually works pretty well I think of these as pretty robust Technologies when I use them I can you know almost always get them to work well um planning and multi-agent collaboration I think is more emerging when I use them sometimes my mind is blown for how well they work but at least at this moment in time I don't feel like I can always get them to work reliably so let me walk through these four design patterns one of my favorite kind of research papers to go over on this channel was where they got this multi-agent collaboration to play Minecraft now this wasn't nvidia's Voyager it was a separate thing but basically they took they created four Minecraft players each its own I believe it was gp4 at the time and they would go out and try to complete certain goals but before they would all set up and kind of talk through what they need to do so they're like we need to build a house how do we build a house and the other person's like no guys like we need to get get some food first right and so as they went back and forth their ability to reason about what they need to do improved then they would distribute tasks now keep in mind this is out of the box this isn't nobody taught it to play Minecraft no one explained to it I mean there was like a prompt that kind of told it very vaguely very in general terms what it should do but they had to figure out everything for themselves these four little AI agents playing Minecraft and so they broke up each task that they came up with into subtasks and assigned it to each each of the four players you know the four AI agents and then those AI agents went and they started executing those tasks what was incredibly impressive and just so interesting is that they naturally like if one would complete a task earlier than the other three they would immediately lend a helping hand to the other 3D I would say okay I'm done let me see if Bob needs some help I should probably dig up that paper and do it again because was absolutely like reading through it it was so and it wasn't one of the big papers that got a lot of attention this was really like that video didn't do well that paper didn't get a lot of attention but it was just such a fascinating read because of how effective they were at going out there and completing tasks and collaborating far better than humans you know there was no complaining there was no criticizing there wasn't fighting over tasks or who was the boss it was very collaborative and they would be able to course correct so if one person had like a bad idea or there was this one AI that kept forgetting what it was doing it was like doing the wrong thing so the other one was like hey Bob we're out chopping wood now what are you doing Bob was like I'm hunting Pigs and the the other three were like no no Bob Bob we we're chopping wood now go chop wood and Bob's like all right yeah I forgot my bad and and and so they kind of like pushed the other in the right direction there was this I don't want to say coercion that's a bad thing but they were kind of like course correcting each other towards the right in the right direction the only thing that was kind of bad about that paper and they buried this like at the end after the conclusion kind of in the appendix was there was a time when all four Bots spontaneously they they couldn't find something they couldn't find wood or some sort of material so one of them goes like let's go raid this nearby Village with where these peaceful villagers lived I guess they had like a library that that had the needed materials and the other four were like yeah you're right we need to do that and they just went and just they raided the whole thing they destroyed the library and then and took the took the materials that they need so that was a little bit dark but other than that one instance uh the whole paper was this the whole experience was very very positive the reason I mentioned is because when you think about this think Beyond narrow cases of like finishing your spreadsheet or whatever because of the gener of how General AI is now this kind of idea of like general intelligence this can be applied to anything you can throw them in a game of Minecraft and have them work together to figure out how to do whatever build the biggest castle and just watch the AIS in there working on that you could create a committee that tweets for you for example if you're trying to build a Twitter following right they sit around and they're like well let's see what's working and here's a tweet let's see how it how well it did and they kind of reflect on how well they did and they keep writing better ones maybe one is a writer one is a researcher one is like trying to figure out all the hottest latest memes and incorporate that into it one is a artist decorate with that comes up with the art for the tweets now this these scenarios I'm mentioning here were probably not there yet like I don't think I'm sure some prototypes of of this is they're happening right now but we're not there where it's like completely reliable but if you've been following along that's the next big wave that's coming it's it's going to be here soon so as you watch this try to think in your life in your in your work or career or Leisure Time whatever think about where could you use a team of agents that work 24 hours a day tirelessly on your behalf so let me walk walk through these four design patterns the few slides and if some of you go back and yourself will ask your engineers to use these I think you get a productivity boost quite quickly so Perfection here's an example let's say I ask a system please write C for me for given task then we have a code agent just an LM that you prompt to write code to say you def do task write the function like that um an example of self-reflection would be if you then prompt the LM with something like this here's code intended for a toss and just give it back the exact same code that they just generated and then say check the code carefully for correctness sound efficiency good construction C just write a prompt like that it turns out the same L that you prompted to write the code may be able to spot problems like this bug line five and fix it by blah blah blah and if you now take his own feedback and give it to it and reprompt it it may come up with a version two of the code that could well work better than the first version not guaranteed but it works you know often enough but this to be worth trying for LW of applications um to foreshadow to use if you let it run unit tests if it fails a unit test then why you fail the unit test have that conversation and be able to figure out fail the unit test so you should try changing something and a unit test for those unfamiliar is basically if you have a large complex amount of code and testing a smaller portion of it to make sure that smaller portion works so for example you have a large code that figures out if a person is eligible for something based on some number of criteria and the first is you know are they over 18 right there's probably a block of code there that checks if they're over 18 based on their birthday for example so a unit test might be just testing that block of code to make sure that that block of code works and more and more people are using AIS to create these little unit tests to test their own code whether that's code that the human wrote the engineer or the computer itself it can run a little unit test see if it fails and if it fails potentially you know using that idea of reflection to try to correct it by the way for those of you that want to learn more about these Technologies I'm very excited about them for each of the four sections I have a little recommended reading section in the bottom that you know hopefully gives more references and again just the foreshadow of multi-agent systems of described as a single coder agent that you prompt to have it you know have this conversation of itself um one Natural Evolution of this idea is instead of a single code agent you can have two agents where one is a code agent and the second is a Critic agent and these could be the same base LM model but they you prompt in different ways where you say one your expert code or right code you say your expert code reviewer as to review this code and this type of workflow is actually pretty easy to implement I think such a very general purpose technology for a lot of workflows this would give you a significant boost in in the performance of LMS um the second design pattern is two Ed many of you will already have seen you know LM based systems uh uh using tools on the left is a screenshot from um co-pilot on the right is something that I kind of extracted from uh gp4 but you know LM today if you ask it what's the best coffee maker can your web search for some problems LMS will generate code and run codes um and it turns out that there are a lot of different tools that many different people are using for analysis for gathering information for taking action personal productivity um it turns out a lot of the early work and Tool use turned out to be in the computer vision Community because before large language models lm's you know they couldn't do anything with images so the only option was that the LM generate a function call that could manipulate an image like generate an image or do object detection or whatever so actually look at literature it's been interesting how much of the work um in two years seems like it originated from Vision because LMS would blind to images before you know GPT 4V and and and lava and so on one interesting paper we covered on this channel is called language models llms as tool makers and in it they found so if you take a larger smarter model like gp4 for example and have it code up tools to use so for example let's say it tries to analyze a sentiment of some document based on the number of times words like sad and happy are being used for example right they can actually write up code that runs and checks a particular set of text for that or a simple calculator like the investment calculator that Andrew mentioned here and with that people discovered is if a GPT 4 or a higher-end model codes up these little tools and calculators whatever you call it the these scripts these pieces of code these tools and gives it let's see let's say it spins up a smaller model GPT 3.5 Turbo it spins it up it gives it those tools now that smaller models interestingly enough often times will perform on the same level as GPT 4 for those narrow tasks but we'll do so you know better faster because it's and cheaper because it's a you know a faster cheaper model so you can think of it as the big smart expensive model creating tools for the small cheaper models imbuing each one with a specific tool for a specific use case and those cheap models will often be as good as GPT 4 for that particular task to think about that for a second gp4 or the smarter models can create clones of themselves that are as good them as themselves for certain tasks but faster cheaper gets a little bit weird to think about right um so that's two use and it expands what an LM can do um and then planning you know for those you that not yet played a lot with planning algorithms I I feel like a lot of people talk about the Chad moment where you're wow never seen anything like this I think if not used planning algs many people will have a kind of a AI agent wow I couldn't imagine the AI agent doing this I've run live demos where something failed and the AI agent rerouted around the failors I've actually had quite a few of those more like wow you can't believe my AI system just did that autonomously but um one example that adapted from hugging GPT paper you know you say this gener image where the girls read where girls read book and it post the same as boy in the image example. jpack and please describe the new image for your Void so give an example like this um today we have ai agents who can kind of decide first thing I need to do is determine the post of the boy um then you know find the right model maybe on hugging face to extract the post then next need to find a post image model to synthesize a picture of a of a girl of as following the instructions then use uh image the text and then fin use textas speech and today we actually have agents that I don't want to say they work reliably you know they're kind of finicky they don't always work but when it works is actually pretty amazing but with agentic Loop sometimes you can recover from earlier failures as well so I find myself already using research agents for some of my work where one a piece of research but I don't feel like you know Googling myself and spend a long time I should send to the research agent come back in a few minutes and see what it's come up with and and it's sometimes what sometimes doesn't right but that's already a part of my personal workflow the final design pattern multi-agent collaboration this is one of those funny things but uh um it works much better than you might think uh uh but on the left is a screenshot from a paper called that is spot on it works much better than what you would think we covered this in the Chad Dev video that I did where each one of these low guys is its own Chad GPT GPT 3.5 turbo and they cat up pretty incredible tools and games and stuff like that and uh collaborate to actually problem solve and it's when I was doing it when I was recording it and I saw what they were doing but yeah I was kind of surprised at how well it did because it was demonstrating to me live some of these things that I read about in papers but here was actually doing gbt 3.5 in general isn't going to be that great of a coder compared to gbt 4 and some of these other models but when you put a few of them together you give them separate roles and have them work together to work through things out all of a sudden its abilities go through the root and watching that take place live you know on my computer using the API to hook into open AI but it was right there it wasn't a demonstration it wasn't in paper it was happening on my computer they were producing the games and the tools that I was looking for that was wild um chat Dev uh which is completely open which is actually open source many of you saw the you know flashy social media announcements of demo of a Devon uh uh Chad Dev is open source it runs on my laptop and what Chad Dev does is example of a multi-agent system where you prompt one LM to sometimes act like the CEO of a software engine company sometimes act a designer sometime a product manager sometimes I could a tester and this flock of agents that you built by prompting an LM to tell them you're now Co you're are now software engineer they collaborate have an extended conversation so that if you tell it please develop a game develop a GOI game they'll actually spend you know a few minutes writing code testing it uh iterating and then generate a like surprisingly complex programs doesn't always work I've used it sometimes it doesn't work sometimes it's amazing but this technology is really um getting better and and just one of design pattern it turns out that multi-agent debate where you have different agents you know for example could be have ch GPT and Gemini debate each other that actually results in better performance as well so get multiple simulated air agents work together has been a powerful design pattern as well um so just to summarize I think these are the these are the the the uh patterns I've seen and I think that if we were to um use these uh uh patterns you know in our work a lot of us can get a prity boost quite quickly and I think that um agentic reasoning design patterns are going to be important uh this is my small slide I expect that the set of Tas AI could do will expand dramatically this year uh because of a gentic workflows and one thing that it's actually difficult people to get used to is when we prompt an LM we want to response right away um in fact a decade ago when I was you know having discussions around at at at Google on um called a big box search type in Long prompt one of the reasons you know I failed to push successfully for that was because when you do a web search one of them responds back in half a second right that's just human nature we like that instant gra instant feedback but for lot of the AG workflows um I think we'll need to learn to dedicate the toss and AI agent and patiently wait minutes maybe even hours uh to for response but just like I've seen a lot of novice managers delegate something to someone and then check in five minutes later right and that's not productive um I think we need to it be difficult we need to do that with some of our AI agents as well I saw I some loss um and then one other important Trend fast token generation is important because with these agentic workflows we're iterating over and over so the LM is generating tokens for the elm to read so being able to generate tokens way faster than any human to read is fantastic and I think that um generating more tokens really quickly from even a slightly lower quality LM might give good results compared to slower tokens from a better LM maybe it's a little bit controversial because it may let you go around this Loop a lot more times kind of like the results I show with gpt3 and an agent architecture on the first slide um and candidly I'm really looking forward to CL 5 and cl 4 and gb5 and Gemini 2.0 and all these other one4 models in M building and part me feels like if you're looking forward to running your thing on gp5 zero shot you know you may be to get closer to that level performance on some applications than you might think with agent reasoning um but on an early model I think I I I I think this is an important Trend uh uh and honestly the path to AGI feels like a journey rather than a destination but I think this typ of agent workflows could help us take a small step forward on this very long journey thank you so yeah that was it uh I really like Andrew a I was mispronouncing his name for so long um but I really like him because he is one of the sort of top tier Minds in AI research so the people see like ilas Suk Dr Jim fan the people behind you know the Transformers Jeffrey Hinton I think he's up there with them Yan laon I think Andrew is up there with them but he chose I think I mean I'm kind of guessing here but it seems like he chose to focus on teaching more which is incredible for the rest of us because so he has deeplearning.ai is his website so deeplearning.ai and you have a lot of free courses here that he teaches him along with many other people from different companies like hugging face Google etc etc he's obviously very smart very knowledgeable about AI also a clear thinker and I think he does have an ability to explain some of these Concepts fairly simply in a way that can make sense to a large audience which is which is often not the case a lot of these people for all their Brilliance do have a hard time explaining things in a way that's going to make sense to a wider audience they're very like it's almost like we have to translate it from one level to the next and I think it is going to be very important for more people to understand this stuff to have access to this stuff right if it's only if the sort of general population doesn't really understand some of these Concepts they will be easily manipulated potentially making the wrong decisions some newspaper says we're all going to die CU AI you know is mad at us or whatever and some percentage of the people maybe even the majority will just simply believe it because the newspaper said so if more people understand what AI is and the benefits it will bring as well as well as the you know the the realistic risks that it'll bring I think that would be very beneficial for society because we're not going to have these knat jerk reactions to the various progress the various unlocks that we make with AI progress and instead have more like a rational Comm approach and these AI agents like I said they're not quite here yet in the sense of that most of the things I've tried it it does have pitfalls you're not going to let it loose on a big important project and just have it you know done when you wake up it's not 100% accurate it'll break down there's tons of issues isues but we're making a lot of progress and we're making a lot of progress fast not just in one particular area but on on every front we're improving how fast our Hardware is we're improving how good these models are how big these models are we're improving our ability to to prompt them to do what we want and these things that Andrew talked about right he calls them design patterns right we have reflection tool use planning multi-agent collaboration and I think he also talked about a what what to me I think is a fifth one although it's part of multi-agent collaboration but the IDE of the larger smarter sort of quote unquote manager models calling up these smaller models to complete certain tasks so they're like summoning a swarm of Agents of their own to then go do stuff on its behalf which also has been I guess that's part of multi-agent collaboration but in my mind it's almost like a a separate thing so the there are these design patterns and there there potentially more that we haven't discovered and as we get better at doing that that will improve and all these things are kind of compounding on top of each other right faster chips means we can do stuff like this faster we can do it cheaper right so there's maybe more use cases right if it costs $1,000 to run an agent uh like this you know to complete a task well that's one story if it costs a dollar to do the same tasks if it's that much cheaper well the whole game changes because then all of a sudden the amount of like economically viable tasks on which we can unleash these agents on drastically changes right a long time ago the first episode I saw Rick and Morty was the the was the one with the the car battery in the simulated Universe where Rick the Super Smart Genius creates a simulated Universe you know that has conscious beings and worlds and economies that generate energy that he's able to extract into his world and he creates that for the sole purpose of being his car battery and the story gets kind of wild from there because that Universe creates its own subuniverse and that Universe creates its own subuniverse this isn't this isn't a show for everybody I understand but it is interesting to think about how complicated a solution to a problem can get if it's inexpensive to run it so for example when you run a Google search you know it retrieves 10 Blue Links and you can click on those links plus some ads whatever but let's say you have some sort of a multi-agent collaboration thing set up where when you search for something and you're okay with waiting you know an hour or two or overnight for it to do its research kind of what Andrew Ang was talking about at the beginning of the video like what if that indeed creates let's say a thousand different agents each with its own little subtasks some of them going to retrieve the data the others are sort of like the the ones that filter knowledge to try to determine if it's accurate or not some of them are like the ones that are supposed to like learn everything they're supposed to read through the text and kind of like summarize it they're supposed to be the the professors of this thing and each one can kind of create their own sub agents to act as assistants for them Etc as you can imagine this can get pretty complicated right but if it's inexpensive enough and effective enough this could be used for any basic search that you do or you can create these agents to be an entire architectural organization of of Architects and architect apprentices that work out how to build the pool's castle in Minecraft right and then they're Unleashed in there and slowly Brick by Brick they erect this massive structure that is cooler and more intricate than any human would have the patient patients to do how realistic is it that we're going to see something like that in the next 5 years well we're seeing things like Gro grq Those computer chips specifically for llm models that are so much faster and cheaper to run for L you know on llm models to do inference to to do the outputs that they do you know assuming any rate of progress in this area I mean we're probably going to see the cost to run these drop precipitously right it's going to be extremely inexpensive right so prompt in GPT 4 now you know I'm sure it's measured in cents a tenth of a cent right what happens when it's measured in 1 millionth of a Cent and the context windows are massive and all these design patterns and systems exist like we can always copy and paste certain architecture of how these agents fit together and you can just copy you know copy and paste them from somewhere online add your favorite models add your own little your descriptions and then unleash them on whatever tasks that you want done I mean off the top of my head my guess would be we we'll have that in 5 years but I keep getting surprised by how how much faster progress is so what I think is 5 years I would have to like like I would be surprised if it's here you know beginning of next year or maybe it'll be here in a few months those things like Devon the software development agent are getting scarily good anyways with that said my name is Wes rth thank you for watching I had a tooth extracted yesterday cuz I like rapidly started getting a lot of pain and they could do and somebody at the dentist cancelled last minute so they had to do like this you know if you can come in 8 in the morning tomorrow we can fix it for you and I was like whatever just I need it to be fixed it hurt way too much so I spent the last 24 hours plus basically eating ice cream cuz you're supposed to only have soft foods so I ate ice cream and played factorio I'll show you what I built in a different video but but that is to say I'm back and let me know what you think about the style of video where we do a with the YouTubers call react right where we go through a video like this break it down discuss it but I hope you enjoy that and I will see you very very soon"
    }
}