{
    "Voo752vFTKE": {
        "title": "Mind-bending AI Is Changing Art And VFX Forever",
        "thumbnail": "https://i.ytimg.com/vi/Voo752vFTKE/hqdefault.jpg",
        "author": "Matt Wolfe",
        "date_of_release": "2023-05-23T17:57:31Z",
        "duration": "PT20M41S",
        "view_count": "163349",
        "like_count": "8370",
        "comment_count": "418",
        "description": "Here's some of the latest research and coolest tools that I've come across over the past few weeks. I'm trying to get more of a routine down with content so that you have a better idea of what to expect. Here's my current plan...\n\nMonday (or Tuesday): Latest AI Tech & Tools\nWednesday: Tutorial or Challenge\nFriday: Recap of the news this week in AI\n\nI'll mix some other goodies in there as well but that's the current plan. I'm always open to feedback. :)\n\nDiscover More From Me:\nüõ†Ô∏è Explore hundreds of AI Tools: https://futuretools.io/\nüì∞ Weekly Newsletter: https://www.futuretools.io/newsletter\nüòä Discord Community: https://futuretools.io/discord\nüê§ Follow me on Twitter: https://twitter.com/mreflow\nüê∫ My personal blog: https://mattwolfe.com/\nüåØ Buy me a burrito: https://ko-fi.com/mattwolfe\n\nResources From Today's Video:\nhttps://vcai.mpi-inf.mpg.de/projects/DragGAN/\nhttps://blogs.nvidia.com/blog/2023/05/02/graphics-research-advances-generative-ai-next-frontier/#new_tab\nhttps://research.nvidia.com/labs/rtr/neural_appearance_models/\nhttps://yumingj.github.io/projects/Text2Performer.html\nhttps://eckertzhang.github.io/Text2NeRF.github.io/\nhttps://huggingface.co/spaces/vinthony/SadTalker\nhttps://www.google.com/earth/studio/\nhttps://futuretools.link/kaiber-ai\nhttps://futuretools.link/skybox-lab\n\nOutro music generated by Mubert https://mubert.com/render\nSome links in this description are likely affiliate links. I do not talk about products based on whether or not they have affiliate links, however, if a product has an affiliate link, I usually sign-up for it. It never sways my opinion or impacts how I talk about a product. \n\n#AINews #AITools #generativeart \n\n0:00 Intro\n0:30 Drag Your GAN\n3:43 NVIDIA Realistic Hair\n4:42 Real-Time Neural Appearance Models\n5:46 Text2Performer\n9:58 SadTalker\n11:00 Google Earth Studio\n12:47 Kaiber Storyboard\n15:34 Blockade Labs Drawing\n18:42 Future Tools",
        "transcript": "in this video I'm going to cover some of the really really exciting AI research that we're going to get access to soon but isn't quite ready but it's pretty dang mind-blowing and I know people that watch my videos they like actionable stuff they like to know what they can use now I'm going to kind of split this video 50 50. I'm going to show you some of the really cool research that's going to blow your mind that's in the works as well as some of the stuff that you can use right now that's available to play with today but let's get into it so the most mind-blowing research paper that's come out recently that has taken the AI World by storm is this drag your Gan research again is a generative adversarial Network now you've probably heard of diffusion models to generate images where an image starts with a bunch of noise and then the noise is removed to get to the image that you're trying to create tools like mid-journey stable diffusion Dolly they all use diffusion models well generative adversarial networks or Gans is a different method for generating images and I'll likely break down the differences in a future video but it doesn't use the same diffusion method it uses a method where it essentially tries to generate an image the computer tries to guess whether that image is real or fake and and it goes back and forth and back and forth until the computer could no longer tell whether the image is fake or not now that's a real oversimplification of how Gans work but if I really try to break it down that would probably take up this whole video so again I'll try to make another video in the future about the difference between diffusion models and Gan models because while Gan models are actually an older method of generating images they're actually becoming more and more popular lately anyway I'm off on a tangent now this drag your Gan has been blowing people's minds and you're about to see why it's a method where you take a starting image like this lion and you can drag the nose from one point to another and it will actually tweak the image to move the nose to that new point and it will actually be very coherent and you can see that the body of the lion actually changes as it moves the image around so it adjusts the whole image to make sure that it still looks like what it's supposed to look like here's another example with a cat where they move the cat's nose and the cat adjusts just so slow lightly but the rest of the body adjusts so that it stays coherent with the new changes that are being made here's an example where it moves the dog's feet it opens the dog's mouth it adjusts where the dog's ears are and as it makes these moves it adjusts the entire dog or you can mask it off and say only adjust what's inside of the Mask here's one where it's working on a car and adjusting the size of the car or moving the position of the car or changing the way the car is pointing and it adjusts the entire image here's a horse where it separates the legs or the cat where it moves the face or closes the eyes a little bit it is just insane Tech like this is probably going to replace Photoshop in the future make this girl smile move her cheeks in make her look her face look thinner move her bangs up just adjust her right eye or her left eye make the shorts longer move the feet move the sleeves there is just so much crazy stuff that you can do with this technology you start with a single image and then just drag the image around until it gets to what you want it to look like it's not available for us to use right now but if we jump over to their GitHub page we can see down here code will be released in June so sometime in June we'll have access to play with this and if I had to guess we'll probably see Photoshop plugins and all sorts of tools start to add this into their workflows so that you can do this kind of manipulation with imagery again this research is called drag your Gan it's at this crazy URL here which I'll make sure is linked in the description below the video now here's some research out of Nvidia where you can manipulate somebody's hair all the way down to like the finest details you can see in this example image they've got this woman and they can manipulate almost every hair at a individual hair detail they even can trim the hair make the areas they're messing with wider and look at how realistic they can actually make the hair now I know this gives some something about Merry Vibes here but this is actually really really fascinating big research I mean the average human has over a hundred thousand hairs on their head and with technology like this you can actually get in there and adjust individual hairs and get the exact detail that you're looking for on an image this has huge implications in the gaming world as well as the visual arts and filmmaking world where you can get so fine-tuned and so granular with the images and the people that you're creating with computer Graphics also coming out of Nvidia research recently is this real-time neural appearance models this is actually really mind-blowing as well because it creates these textures on these objects that are so realistic that if you just saw this you wouldn't know that that wasn't a real object you can see that it starts as just a white 3D object and then it adds this texture over it that has the reflections and just this polish to it where even when it's zoomed in you can see all these fine details it looks like there's specks of dust and scratches is and little imperfections on it as well as the shine and the glare of the lights around it but this is just a 3D object that's being textured with Hyper realistic textures here's another example of a white object and then it's given this texture to it that makes it look like this antique artifact the level of detail that they're able to get on some of these textures is just mind-blowing again this one's called real-time neural appearance models it's put out by Nvidia research and I will link up to this research paper if you want to learn more about how this works now the next one I want to show you is called text to performer which is another one that's not available yet but the demos look pretty crazy so here's a text prompt this female is wearing a dress with solid color pattern it has no sleeves and it's of three quarter length she shifts to the right and then you can see here's the girl and then she shifts to her right but then check out this one where it actually performs a sequence of prompts the dress the person wears has medium sleeves and is of short length the texture is of Pure Color the lady moves to the left she is turning right from the front to the side she is turning right from the side to the back she turns right from the back to the side she turns right from the side to the front she moves to the right and as it goes through these prompts you can see that the text to performer actually performs these actions and this is all AI generated here it generated the person it generated the dress with medium sleeves short length and a pure colored texture and then it actually moves her in all of the directions it says here in each of these individual prompts here's another one this person is wearing a sleeveless dress it is of short length its pattern is pure color she moves to her right she's moving towards the center from the right to the side she turns right from the front to the side she turns right to the back she turns her head to the right she turns right from the back to the side she turns right from the side to the front she is swaying in place and you can see at the end she's kind of swaying in place one last example here the dress the person wears has long sleeves and is of short length it's text is Pure Color the lady moves to the right the person is moving to the center from the right she turns right from the front to the side she turns right from the side to the back and this text to performer performs all those actions this one again is not available yet but it's called text to performer and this is a research paper where I imagine we'll have demos and hugging face spaces where we can play around with this soon next up is text to Nerf and if you're not familiar with Nerf I have talked about it in previous videos it's neural Radiance Fields it's basically where you take a single image from a whole bunch of angles and then all of those images are essentially stitched together to make a 3D object well with text to Nerf you can just give a text and it will generate 3D objects here's some of the prompt examples a bedroom with a desk and it generated this 3D model of a bedroom with a desk just from that text prompt and you can see based on the movement that it is 3D and it created a sort of depth map with that text to image prompt a cozy living room a dog playing on the lawn a bonsai on the table a cabin in the woods a red sports car in the park just from a single text prop it creates this neural Radiance field which is sort of a 3D image with depth to it here's some more a locomotive at the train station it generated two different versions of this a deserted Commercial Street two different versions of it it could even do it for Artistic Styles and not realistic images an oil painting style or a unicorn in a forest or a future city in a serialism style it could even do 360 degree scenes where it's actually doing a garden and just rotating the camera 360. again the code is coming soon so this isn't one that we have access to but everything I've shown you up until now is really awesome research which is just making our AI generation capabilities so much more realistic starting with drag your Gans where you can actually manipulate an image to make it look any way that you can imagine just by dragging and dropping it around the ability to manipulate hair to to the finest details creating textures that are just ultra realistic that you would never even know that this wasn't a real video that this was a 3D object because the text string on it is just so precise and perfect text to performer where we can generate a person that actually looks the way we describe them and moves around in the way we ask them to move around just by using text prompts and text to Nerf where we can use a text prompt and actually create a 3D scene from a single text prompt that is awesome insane technology that we're going to have access to within the coming weeks or months and from somebody who likes to make creative content like 3D videos and crazy imagery I'm really really excited to get my hands on this stuff now I want to talk about some stuff that you can actually use right now so if you've ever used the tool did where you can upload an image and then add some text and make that image talk well there's actually an open source version of that now called sad talker and you can actually play around with it right now over on hugging face where where you can upload an image give it an audio prompt and it will actually animate that image to go along with the audio prompt the holidays are a time of celebrating with loved ones enjoying the festivities and muddling through Wisconsin's code this is completely free to use right now on hugging face there's a whole bunch of examples that you can see down here here's another one you can see the face moves with the voice we could even get rid of this audio here and type some text here it's not the greatest audio in the world you're probably better off uploading your own audio but you get something that looks like this hello subscribe to Matt wolf on YouTube and this is called sad talker and right now it's free to use on hugging face or if you want to install it locally so check it out I will link again to it in the description now this next one isn't actually AI at all but I just found it really really cool for video generation I don't know how long this has been around this has made this may have been around for years and years and I just now discovered it and I'm way behind which is probably most likely the case but you can actually create animations using Google Earth studio so if you jump into Google Earth Studio there's actually a few different templates you can use where you can have it animate zooming into a specific point on a map you can have it orbit a certain object on a map go from one point on a map to another point or create a spiral around a certain spot on a map or even fly to something and then orbit that thing I found this really really cool again not AI but something really really awesome for video generation so I'm about to head to the awe the augmented World Expo in Santa Clara at the Santa Clara Convention Center you can see it zoomed in on that on the map I'll just set my starting altitude as above Earth right there and you can see it just made this animation where it finds the actual Santa Clara Convention Center from zooming out from Earth now if I click check we actually have an animation editor here where I can edit this animation and add keyframes maybe when it gets to the end I want it to be sort of more of a 3D view of the convention center I can pivot it and draw it like this Frame It Up the way I like it set this as a new keyframe here and now as it zooms in it's going to zoom into that 3D version of it I just found this really cool I don't know if anybody else is as nerdy as me and finds this kind of stuff interesting but you'll probably see me use this in a few of my videos especially when I travel I can do a point A to point B and showing the sort of path that I'm traveling to go places and then probably combine it with tools like kyber to make really cool animations speaking of kyber kyber is about to release a new feature I did get early access to it but it's actually coming out May 23rd so likely by the time you're seeing this video it's either coming out tomorrow or it's already out by now and the new feature is called storyboarding so if I create a new video here I can begin with an initial image here let's start with this profile pic that I use everywhere and then I can continue to a prompt it already kind of guess what was in the image a man with a beard and blue eyes in front of a purple and blue background with a neon pattern in the style of let's go cinematic and then it automatically wrote this prompt photo taken on film film grade vintage 8K ultra fine Etc now I can move on to video settings here and I can have it make this first section be eight seconds let's have it zoom in during this section show initial image in the first frame and let's go ahead and generate a preview here I'll use this one because I like the curly mustache that it made and then what I can do is I can click this plus storyboard and add another section to it so this time let's make it a humanoid robot with circuitry and a big brain and let's have this one do in the style of 3D rendering go to video settings and this time let's have it zoom out and move down we'll go ahead and generate preview and you can see it started with that same image as the inspiration for the first image so we'll go ahead and use that and then we can even add a third storyboard if we want so let's click storyboard again this time let's go a humanoid alien with green skin and let's do it in photorealistic let's just see what happens go to video settings this time let's have it move to the left and rotate clockwise we'll generate preview and let's go ahead and create our video it's got three different scenes in it now with three different prompts and it's gonna move between the scenes it's going to change the rotation based on the settings we gave it and it's going to create something really interesting so let's go ahead and create video and now it's going to craft our Masterpiece and here's what we got out of it you can see it sort of shifts into the guy with the handlebar mustache my hair turns blue as it evolves now I start to turn into a robot and the the camera starts to zoom out as I turn into a robot for about 8 eight seconds and now it starts to rotate as I slowly turn into a green alien like the prompt that I gave it really really cool technology you can actually add music to it as well I didn't have any music queued up but that is another feature inside of kyber where you can actually add music to go along with it and again this is called kyber's storyboard feature which as of the recording isn't publicly available but as of this recording it's going to be publicly available tomorrow so there's a good chance it's ready for you very soon or possibly even now and then finally I want to talk about blockade Labs now this is a tool I have talked about in the past but they added something that is really really cool which is the ability to draw in stuff with the images you're creating now blockade Labs creates these 3D Landscapes where you can look around you can generate whatever you want but if we come down here and click create new we actually get this sort of grid where we can draw in whatever we want here so if I was to take this p paint brush tool here let's draw a little house I'll try to kind of stick with the lines as best as possible I'm already doing a horrible job at it let's go ahead and draw a little house here like this maybe even put a little chimney on it and then let's move over here let's uh draw some circles and a square and let's move over a little bit more and then over in this area I'm going to draw some lines here maybe even put a line across here see what happens and then down here let's do modern computer animation and let's type a colorful Minecraft village and click generate and it's actually going to use these lines that I drew as part of the prompt here you can see here's where those lines are that I drew it kind of put like a little building with a line across it here here's my house that I made you can see it drew it in that same area if I come around here here's the little circle that I made it made a little like orb thing here's my square that I originally Drew you could see if I hover over this area up for these guides here you can see where my original circles are you can see the green circle to the left and the square how it sort of followed that if I drag over to where these lines are here and I hover you can see there's my original lines where it followed those and if I drag over to my house over here hover over this you can see it put the house with the chimney exactly where I drew it in and it created us a nice colorful Minecraft village following my drawings I could change this prompt down here to something else let's go a futuristic cyberpunk city let's change this to cyberpunk and click generate again you can see where my original outline for my house is and now in our cyberpunk city you can see it made a sort of building here in that same shape if I move around here you can see here's where my original lines are it actually puts some buildings that kind of cross where those lines are by Circle back around over here you can see here's where my original Circle was it kind of created this big circle building and another building where I put this Square so it follows is what I drew no matter what prompt I give it you can see that it follows my drawing pretty well this blockade Labs tool is just becoming cooler and cooler you can use this for your Sky boxes for things like Unreal Engine or Unity if you're creating games if you're creating a you know a 3D video you can actually use this for your 3D World and your 3D video this is just a really really awesome tool that they keep on improving they keep on shipping new features and I'm super impressed with what these guys are doing over at blockade Labs so I wanted to show this off because this is something you can use right now and as of today as of the recording of this video it's totally free to use you can just get in here and play with it and start drawing some cool 3D worlds so that's all I got for you today just wanted to kind of have a little nerd out Fest about some of the Cool Tech that's coming out some of the Cool Tech that you can use right now if you love all of this AI stuff and you want to stay even more in the loop check out futuretools.io this is where I add all of the cool tools that I come across I curate only the best tools I'm adding a handful of new tools every single day and really I've gotten strict with the tools that I add out of all of the people that are submitting tools I only approve maybe about 10 of the tools that are submitted because I don't want all of the tools that do all the same crap you've already seen other tools do I only want to show you the cool novel tools that we haven't seen a hundred times already so it's a real good curated source of all of the latest AI tools that you could use and play with right now and I also keep this AI news page super up to date with all of the latest news in the AI space so check it all out it's over at futuretools.io if all of this is too overwhelming and you just want to stay in the loop once a week make sure you join the free newsletter every Friday I'll send you the tldr of the week of just the five coolest tools I came across a handful of news articles handful of YouTube videos and one cool way to make money with AI again it's just the grand overview of the signal versus the noise and AI so to speak for the week and it goes out every Friday you can join the newsletter over at futuretools.io and if you like this video and you want to see more videos like this in your YouTube feed give this video a like And subscribe to the channel and I'll make sure that you stay up to date with all the latest research and news and cool tutorials in the AI space I'm making videos at least three days a week so if you're subscribed to this Channel and you click the little bell to get notifications it'll make sure you stay in the loop and you never miss the latest videos thank you so much for tuning in I really really appreciate you I'll see you guys in the next video bye-bye foreign [Music]"
    }
}