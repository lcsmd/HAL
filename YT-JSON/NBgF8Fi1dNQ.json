{
    "NBgF8Fi1dNQ": {
        "title": "This AI Skill Will Put You Ahead of 98% of People",
        "thumbnail": "https://i.ytimg.com/vi/NBgF8Fi1dNQ/hqdefault.jpg",
        "author": "David Ondrej",
        "date_of_release": "2024-04-15T21:58:18Z",
        "duration": "PT30M19S",
        "view_count": "16635",
        "like_count": "741",
        "comment_count": "39",
        "description": "If you're serious about AI, and want to master Prompt Engineering, join my community: https://www.skool.com/new-society\n\nFollow me on Twitter - https://x.com/DavidOndrej1\n\nCORRECTION: The example at 14:00 isn't technically \"few shot\", as there are no specific examples in the prompt, it's simply giving the LLM more context to produce more relevant answers.\n\nPlease Subscribe.\n\nHere are the first six modules of my Prompt Engineering Masterclass.",
        "transcript": "your prompts suck most likely but that's okay because this video will fix that prompt engineering is one of the most important skills you can learn 99% of CH GPT users have no clue how to write effective proms with good promps you can drastically improve the capabilities of AI models this is a common misconception in the long RM nobody knows what will happen but in the short term AI will not take your job people who have mastered AI will so if you want to prepare for the future watch Until the End prompts are everywhere so so mastering promt engineering will help you build agents use CH gbt like a pro create amazing AI images become a better writer develop a deep understanding of AI and much much more the demand for great promt Engineers is growing rapidly every large company is currently hiring AI focused people so why not become one of them so what even is prompt engineering it's the art of Designing The Prompt or message you sent to the AI think of it as social skills but for communicating with AI you know social skills help you communicate effectively with people prompt engineering helps you communicate effectively with AI so by using the same tools and same models as everyone else you can get completely different results just by writing better PRS so module number one the must know principles give the model enough context most of you right now are not giving AI enough context therefore limiting its performance you know it cannot see inside of your head so providing enough context alone will improve llm results across the board so mistake number one people make is not providing enough context but mistake number two they make is including bunch of waffle a bunch of extra information that's irrelevant that is just as bad another mistake is not trying again don't give up after your first promp fails try again and make the next prompt better experiment as much as possible don't assume the AI can't do something just because your first attempt was unsuccessful most of the time your bad prompting is to blame not the model don't try to do everything at once in your prompts separate more complex tasks into several smaller steps just by implementing this the usefulness of the model instantly increases for the most complex and lengthy tasks consider building a team of Agents now make it visually clear this is underrated one and people don't understand why it also adds tokens in between the sections and that can help AI understand the prompt a bit more so what expert prom Engineers do is they use markdown to write their prompts I think this actually has a side effect of accessing more high quality data inside of the training data of the model formatting it properly like scientist or a researcher would do you access higher quality data at least that's my theory this is another super important part of writing great prompts especially with longer ones repetition reinforces important elements within the l&m's limited context window so every AI model has a context window and the more stuff you put in the more likely it is to forget something so when something is important when something is key just repeat it multiple times put it at the start put it in the middle put it at the end don't be afraid to repeat repeat every important part and stress that it is important several times next trick is to give the model a role this is called role playing just by assigning the model a role you can significantly improve the results so turn your model into a professional X like a I don't programmer an expert writer a senior developer whatever just make it give it a role of something of someone who would be perfect for the task you're using it for there is no reason not to do this I mean it takes zero effort Pro tip use emotional stimuli adding an emotional story or you know a reason can often trig the llm into doing things that it otherwise would just refuse to do so this tip actually comes from Benjamin Bush which is a member of our community and he was struggling to get um this to work but when he added a traumatic backstory and a crippling mental disorder to the GPT I mean it it sounds crazy but it actually did work like he spent months trying this and this was what made it work so if you're stuck on something try giving it some sort of emotional reason like this is really important to me for blah blah blah if I don't do this I might get fired something like that and you'll see the llms will do things that they otherwise would not do or they will go to a greater extent greater length to make the promise really good don't make the Alm hallucinate by writing bad prompts bad prompting can greatly increase how much the models hallucinate and give wrong information for example with multiple choice questions you know you have a question and you have like ABCD or whatever it is often better to not give the ABCD at all don't give it the choices and just have it answer without that if you tell it to pick one of the choices it often just chooses one and hallucinates and makes up reason for that uh option instead of actually reasoning for what might be the correct answer it doesn't even try to do that it just assumes one of them is correct and chooses it and then justifies it so yeah don't do this with multiple choice module number two how to implement this in your prompt now I took all these prompting principles and turned them into pre-made prompts for you here's a little teaser and you can find these below the modules in my community so if you want to access all of these pre-made prompts then make to J my community it's the first link in the description and you'll also get access to hundreds of other people who are taking AI seriously and are on The Cutting Edge which honestly is priceless so if that sounds interesting make sure to join now here is example of role playing if you don't use it you might say please help me with my health problem like my elbow hurts or something right but if you do role playing you say you are a doctor who has extensive experience in helping young athletes recover from injuries and then you uh you know describe the injury give it context and this just by giving it a role that it's a doctor with extensive experience in the area that hurts so maybe I don't know your eye hurts or whatever like you get the point you can specify it and that way the answer you get is much more relevant and much more useful to your problem here's the example of repetition right so here this is before no repetition and after you say uh here I highlighted this four prompts at once and as you can see it's right here in the rules and it's right here below so if you say twice the likelihood of it actually following that is like goes through the roof so if something is important say it at least twice in the prompt formatting so this is you know just normal formatting that's that isn't really organized or anything but this is markdown just splitting it like this could make a huge difference again not necessarily for the AI itself although it will access slightly better training quality information from the training data but this is much better for you when you're writing the prompt engineering them seeing like okay this is the task this is the information these are the rules this is the personality of the AI and you can fine tune each of them if it's just one big block of text like how can you work with that here's a example of how it can go wrong when you let the llm choose instead of having it use reasoning and try to come with the right answer so obviously um here all three answers are incorrect the correct answer is 45 and instead of actually reasoning and giving you the correct answer the AI just chooses one of them and gbt 3.5 chose 63 gbt 4 chose 57 I guess 57 is less wrong than um 63 but both are obviously completely wrong module number three the fundamentals of prompting Fus Shing equals good so F shorting means simply providing examples these can be examples of good responses or things which worked for you in the past or anything else that might be useful for the AI it is a basic concept utilized by almost all of the more complex systems which we'll touch on later in this presentation now zero shorting is the exact opposite of few shorting and zero shorting is bad it means not providing examples so provide examples were possible this is especially useful giving examples is especially useful with complex and Niche applications where there might not be enough information online or that might require the AI to really like use its reasoning capabilities so the more complex your task is the more crucial it is that you provide examples so this is a really good framework that I use if you need a fast answer go with zero shot if you need a good answer provide examples sometimes you just need a quick you know search ask shb something to explain something that's fine just type out one sentence and hit enter obviously you're not going to include a bunch of examples there but if you're working on an important task and you want the llm to perform at its best then you would include five seven 10 solid examples Chain of Thought now we're getting into the interesting Concepts so Chain of Thought makes the llm break down complex problems into a series of intermediate steps before providing the final answer so instead of tackling the problem all at once the llm has to break it down into steps and then it's much easier for it to perform well because like if you say like code Minecraft in unity that's a massive task but if you say you know your task is to code Minecraft in unity break it down into 15 smaller steps sure that is still the the same goal the goal is the same the task is the same but by breaking it down into 15 smaller steps it can focus on each of the steps at once and it's much higher like that it will reach the goal when it has to do 115 of a massive task so the key idea is to demonstrate that the intermediate steps needed to solve a problem rather than just providing the final answer right away which is much harder and the same is for a person I mean imagine you hired a new person and you give gave them a massive project like that's asking for disaster rather just give them a small like you can give them the massive project but then break it down into small tasks that they can handle right and this is the single Pro PR that's like works like magic so if you just insert this at the end of all of your prompts you will have instantly just by adding this instantly improve the capabilities of CH gbd or whatever AI you're using so let's work this out in a stepbystep way to be sure we have the right answer this alone greatly improves the capabilities of the models so why why is chain of fault important well it breaks down complexity it demystifies complex tasks by turning them into series of smaller more solvable steps it reduces the likelihood of Errors a more structured approach minimizes the chances of the models leaping into illogical conclusions and it unlocks broader applications meaning you can do more with the same model so this is why Chain of Thought is important another concept is knowledge generation prompting and this this was especially key with smaller models right and it means first generating some knowledge about the topic and then asking question so like a two splitting it into two proms you basically tell it to like write about a bunch of a topic and it writes a bunch of F and it basically loads that into the contact window and then you ask a question relevant to that and this lowers hallucination and honestly this isn't really used with the current models with the best models like gbd4 turbo or CLA 3 because llms are just that good but if you want to you know build agents with cheaper smaller llms this could still be quite useful prompt chaining is another technique it's also know also known as chain of prompt cop not to be confused with Chain of Thought and I'm going to explain the difference in a bit so you decompos a task the overall task is divided into more manageable subtask each handled by individual prompt and the the key difference is that you do it so you as the prom engineer um chain the proms in a strategic way that way you get a specific result so as the chain progresses each prompt builds upon the previous one and refines the output of the previous prompt so here is the difference between chain of F and chain of prompt that way it doesn't get too confusing chain of f is the emphasis of encouraging the llm itself to explicitly demonstrate a step-by-step reasoning process when solving a problem while chain of prompt is the FOC the focus is on the engineer on you carefully designing a sequence of prompts that is most likely going to get a great result so why is prompt chaining important well it's basically steering the llm a single prompt leaves much to chance much to interpretation prompt chaining gives you a granular control over the models thought process you can also inject knowledge so chain of prompt allows you to insert knowledge insights or instructions at specific points in the process so if you do a task you know all at once you cannot really go halfway through when when it's generating tokens like okay okay I didn't mean it like that but you can do that with chain of prompt because you can split it into multiple PRS so if a response at one step seems inaccurate you can just adjust the next step to help the model correct its course module number four level up your prompts so this is example of few shot versus zero shot I want to buy a new gaming mouse give me a recommendation and these are just some random options right but with f shot saying what you will use the mouse for the actual outputs are much more relevant to that use case and honestly like this could be the difference between buying a product that's okay you can buy a good mouse or buying the perfect Mouse for you and obviously there are much you know more important tasks than buying a new mouse but this can be applied to anywhere so just by telling it what uh giving the context and giving EX examples instead of doing zero shot you can get massively better recommendations or results with llms Chain of Thought this is without Chain of Thought GPD 3.5 struggles to answer this logical puzzle but the same model with Chain of Thought you know just by saying explain your reasoning step by step just by adding that the model can successfully Solve the Riddle now here are some examples of prom chaining so example number one detailed code review you break it down into four different problems and you can do however many problems I just asked uh I just did four that way it's not too overwhelming so provide a comprehensive analysis this is the main task a comprehensive analysis of a given code snippet and then you guide it through different proms so summar the code functionality in English is a pro one the llm does that then you start with prom two llm does that and then you do prom three on four and at the end you're much more likely to end up with a great outcome then if you try to Boom put everything at once and like hope and pray like please chgb give a good answer that's not a good strategy here's a second example for writing help Elevate writing style so this one I think most of you can use this somewhere analyze this text insert sample text identify any overused words or phrases so you know to be a good writer you don't want to overuse words too much it analyzes that and it focuses entire attention of that response on just one thing and then another prompt and another prompt and by doing this you can get you can turn your text into something much better than if you just tried to tell it five different things in a single prompt um it like it will do all of them but mediocre if you do this it will do all of them really well knowledge generation prompting so number one enhance Q&A on Niche topics smaller models often like the training data for specialized domains knowledge generation prompting is the solution right so like let's say like knitting or I guess knitting is still quite popular something like super Niche something that's like doesn't have much training data especially if if the model is small by having to generate some knowledge on that and then asking the question you can like it can completely get a different result or creative storytelling so problem smaller models that are limited let's say mistal 7B or Lama 7B struggle with generating original long form narratives and the solution with knowledge generation prompting is to prompt the model to brainstorm the plots characters stuff like that first and then feed them into next prompts to guide the development of a more complex story so that's how you can just two examples how you can use knowledge generation prompting with smaller smaller less intelligent llms module number five intermediate prompt engineering rephrase and respond ask the llm to rephrase your question and then answer this will show you whether the AI actually understands your problem so if the task is obvious like what's the weather today or you know solve like explain a concept something like that you will you would not use this but if you're trying to explain something more complicated something you know not so obvious or maybe if English is in your first language and you're not sure whether you uh explain it correctly this could be a game changer because you can see that the AI how the AI understands it and whether that is correct with your understanding and another great trick is having the AI generated question so let's say my arm hurts ask me seven questions to better assess my situation instead of saying most people would say probably my arm hurts my my arm hurts how can I make it stop hurting and like that would give such a genetic responses I mean the chances of that solving your problem is so low but if you say ask me seven questions like okay did you fall did you do any physical activities and stuff like that or how does it hurt is your bone broken and you can answer them and after you answer them the AI has much more context on giving you a useful response so sometimes you don't even you like don't even know what to tell it you don't know what context provide in that case just say ask me 10 questions about uh to better assess my situation it will do that you will answer them and then you'll get a seriously better response tree of thought now this is a fascinating concept so it's similar to Chain of Thought but a bit more advanced a bit more interesting it's a very powerful concept when combined with agents so this is a beautiful visual that explains uh the different prompting techniques on the left this is what most of you probably are doing honestly this is just input output or iio so you give an I input and the LM gets an output that's it no no really like prompt engineering techniques there the next level is chain of fa prompting so you make the llm break it into task and you get output this already is a huge Improvement what's even better though is self-consistency with Chain of Thought which means you have it do that multiple times and I'm going to explain self-consistency in a bit so don't worry but basically you have it do that multiple times and then it chooses the majority based on majority of the outcomes so let's say I don't know you have five outcomes and you have five different chats and three of them give the same answer well that is the final answer right so this is even better but the you can achieve the best results with or four and that is basically generating like a tree as you can see from the name and from the graph of different possible paths the llm can go and then you can like go get to a point that you would you otherwise would never access if you just use you know input output or Chain of Thought So the key difference between Chain of Thought and tree of thought is that Chain of Thought is linear there's only one channel as you can see like this images is beautiful there is only single like progression and there is no way to like backtrack or explore multiple different thought processes or options while TR while tree of f tree of thought can backtrack if something doesn't work and explore more ideas you can get to more unique or esoteric solutions that otherwise you would never get to with standard um you know chain of prompt or just input output also Trio often produces way better results at complex tasks but it's also harder to implement so this is like you know basically what's it call like Risk to reward or like the more you put in the more you get out and that's the same in every skill in life like the more you try like if you spend I don't know a thousand hours playing football you'll be decent but if you spend 10,000 hours playing football you might be a professional footballer or if you spend 30,000 hours you might play in the Premier League like you know the same compound in is with prom engineering if you are willing to learn the more advanced concepts you will get much better results but you have to learn them and you have to go through that initial period of being bad at it of sucking right so here is just an example of the power of tree of thought uh especially the middle chart is I think really solid you can see input output tragic results Chain of Thought already massive Improvement but tree of thought completely destroys both and this is just you know one example now let's take a look at rag or in other words retrieval augmented generation now this sounds way more complex than it actually is so don't be afraid of big words it can be overwhelming but it's actually quite easy to understand it's essentially a better version of knowledge generation prompting by feeding external information maybe from a PDF from you know a text document into the llm stuff that might be proprietary business knowledge or something like your private information that's not available on the web hopefully the llm doesn't have access to that with rag you can feed it into the relevant information into the LM and greatly enhance the results and it's used a lot in programming where it's often combined with vector and beddings from a multi-dimensional vector database where you find the best suited um like the most accurate representation the most relevant information and you feed it into the response so here are the three steps of rack number one search first the model searches the vector betabase to find K nearest neighbors or in other words the most similar results understanding secondly the model reads through the sources and analyzes them to understand them and then generation the model generates an output based on the information inside the documents so why is rag important well to change the knowledge of a model you need to retrain it and that's takes a lot of resources a lot of time a lot of money a lot of comp comp right by utilizing rack you can bypass the need for retraining for every single information for every single new piece of text new piece of data you can just feed it through Rag and limit hallucinations by doing so for much cheaper and much faster so you can have a separate agent doing each of the steps and create an efficient process of rag and most you know tools like you know Lang chain has rag um pretty sure crei as well most of them like already come with rag so oreg reasoning and Tool use and which is Art and program AED language models now I'm just going to simplify this into tool use arst tools polish programs you can you can learn these you know Advanced names but just think of it as tools basically tool usage these are systems designed to help llms deal with complex tasks that cannot be accomplished just by a language model it needs something else right so it's essentially means allowing the LM to use external tools or programs to its advantage the difference between these two is basically negligible that's why I'm just going to refer to them as tools so how do external tools work when used with llms so when the model reaches a point where a tool is needed it stops generating tokens and it calls to a tool and rewrites the prompt into a format which the tool can use which is most often Json the tool outputs a Jason response back the llm takes that and processes the answer and gives it to you in plain English so where can we find LMS with tools well CH GPT uses a bunch of tools code interpreter is one of them but some other ones are you know di free is a tool what else it has has code inter D free uh I don't even know but yeah I mean it has access to a bunch of tools oh yeah the external documents as well so like those are all tools it's the llms cannot do that itself it's tool or in other words a piece of code usually a function or multiple functions programmed that the tool that the llm can use to its Advantage so with code interpreter it can open files test code update spreadsheets do precise math and about 100 other things thanks to code and opor things that Chad GPT itself the model GPT 4 Turbo cannot do so every Advanced team of Agents use this tool by the way to achieve more things than simple LM scan perplexity another example uses several tools to quickly scrip numerous websites like Reddit Wikipedia Google stuff like that and give you relevant helpful answers which are then processed by llms the answer is processed by llms but the information is gathered by tools another concept directional stimulus prompting or DSP again the name is complicated but it's simple it's basically examples but a more subtle way more like guiding way right so it's adding a small carefully designed element called a directional stimulus to your LM prompt and this DSP concept targets the style format and direction of the response right so it suddenly nudges the model in a specific Direction without dictating the exact content uh that it should do while on the other hand you have few short learning which is providing examples where you provide concrete examples of the desired output DSP is more subtle it's more like just you know directional it's not limiting the LM as much as saying Hey I want this example so in some cases you want to give concrete examples in some cases you want to leave that a bit more open a bit more ambiguous that way the model can do its thing more freely module number six from Theory to practice so here's an example of how to implement rephrase and response right so you might say right or five of the most important steps I should take to live longer I mean it's all right problem but it's like very basic and uses like very I don't know casual language not as much scientific or professional it it will not trigger good parts of the sharing data if you instead say the same thing rephrase this question and then respond chbt rephrases it into more like professional more proper way of saying that so instead of write out five the of the most important steps I should take to live longer the rephrased better question is what are the top five ESS actions to extend lifespan and that alone will hit on more like scientific more research papers training data because just of the keywords it uses the way it's phrased so this could be really fast way of improving your prompts here's example of where directional stimulus prompting managed to do something impressive so standard prompting you just say question by the way this on top this article this input input text and reference these are uh accessible by both of the LMS you just give the prompt right here this is the only variable that changes so summarize the above article briefly in two to three sentences a very short prompt kind of lazy prompting like most people would do right but then you use directional stimulus prompting by giving it a hint so you just say Bob Barker TV blah blah blah all of this information is already in the text above but by guiding it you know giving it that directional stimulus giving it that bit of a dire bit of a hint the output is much better see like the score goes from 34 where a lot of the key information is lacking to a 48 where all of the key points were hit here is what llms look like without rag it's lacking key information about this physics competition but with rag where you give it the PDF it's able to list it out right this is example of what happens without tools right lm's like without tools are not as useful so here's jgb 3.5 struggling to answer a simple question what the weather today is in Prague but with tool usage that question is a piece of cake if the llm was truly smart it would know that in Czech Republic everybody uses Celsius to measure the temperature and it wouldn't give the answer in Fahrenheit obviously now for those of you who want to take AI seriously I would highly recommend joining the community the next two modules seven and8 which are the most advanced are exclusively available for my community members so if you really want to master prompt engineering and get access to all of the promt templates I made as well as all the other courses and workshops like on how to build and deploy AI agents or how to use chgb Pro if you want to access all of that as well as hundreds of other people on The Cutting Edge of AI consider joining it's the first link in the description"
    }
}