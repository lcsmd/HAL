{
    "jQwwLEZ2Hz8": {
        "title": "STUNNING Medical AI Agents OUTPERFORM Doctors ðŸ¤¯trained in the simulation, continuous improvement.",
        "thumbnail": "https://i.ytimg.com/vi/jQwwLEZ2Hz8/hqdefault.jpg",
        "author": "Wes Roth",
        "date_of_release": "2024-05-09T03:31:41Z",
        "duration": "PT27M44S",
        "view_count": "41003",
        "like_count": "2719",
        "comment_count": "589",
        "description": "Let The Robots Do the Work:\nhttps://www.skool.com/natural20/about\nJoin my community and classroom to learn AI and get ready for the new world.\n\n\n#ai #openai #llm \n\n\nAgent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents\nhttps://arxiv.org/abs/2405.02957\n\nhttps://www.mapeditor.org/\n\n\nEthan Mollick:\nPeople are just insulting the paper authors without reading the paper or understanding the context of the fields being discussed. They didnâ€™t ask that I tweet about them, and I didnâ€™t expect the tweet to travel so widely. Getting nasty on Twitter.\nhttps://twitter.com/emollick/status/1781868013232242978\n\n\nAutomated Social Science:\nLanguage Models as Scientist and Subjectsâˆ—\nhttps://arxiv.org/pdf/2404.11794\n\n\n\nMillions of new materials discovered with deep learning\nhttps://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/",
        "transcript": "so imagine you fall ill and go to visit the hospital but this hospital is fully run by AI agents the doctors the staffed the nurses powered by large language models like gbt 4 how do you think that would work out now I can imagine what's going through your brain you might be thinking things like malpractice lawsuit 100% fatality rate zero chance of survival right well not quite if you get nothing else out of this video just remember this doctor agents again AIS run on large language models can keep accumulating experience from both successful and unsuccessful cases sounds kind of like humans doesn't it simulation experiments show that the treatment performance of doctor agents consistently improves on various tasks the knowledge that doctor agents have acquired in agent Hospital in the simulation of a hospital is applicable to real world Medicare benchmarks right that's uh interesting isn't it after treating around 10,000 patients this would take over 2 years for doctors in the real world the evolved doctor agent achieves a state-of-the-art accuracy of 93% on a subset of the med QA data set now if you're new to this Channel at some point to understand that this isn't a fluke this is at this point we can say it's kind of a pattern and the pattern is this we are able to WR run certain AIS certain neural networks and train them in simulation in a digital environment and then were're able to extract their learning their digital brains if you will and that experience that they've achieved in simulation is applicable is useful in the real world so for example right now you're seeing this little robot this is nvidia's simulation called this is probably Isaac gim or or something they have a few different ones and then now you're seeing that same robot in the real world with various Wheels attached to his hands and feet or his hands and feet are basically Wheels it learns to do it in simulation it does it how many millions of times the simulation has the same physics as we have here in the real world it's slightly randomized here and there to make it a little bit more robust a little bit more adaptable looks like by 200 iterations it starts being able to open that door time runs a thousand times faster 10,000 times faster so you're able to train them very very rapidly and then when you take them out of the simulation they're able to very robustly perform those tasks in the real [Applause] world wow I would see that action movie but before we dive deeper into this paper we probably should touch on this little tweet so this was was posted on April 20th 2024 Ethan molik we've talked about him on this channel before excellent person to follow not a very controversial person not a very outrageous person he posts studies about AI Warden Professor studying AI Innovation and startups as a substack like a Blog with a newsletter called one useful thing and he posted a paper called automated social science language models as scientists and subjects no big deal right here's that paper MIT Harvard and the idea was pretty simple again they take large language models llm again kind of the central theme of A lot of the stuff right and they're basically asking and I'm simplifying quite a bit here they're asking can this LM can it be like a scientist can it come up with hypotheses run experiments gather data can it if you will do science again I'm simplifying please don't yell at me right so social scientist start by selecting a topic or domain to study within that domain they identify interesting outcomes and causes that might affect the outcomes these are the variables right and the proposed relationships are the hypotheses for example I have a hypothesis that your luck is greatly increased when you hit the like button and subscribe to this channel it's really improved so we can test that out by well you hitting the like button and then we'll you know go ahead and gather some data so so go go ahead and do that now right and so This Is Us designing an experiment to test these hypotheses right by inducing variations in the causes and measuring the outcomes then after designing the experiment social scientists determine how they will analyze the data then they recruit participants run the experiment and collect the data so you're the participant hit the like button then they analyze the data and estimate the relationship right so basically this is kind of the scientific method right this is how we move our understanding forward and up to very recently 100% of this this progress this process was made by humans and very recently we're seeing AI take over just a little bit here and there all right we've talked about gnome millions of new materials discovered with deep learning so this is a deep minds thing this little robot sits here creating new materials and then there's a separate sort of AI that comes up with certain potential recipes that this robot then tries to create and this what I assume is a blast proof case in case the robot messes up and you know something goes boom and here's how many materials in this case crystals right this is how many humans were able to sort of create that were stable then with various computational methods we can we had this circle which is bigger and of course this gnome or gnome right it's this big circle right so AI is advancing science already in some areas and so in this uh case basically these LM agents they create certain social scenarios hypotheses then they build the AI agents with certain relevant attributes right so for example one of the experiments was a negotiation of some sort right they designed those interactions model estimation data collection and then they run the experiment and they talk about all the things that worked well all the things that maybe didn't work so well it wasn't perfect but at the end of the day here's their conclusion we show that such simulations produce results that are highly consistent with theoretical predictions made by the relevant economic theory this could potentially allow for controlled experimentation at scale right right we can run these simulations at scale to test various things to gather data right we could yield insights that would generalize to the real world now you may be wondering well why was this controversial what what was the controversial piece of this whole thing well this this was it now I caught a portion of this as it was happening people basically would come into the thread and they got very nasty they did not like this idea of collecting data in a simulation they didn't like the idea of large language models potentially contributing to science and they weren't very nice about it so Ethan mik says yeah he's going to delete that thread people are just insulting the paper authors without reading the paper or understanding the context of the fields being discussed they a meaning the authors didn't ask that I tweet about them and didn't expect the Tweet to travel so widely getting nasty on Twitter now again I saw a little bit of it I'm not sure exactly what got people so riled up but having talked about some of these topics on YouTube I know firsthand that there's some small but very vocal minority of people that go into this murderous rage when you suggest that large language models have some ability to reason to understand to have World models and they usually don't have something that can be called arguments that show why they think what they think it's mostly just insults and getting nasty and yeah so I had a lot of misgivings about talking about this paper on one hand I'm very busy because I'm launching my course on how to build AI agents it's going very well we're up to almost a thousand people it's been live for just a few days check out the links down below if you're interested so on one hand I don't have too much time to delve into this if you will but on the other hand talking about this new paper would probably make a lot of those nasty emotional people very very mad which I just cannot say no to so today let's talk about agent Hospital a Similac room of hospital with evolvable medical agents yes AI agents that think reason learn and evolve and there's nothing you just stop it let's get started all right so this is kind of like their main overview of what this Hospital looks like so they're saying this is an overview of agent hospital it is a Similac of Hospital in which patients nurses and doctors are autonomous agents powered by large language models agent Hospital simulates the whole closed cycle of treating a patient's illness disease onset triage registration consultation medical examination diagnosis medical dispensary convalescence and post Hospital follow-up visit and interesting finding is that the doctor agents can keep improving treatment performance over time without manually labeled data so this is kind of the big deal normally when we train AI we need lots of data so for example if we're training an AI that recognizes pictures of animals we need lots of pictures of animals with you know labels they call it data pairs right so a picture of a dog and then along with that something that says this is a dog and you know many many of those so they can kind of generalize how dogs what they look like so a million pictures of dogs that are labeled dog you know I think in this case since they're talking about Dermatology right so let's say it's some sort of a skin condition I don't know some rash right so maybe there's a bunch of pictures of this rash that's labeled with the name of that particular condition right that's normally how we we do it but here it seems like in the simulation these doctors these AIS is keep learning keep improving without manually labeled data so without human medical professionals sitting there and pouring over data and labeling it making sure it's correct you can say that they generate their own synthetic data within the simulation and then learn and improve from that data the central goal of this paper is to enable a doctor agent to learn how to treat illnesses within the simulacrum they're proposing a method called Med Agent Zero so here's kind of a map that they've built you know looks like this is the entrance right you have the registration window Pharmacy waiting area the triage station biochemical testing room etc etc looks like they've used this tiled map editor. org to build out some of the stuff I got to say I'm very excited about the intersection of video games and AI specifically AI agents I mean the fact that we can use generative AI to voice dialogue create dialogue all that stuff that's cool but something about having actual autonomous agents running around in games and affecting the gameplay world I got to say that's that's making me very excited and looks like they also use this phaser.io a fast free and fun open source framework for various uh browser games so I guess here's kind of what that looks like so they use something like that to build this right so this is a hospital sandbox simulation environment tile and phaser titled is a map designning tool phaser is a framework to manage the movements and interactions of the agents on the sandbox and then they create the various agents and the information about the roles of these agents is generated using GPT 3.5 so I think they're just using GPT 3.5 just for you know kind of generating the background for these people I hope they're not using it for the doctors can you imagine going to a hospital and the doctors running on like gbt 3. 5 you would walk right out right it's a little llm joke for you there and so they greet a series of medical professional agents including 14 doctors and four nurses doctors diagnose diseases and create treatment plans whereas nurse agents folks on triage supporting the day-to-day therapeutic interventions so here's example agents so we have a radiologist his duty spelled out skills Etc then we have a patient internal medicine doctor and a receptionist if they're running on GPT 4 I'd be curious to know how much this whole experiment cost I believe the staford experiment the social simac we've covered on this channel kind of had a similar thing but there it wasn't even a hospital it was just a little village where people went around their business and tried to organize a party I think that one blew through thousands of dollars of open AI API credits so planning we've covered how to approach these agentic planning how to create planning architectures for AG agents in that Stanford simulation so the interesting thing there they don't go into as much detail about planning as I think they did in the Stanford paper there the trick was starting very broadly with the entire day right so kind of like what are the big rocks in the day that's the first thing you ask you know Chad GPT this llm and then you kind of keep fine-tuning it like okay so then break it down by every hour then every half hour then you know every 15 minute intervals Etc so here these uh patients in this case right they have their daily planning and dynamic planning all right so upon arrival at the hospital they'll go to the triage station and then based on what happens there their actions and movements will follow based you know what happens there if they tell them oh we got to get you into urgent care or whatever they go there so here this person gets sick km goes to the hospital at the front desk a triage I guess this means registration they head over to registration and then into consultation then into Medical examination diagnosis then to the medical dispensary convalescence and then there's this arrow pointing back to the disease starts over again which which this sounds like a nightmare if it just an endless loop but okay in planning for the medical professionals they just kind of fulfill their responsibilities based on their designated role and they're trained from two types of actions one is practice so actually dealing with the patients giving them care as patients are assigned to them during their shift and the follow-up information from patients that will help them polish their medical records experience and the second part of their kind of learning or planning aspect is actually learning outside of working hours they engage in studying past medical records to gain clinical experience reading medical textbooks to expand their knowledge it's this idea that a large language model right this soulless machine if you will sits there in simulation reading a book in its off time when it's not working and is able to expand their knowledge to improve their results from reading a book I mean to me that's very exciting that's very interesting to think about but I think this is where a lot of people get uncomfortable which by the way if you're one of those people I'd love to know more what is it that is so disturbing about this idea because again there seems to be a lot of anger directed at the people that are talking about this so we won't cover a lot of the stuff but I do encourage people to read the paper but let's focus on the core things here so the Evolution right so the Improvement of these agents they propos their kind of framework their strategy Med Agent Zero and there are two important sort of areas modules in this strategy the medical record library and the experience base successful cases which are to be used as reference for future medical interventions are compiled and stored in the medical record library for cases where treatment fails doctors are tasked to reflect and analyze the reasons you know why they failed and dis still a guiding principle to be used as a cautionary reminder for subsequent treatment processes so here's kind of their Med Agent Zero method right so you have the patient query so the doctor can use medical record retrieval prompting so AKA asking the patient experience retrieval then it looks like the medical agents the doctors generate an answer so I'm assuming this is their diagnosis right is it correct is it not correct and here we have kind of the golden answer meaning this is the the truth kind of the the ground truth like this is what we know to be the true answer so if somebody comes in with you know disease X right we make sure that the doctor comes up with that if the doctor says something else we say no that's incorrect and then the doctor goes into the reflection mode thinking about it again as they say here distill a guiding principle to be used as a cautionary reminder for you know further treatment right if the answer is correct right the we know that that's the case for that uh Hospital patient so we add that to the medical records Library again to be used in the future if they come in were able to retrieve it and say oh you know you had this in the past right and then if they don't get it correct and after reflection right after thinking about it they attempt to reans it right if they get it wrong again we abort it right so it looks like they're just not getting it but if they answer correctly on the second try that gets added to the validated experience to the experience base and I got to say this is similar to probably how the human learning process is probably everything except the fact that there's probably no golden answer there's no absolute truth that we can compare it to usually also if you're wrong twice we don't just pull the plug on you but other than that this is very lifelike and so this process builds the record Library The Experience base keeps expanding the more patients are treated and so the way those records are built so they use uh text embedding into Vector Space by this embedding uh model provided by opene so basically how llms store data isn't in text format how you and I would they use something called Vector space I think the easiest way to kind of visualize that of these little 3D charts where each word has a set of traits and then based on those traits you can kind of visualize it in a 3D environment so if you're looking for a cluster of words for example that have kind of similar meaning or similar tone or whatever you can kind of organize it like this so here's kind of one that's showing the different directions of like Sky wings and engine right so a helicopter drone and Rocket would kind of be in this space whereas a goose Eagle B would be in this space so all things with these characteristics would kind of be in that same Vector space which is interesting to think about because I feel like kids when they're learning to speak English or whatever language they're learning you can kind of think of it as them using something similar to this they learn the meanings of words by kind of contrasting them to the other words that they know right there are these clustering of words whether it's words there are opposites or words there are groups all that is to say that I don't think that the fact that llm aai agents act kind of humanlike at the end of the day I don't I don't think that's an accident and the point here from the experimental results is that after they keep training on 10,000 samples 10,000 patients they show a continuous Improvement a continuous increase so as you can see here there's a rapid increase in Precision right so there's like this rapid increase up to maybe 2,000 training samples I mean it it continuously increases from there on but I mean there's a little bit of a diminishing returns but the point is they keep improving they keep learning and yeah it does seem like they're using GPT 3.5 for this because probably GPT 4 it would be I mean 10,000 patients however many the 14 doctors or however many they had I mean that would cost a lot of money so keep in mind that if they just substituted gp4 for this the results would likely be even better here's the breakdown of various diseases how old they're able to figure out what those are yeah for some of these I mean they start out at like 20% accuracy or 40 or 60% accuracy and then over time like on this one this has got to be around 90% accuracy so there's an obvious learning proc process that happens all right so they used both GPT 3.5 and GPT 4 so I apologize if it was a little bit unclear to me which one they used they used both and as you can see here they compared it to just prompting these models for the answer and this these were the results they use Chain of Thought as well as these other sort of approaches these methods for testing them but Med Agent Zero which is this paper that we've covering so training them in a simulation with 10,000 iterations 10,000 patients I mean both GPT 3.5 and GPT 4 beat out all the other ways of using that model so they are the number one GPT 4 comes in at 93% which outperforms human experts in the med QA data set which humans experts are around 87% so gbt 3.5 approaches a medical professional on that data set GPT 4 beats them by quite a bit 87% versus 93 also keep in mind they can run the simulation a lot faster right 10,000 patients I mean it would take a doctor many years to accumulate that much experience here that could be ran pretty rapidly and every year you'd be able to run it faster and faster as technology improves as both hardware and software and these neural Nets improve as well so if you enjoyed this please hit thumbs up to get this out to more people if this bothers you tell me why I am genuinely curious because I keep seeing this pop up and and it's just not just me on my YouTube channel but obviously even respected professors and researchers that post their work on Twitter and actually here I found one comment that actually so once once Ethan mik deleted the original tweet a lot of those kind of really negative responses uh disappeared but here's one that from what I've seen cuz I briefly went into that rabbit hole of that uh thread and I think this is kind of Representative of what was said so I think this person kind of captures the complaint but just imagine this but much nastier and attacking people personally so he's saying to be fair you kind of casually post Ultra dystopian stuff and are like isn't this Tech so cool smartman in your area but you seem not detached from the world a bit maybe maybe he me you seem too detached from the world a bit if you didn't see this coming at some point so again I I really think this is really representative of what the people were saying and you know on this channel I Tred to be unbiased and try to understand a lot of different perspectives or at least be open-minded to it and so I wouldn't understand this but I just don't so he's saying that studies like this are Ultra dystopian I don't even understand why would it be ultra dystopian accelerating progress by the use of machines improving our ability to understand the world around us improving our technology improving our ability to help people that are sick to diagnose right maybe potentially have ai doctors that can help people without resources there's many places in the world where there's poverty there's no doctors there's no access to highquality Medical Care what if these trained AI agents could help people you know for for pennies to at least get a correct diagnosis how's that dystopian I almost feel like Ultra dystopia would be if we outlawed this technology that we didn't allow Humanity to benefit from what it could bring to the world because that would benefit the people that already have everything that they need if somebody said that would be ultra dystopian I could agree that would be but this I just don't understand I also notice how and and a lot of these comments have that in common you know they do tend to get personal like there's personal attacks I mean here they're saying well you're detach from the world if you didn't see this coming you may be smart over here but you're kind of Clueless over here and that's what a lot of these comments had in general they're not saying I disagree with what you're saying and here's a respectful breakdown of some points that I disagree with you with most of them were like you're wrong and you're clueless and you're a horrible person that was the kind of combination of those things which again I have a hard time grasping where that's coming from and we've covered uh Sam mman talking yesterday to the kids at MIT because it does seem like he's getting a lot of this from this is kind of sad from from these college students at these Elite universities or at least some subset of them right and he posted this I think as a response to that so just the timelight fits to where I think he was talking about what he experienced during his college tours talking to the students at Stanford and MIT Etc he's saying using technology to create abundance intelligence energy longevity whatever will not solve all problems it will not magically make everyone happy but it is an unequivocally great thing to do and expands our option space to me it feels like a moral imperative and at the bottom here he's saying his most surprising takeaway from the recent college visits that this what he said above there is a surprisingly controversial opinion with certain demographics and again I mean on this channel even you can go back like a year see some of those videos I did about GPT 4 reasoning where I talk about specifically this me dealing with this where you cover some cool new AI breakthrough that seems to be very beneficial and move science forward and it's surprisingly controversial yeah with certain demographics it's it's a minority of people but they're really incensed about it he says Prosperity is a good thing actually d d growth well that's it for me for today if you've enjoyed the stuff here on this channel and would like to join me in my quest to build the biggest and most valuable private Forum where we can talk about AI how to build autonomous AI agents or we can all upskill and learn to use AI to prepare for what's coming in the future I've launched a natural 20 I'll put the links down in the descrip description we're almost thousand strong join us won't you let's build it together my name is Wes rth and thank you for watching"
    }
}