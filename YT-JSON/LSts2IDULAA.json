{
    "LSts2IDULAA": {
        "title": "Agents cannot be stopped, Experts say",
        "thumbnail": "https://i.ytimg.com/vi/LSts2IDULAA/hqdefault.jpg",
        "author": "David Ondrej",
        "date_of_release": "2024-04-01T21:11:19Z",
        "duration": "PT11M29S",
        "view_count": "17481",
        "like_count": "553",
        "comment_count": "63",
        "description": "Don't watch the AI Revolution from the sidelines. Be part of it. Act now and join us: https://www.skool.com/new-society\n\nFollow me on Twitter - https://x.com/DavidOndrej1\n\nPlease Subscribe.\n\nCredits:\n\ndescribe the video in 1-2 sentences",
        "transcript": "AI agents are going to change the world at least that's what the most elite AI experts think I'm talking about people like Andre karafi co-founder of open AI Andrew Ang the creator of Google brain Arthur MCH the CEO of mistal AI and Harrison chase the founder of L chain I went through all of their speeches and compiled the most interesting and valuable Parts into this single video enjoy oh and a huge shout out to seoa for holding such an awesome AI event at a high level it's using a language model to interact with the external world in in a variety of forms um and and so tool usage memory planning taking actions is kind of the high level gist today agents are A New Concept however that will quickly change in 5 years everyone will know how to build agents meaning we now have a unique opportunity to be the early adopters of this technology human language that potentially at some point the developer becomes the user and so we're evolving toward any user being able to create its own assistant or its own autonomous agent I'm pretty sure that in 5 years from now this will be like something that you learn to do at school here is why everyone including yourself have to pay attention to AI agents I'm looking forward to sharing with all of you what I'm seeing with AI agents which I think is the exciting Trend that I think everyone building an AI should pay attention to guys Andrew in the greatest educator in the history of AI just told you that everyone needs to be paid paying attention to agents now building your first agent can be intimidating that's why I created an entire workshop on how to build and deploy AI agents which is available inside of my community so if you want to be among the early adopters make sure to join for this link in the description and the simple form of this you can maybe think of as just running an llm in a for Loop so you ask the llm what to do you then go execute that and then you ask it what to do again and then you keep on doing that until it decides it's done now here is a beautiful explanation of why the entire AI field is headed towards agents we are evolving toward more and more autonomous agents we can do more and more tasks I think the way we work is going to be changed profoundly and making such agents and assistance is going to be easier and easier one of the most fascinating breakthroughs is that with agents you can actually make GPT 3.5 smarter and more useful than even GPT 4 this also means that with proper flow engineering you could today create agents that perform just as well as GPT 5 will but more on that later so it turns out that if you use GPT 3.5 uh zero shot prompting it gets it 48% right uh gbd4 way better 67 7% right but if you take an agentic workflow and wrap it around GPT 3.5 say it actually does better than even GPT 4 and you notice that GPT 3.5 with an agentic workflow actually outperforms gp4 and and this means that this a sign consequences fighting how we all approach building applications when you're trying to build agents you have to understand that they are fundamentally different from humans what might be hard for an AI agent could be trivial for us and vice versa and Andre kPa thinks that this is actually a flaw in the model architecture itself the problem is that the human psychology is different from the model psychology what's easy or hard for the human are different to what's easy or hard for the model and so human kind of fills out some kind of a trace that like comes to the solution but like some parts of that are trivial to the model and some parts of that are massive leap that the model doesn't understand you're kind of just like losing it and then everything else is polluted by that later the model needs to practice itself another kind of like aspect of this is just the importance of basically flow engineering and so this term I heard come out of this paper Alpha codium it basically achieves state-of-the-art kind of like coding performance not necessarily through better models or better prompting strategies but through better flow engineer ing so explicitly designing this uh kind of like graph or or or state machine type thing and I think one way to think about this is you're actually offloading the planning of what to do to the human Engineers who are doing that at the beginning and then one other important Trend fast token generation is important because with these agented workflows we're iterating over and over so the LM is generating tokens for the elm to read so be able to generate tokens way faster than than any human to read is fantastic and I think that um generating more tokens really quickly from even a slightly lower quality LM might give good results compared to slower tokens from a betm maybe it's a little bit controversial uh so I think that's roughly where it's headed is we can bring up and down these relatively uh you know self-contained agents that we can give Tas to and specialize in various ways so and it's not just one agent it's many agents and what does that look like the basic idea here is that if you think about running the llm in a for Loop often times there's multiple steps that it needs to take and so when you're running it in a for Loop you're asking it implicitly to kind of reason and plan about what the best next step is see the observation and then kind of like resume from there and think about the what the what the next best step is right after that right now at the moment language models aren't really good enough to kind of do that reliably and so we see a lot of external uh papers and external prompting strategies kind of like enforcing planning in in some method whether this be uh planning steps explicitly upfront um or reflection steps at the end to see if it's kind of like done everything correctly as as it should I think the interesting thing here thinking about the future is whether these types of prompting strategies and these types of like cognitive architectures continue to be things that developers are building or whether they get built into the model apis as we heard Sam talk a little bit about our bet is that uh basically the platform and the infrastructure uh of int of artificial intelligence will be open yeah and based on that we'll be able to create assistance and then potentially autonomous agent and we believe that we can become this platform by being the most open platform out there agents the theer has been tossed around a lot there's a lot of consultant reports talk about agents the future of AI blah blah blah I want to be a bit concrete and share of you um the broad design patterns I'm seeing in agents reflection is a tool that I think many of us just use it just works uh to use I think it's more widely appreciated but actually works pretty well I think of the has pretty robust Technologies when I use them I can you know almost always get them to work well um planning and multi-agent collaboration I think is more emerging when I use them sometimes my mind is blown for how well they work but at least at this moment in time I don't feel like I can always get them to work reliably the next thing that I want to talk about is the ux of a lot of agent applications this is actually one area I'm really excited about I don't think we've kind of nailed the the right way to interact with these agent applications I think uh human in the loop is kind of still necessary because they're not super reliable but if it's in the loop too much then it's not actually doing that much useful thing so there's kind of like a weird balance there one ux thing that I really like uh from from Devin um and and and Jordan B kind of like uh put this nicely on Twitter is is the presence of like a rewind and edit ability so you can basically go back to a point in time where the edit or where the agent was and then edit what it did or edit the state that it's in so that it can make a more informed decision and I think this brings a little bit more reliability but at the same time kind of like steering ability to the agents and speaking of kind of like steering ability honestly the path to AGI feels like a journey rather than a destination but I think this typ of agent workflows could help us take a small step forward on this very long journey the the last thing I want to talk about is the memory of of Agents like interacting with the bot and kind of like teaching it what to do and correcting it and so this is an example where I'm teaching um in a chat setting an AI to kind of like write a tweet in a specific style and so you can see that I'm just correcting it in natural language to get to a style that I want the next time I go back to this application it it remembers the style that I want but I can keep on editing it and so this I would kind of classify as kind of like procedural memory so it's remembering the correct way to do something I think another really important aspect is is basically personalized memory so remembering facts about a human that you might not necessarily use to to do something more correctly but you might use to make the experience kind of like more personalized um so this is an example kind of like journaling app and you can see that I mentioned that I went to a cooking class and it remembers that I like Italian food and so I think bringing in these kind of like personalized aspects um whether it be procedural or or kind of like these personalized facts will be really important for the next generation of Agents we're really focusing on the developer first uh but there's many um like the the frontier is pretty thin in between developers and users for this technology and so that's the reason why we released like a an assistant demonstrator called lha the point here is to expose it to Enterprises as well and that answers some some need from our customers that many of of the people we've been talking to uh are willing to adopt the technology but they need an entry point and if you just give them apis they're going to say okay but I need an integrator and then if you don't have an integrator at end and often times this is the case it's good if you have like an off the shelf solution at least you get them into the technology and show them what they could build for their core business so that's the reason why we now have like two product offerings the first one which is the platform and then we have L uh which should evolve into an Enterprise of the Shelf solution I expect that set the Tas AI can do will expand dramatically this year uh because of agentic workflows um and candly I'm really looking forward to CL 5 and uh Cloud 4 and gb5 and Gemini 2.0 and all these other wonderful models in minor building and part of me feels like if you're looking forward to running your thing on gb5 zero shot you know you may really get closer to that level of performance on some applications than you might think with agenting reasoning um but on an early model and and just one of design pattern it turns out that multi-agent debate where you have different agents you know for example it could be have ch GPT and Gemini debate each other that actually results in better performance as well so having multiple simulated air agents work together has been a powerful design pattern as well"
    }
}