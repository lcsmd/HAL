{
    "38jlvmBdBrU": {
        "title": "Finally Ollama has an OpenAI compatible API",
        "thumbnail": "https://i.ytimg.com/vi/38jlvmBdBrU/hqdefault.jpg",
        "author": "Matt Williams",
        "date_of_release": "2024-02-10T01:11:45Z",
        "duration": "PT10M47S",
        "view_count": "16811",
        "like_count": "715",
        "comment_count": "92",
        "description": "A user-contributed PR brings us an OpenAI API to Ollama.\n\nBe sure to sign up to my monthly newsletter at https://technovangelist.com/newsletter\n\nAnd if interested in supporting me, sign up for my patreon at https://patreon.com/technovangelist",
        "transcript": "open AI heard of them they have this AI product that's kind of popular maybe you heard of that chat GPT well they have an API for others to use to leverage open AI products it's not the best API to use but it's there and it's pretty popular if you've been using olama for any amount a time you know there's an AMA Discord and if there is one question that is more frequently Asked than any other it would have to be no question not even close it's why is there only one freaking channel on this server but this isn't that video if you look at the second most popular question of all time again it's so obvious you only have to be in Discord for 30 seconds it's about why is my GPU not being used again wrong video for that question but the third most popular question is absolutely unequivocally where is open AI API compatibility people don't even know what it means and they want it well as of this release of 0.124 it is right there for you to use nothing special for you to turn on now there are some features that aren't available yet but for most folks it'll just work so does that mean that folks who spent the time adding AMA to their product just wasted the equivalent of a few blueys no but Bluey is pretty awesome even if us Americans don't get to watch the pregnant Dad episode what else is in this release not much it really is all about open AI not that I don't appreciate E's pointer to LM olama or M raiser's Cuda country cont contribution but let's talk open AI so this has API in the name of the feature but let's start the opposite point of view the end user who is working with chat GPT for their regular jobby job I'm on a Mac so I did a search for regular client tools that use open AI in some form or another and do not support AMA at first I was going to use obsidian but it seems that most of the tools either support AMA now or don't have a way to add a custom URL now why is adding a custom URL important for chat gbt well if you are a company and the very real privacy and security issues with chat gbt scare you then you can host the service yourself on your Azure environment and then you probably want your users to use that service so that your company Secrets don't get discovered by a reporter like what happened to Samsung I found a cool tool called mmac This is a super slick tool and I think I may consider buying it but when I first tried it I could have sworn that ama wasn't in the supported list so I set up AMA as if it were open Ai and then when I started scripting this script I saw that olama was in the supported list so less useful for me for for this video well then I found chat wizard on GitHub and got it installed this works great with chat gbt but it has no idea what oama is if you come into settings you can see a place to put in a URL at first I put in HTTP logo host Port 11434 slv1 as per the olama release announcement but this didn't work thankfully I can use the olama debug environment variable to figure out what's going on there you see that it says slv1 slv1 okay so go back into settings and remove the V1 from the URL now before I knew you could add a model I just did an olama CP new Hermes mix roll to GPT 3.5 turbo tricking the system to think it was really on open Ai and that works but it turns out you can add a model in the um uh you know in ice block view just enter a model name and then you can define a cost if you like there's no checking that the model exists so be careful here then the model just works in the chat check this out pretty nice huh now let's change gears a bit and get a little bit more technical a little closer to the developer Persona autogen Studio this is a pretty cool app from the folks at Microsoft that brought us autogen the idea of autogen is to make it super easy to build agents that will do things for you using the power of AI this gets more powerful when you combine the agents to work together on your tasks autogen and autogen Studio work with the open AI API autogen is a purely developer product while studio is a web guey that's a t more friendly it has been popular to use orama with these according to the posts in the Discord but to do so you have to use light llm in the middle and I think you might even have to set up a web server well you used to have to do that now you can just use olama directly once you get autogen Studio installed and up and running which is easier said than done because it's python go to build and then the models Tab and then click the green new model button enter a model name I'll use dolphin mistol and then the API key something has to go in here but I don't think it really matters what then there's the base URL the default to go here is HTP localhost Port 11434 and that's it try out the Model H well okay well it failed okay let's add the slv1 to the URL try again and H there we go from here you can create skills which are specific activities you want your agent to do this could be search the internet or search a database or parse a file or well whatever these skills are written in Python so there is almost no limit to what you can do and then you create agents that have a system message a model and possibly some of the skills defined then finally a workflow that orchestrates the different agents to do some sort of complex task let's just use one of the examples the general agent workflow and have it run through the sinewave example now this takes a minute or two on my machine but while it's working we can verify its running by checking out the olama logs as well as the autogen logs this example is right wrting a python script it's simple so any of the common models should handle it but for more complex tasks perhaps a larger more specific model is required or if your workflow is quering a database using a skill and then interpreting that to English or another language maybe a super lean and fast model is the approach to take this is super cool but there's probably a warning somewhere not to do this on your local machine it's creating code and running it without your input so it could do a lot on its own now I am not worried that this is Skynet or bringing on the Doom of AGI but maybe it could wipe out your entire machine that's probably why Docker is recommended for the python environment I might actually spin up a new machine on brev to secure it I think it would be great to be able to cover autogen in more detail in the future let me know in the comments if that is interesting to you finally let's look at going one level deeper you are now a full-on developer so we need to open vs code and now go to it oh well maybe we need some help so let's look at open ai's developer site I'll go to chat and here's a code sample ready for us to try back to vs code and I want to use Dino for this one so I'll do a quick Dino in it which creates the main.ts file and and doo. Json files and then I'll replace the existing code with the code Temple from open AI Dino has a different way of dealing with packages so to use a regular npm package just throw npm colon at the beginning of the import now we need to update the Constructor first an API key I'll just set this to a llama and next is the base URL and that's going to be logo host and the port slv1 that should be all we need so we can run it when you use Dino you need to be intentional about the resources used so Dino Run allow net main.ts and there is our message from AMA and we can watch the logs to ensure that it really is olama running this open Ai call to make it a little more pretty we can just print out the message content so we have seen the new open AI API compatibility in ama and we saw it from three different perspectives a user a power user and a Dev I think this is pretty cool using the olama API directly is going to be easier more performant and generally better but especially with the official JS and python libraries as well as you know all the community created libraries for for rust and Ruby and and R and Swift and so many others but if there's an existing tool that uses the open AI API today and lets you set the base URL then this is is going to be super powerful for you let me know if there's anything else you'd like to see on this channel it seems that a lot of you have been subscribing to the channel and I love every single one of those subs it is so exciting to watch how many of you are interested in me creating more videos so keep it up and thank you so much for doing that and thanks so much for watching this one goodbye ah"
    }
}