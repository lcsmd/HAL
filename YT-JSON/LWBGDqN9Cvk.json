{
    "LWBGDqN9Cvk": {
        "title": "Hugging Face Agents ‚Äî Building Custom Tools",
        "thumbnail": "https://i.ytimg.com/vi/LWBGDqN9Cvk/hqdefault.jpg",
        "author": "James Briggs",
        "date_of_release": "2023-05-25T14:30:10Z",
        "duration": "PT11M12S",
        "view_count": "8523",
        "like_count": "228",
        "comment_count": "24",
        "description": "Hugging Face's new Agents framework allows us to build advanced LLM and chatbot agents. Using these agents we can use LLMs like gpt-3.5-turbo and gpt-4 and allow them access to all of Hugging Face's library of models enabling multi-modality, image generation, and more.\n\nOne key component of the library is the ability to create custom tools for our agents, expanding their capabilities. In this video, we'll see how to do that.\n\nüìå Notebook:\nhttps://github.com/pinecone-io/examples/blob/master/learn/generation/hugging-face/agents/hf-custom-tools.ipynb\n\nüå≤ Subscribe for Latest Articles and Videos:\nhttps://www.pinecone.io/newsletter-signup/\n\nüëãüèº AI Consulting:\nhttps://aurelio.ai\n\nüëæ Discord:\nhttps://discord.gg/c5QtDB9RAP\n\nTwitter: https://twitter.com/jamescalam\nLinkedIn: https://www.linkedin.com/in/jamescalam/\n\n00:00 Custom Hugging Face Agents\n00:10 Hugging Face Custom Tools Setup\n02:58 How Agents Work in Hugging Face\n03:55 Building Custom Tools\n07:34 Keeping Agent Toolbox Organized\n10:02 Final Thoughts on Agents and Tools\n\n#nlp #artificialintelligence #openai #huggingface",
        "transcript": "today we're going to be taking another look at hugging face agents this time we're going to focus on how we can actually build our own custom tools for these agents to use so we're going to work through this notebook here there will be a link near the top of the video right now for this and you can just follow along as we as we go through it one thing before we do start is we're going to be running transforming models locally and diffusion models as well so to speed that up we can go to runtime change runtime type make sure you have GPU as your Hardware accelerator for this walkthrough you can use the free version of colab you just select GPU the base GPU will work for this so we save that and then all we need to do is run the PIP installs up here so we've got Transformers the fuses because we're one of the examples includes a image generation and also accelerate so that just Optimum sizes the way that we use our GPU and also open AI because we're going to use open ai's GPT 3.5 turbo model as like the the controller or the agent itself okay so we run those and then you'd also want to run this as well so we're importing the open AI agent is also a hooking face agent which uses hook and face endpoints to give us access to the hugging face sword models or the models on the hook and face Hub we can also use that but it's actually easy to just use open Ai and also cheaper to use open AI at the moment until they build out the functionality to use local LMS so yeah we run that you'll need your openai API key which you can get from platform Dot openai.com and after you run that it's just going to download some tool configurations here so obviously hunger face agents it is using a set of tools so that is why it's downloading those for and then what we're going to do is just run this so we're going to make sure this is actually um initialized and working so first time you run these it's always going to download the models that it needs to run the the tools that the agent will be using so we do have to wait a little while the first time but then after running it the first time we can run it again and it'll be a much faster okay and not downloading and running the process we get this image of a boat in the water we can try running it again and this time it will be much faster so we run that okay that processes and we should get our image there we go all right so that was 12 seconds so it's fairly takes a little bit of time but it's obviously much faster than downloading everything every time okay now what we've just done is use the default agent with all the default tools that come with it and there are quite a few of those and we can actually see them by printing out the agent toolbars okay so we can see there's this document QA image captioner image QA image segmenter all these other things and you can see the details of those tools in there as well now for the default tools they are defined as pre-tool objects okay so we can we can see all that in there it tells you what this task is for it gives you a description of the tool and this is actually used by the agent this description in order to decide which tool to use so that is actually very important and it's not just for us it's actually for the model I can't even see there's actually quite a few in there I'm not sure how many exactly but there are a few so what we can do is actually Define our own tools just like these okay and then we just add them to the agent toolbox and then the agent can actually use that tool and naturally being able to build our own tools for these agents to use makes what these agents can do in scope and much broader we can kind of anything we program we can almost do with an agent which is is pretty cool and obviously if we're building tools or you know use cases with these agents it's something that I think the vast majority of use cases are probably going to need so all I want to do is just show you how to build a really simple tools I mean nothing complicated but it just kind of shows the format or the structure of what a tool must be so for that we have this meaning of life tool uh you can see here right we have this task we have a description and we have a similar but not exactly the same format here so in this case we actually have a name and these uh if I okay so the name is actually this here so it's a key within that dictionary so they do still have that name it's just not within the pre-tool object here so we have a name and then we have the description just like what we see here and this description like I mentioned before it's for the large language model it's not for us to understand although if we can understand what this tool does is probably a good indication that the large language model should understand as well but when we're writing these descriptions the most important thing to understand or to consider is that it needs to be really concise and very specific on what the tool does right just very simple language make it very clear okay so we have our description and then we also want to specify inputs and outputs of the tool so the input format is just some text and the output format is actually just some text as well so we specify that and then we have the call method here so every every tool when you when the agent refers to that tool for help this is what it's going to be called okay so in here you would write some code usually to process whatever it is you're doing here right in this case we're just doing something really simple we're going to return the string 42. okay so whenever the user asks something like what is the meaning of life or some other broad unanswerable question we're going to return 42 and after we've initialized that tool what we're going to do is re-initialize our agent with this meaning of life tool okay so we have these additional tools and we just passed in that that meaning of life tool so let's run that actually did I run this okay run this first and then run this cool and then we can say okay what is the meaning of life and we can see this explanation from the agent so it explains it's going to use this meaning of life tool to find the answers to the question the code that it generates is this so it goes to the meaning of life tool and it passes in this query what is the meaning of life and it then prints out the answer okay so the answer is 42 okay perfect now one other thing that we should just kind of cover here is that right now there are a lot of tools that are attached to our agent okay so if we just print all those out and we have all of these pre-tools so it's 14 pre-tools in total and then we have our meaning of life tool at the end now in some use cases maybe you do want all of these pre-tools but I think in most we would probably want to Define which tools are open to be used by the model right because chat Bots tend to work better if you restrict their scope and in order for the agent to use these tools all of these tools and their descriptions are passed into every prompt we send to the LM and if we and I mean there there were a lot of there's a lot of text here right all of these descriptions are being passed to the LM that's a lot of extra tokens which is going to slow down the processing or the response time for our LM and it can reduce the quality of what it outputs because if you if you put in more text LMS can struggle to follow the initial instructions that you've given them and it's also going to cost more money because there's more tokens that you have to pay for here so for those reasons it's a good idea to limit the number of tools that we have available to our agent and we can we can do that okay we can see the agent toolbox here again we can do that by just going through here identifying which of these tools are pre-tools and just removing them from the toolbox so let's do that so I'm just going to initialize this delete list we're going to go through each tool in the toolbox and we're just going to test if it is a pre-tool if it is a pre-tool we add its name to the delete list and then after that we we're just going to go through that delete list and just delete them from the toolbox okay so we can run that and then this is our toolbox now it's just got one item in there right so we've just cleaned up that toolbox and that will just help our agent focus on the tools that we actually need rather than all these other tools that we we don't need in most cases so that's it for this walkthrough I just wanted to show you a little bit of how we can use those custom tools and also control it or clean up the toolbox within our agent for hooking face naturally as I mentioned these agents what they can do is massively expanded in Scope when we start building our own custom agent and as I said like if you are actually building projects with these I think almost all the time you're going to want these custom agents unless you manage to find agents out there that have already been built for you to use of which for holding face agents as a very new framework there are very few so yeah that's it for this video I hope this has been useful and interesting so thank you very much for watching and I will see you again in the next one bye"
    }
}