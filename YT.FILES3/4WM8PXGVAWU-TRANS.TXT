{
  "transcript": "hello and welcome back to the fourth Industrial Revolution podcast this is episode three I am delighted and pleased to have a fellow YouTuber and AI uh commentator uh along for the ride um so please welcome Dylan from uh Curious AI or how what's your Channel's name Dylan Dylan AI or curious AI yeah just Dylan curious for right now so I started wanting to talk about like quantum mechanics and all this stuff and then I was like No just focus down on AI so Dylan curious D AI is what as of today perfect yep so fellow fellow YouTuber up and cominging really sharp guy really funny I love his channel um just all the all the really uh kind of uh commentary that he adds so yeah today we are going to have um another Deep dive I think the two topics that we're going to cover we're going to we're going to talk about jobs the impact that AI is having on jobs which you know the data is kind of inconclusive but then the potential impact and then we're g to we're going to Pivot to talk a little bit deeper into P Doom or P win and and kind of where it's all going and and that sort of thing so um with all that uh Dylan you want to give yourself a quick quick plug yeah um I guess just a quick introduction I uh you kind of like went to school I I studied bioinformatics I was like when I was a kid I thought um biology and information were just the coolest and I didn't even end up graduating from college I ended up uh starting uh a startup with some friends we built software for like the ticketing systems that were like selling selling tickets for Sundance Film Festival in Park City and then uh turned that into my own company ended up getting um some investors that were here in Las Vegas and uh there's this guy named Tony Shay he was um CEO of zapo sold to Amazon pretty close to a billionaire and just was doing all this really cool stuff so I got a chance to see some really really awesome like interplay between City and government and big business and especially with the tech space where he was trying to kind of reinvent a culture that would be different and I just super fortunate to have a first firsthand uh experience with all of that and along the way got really into systems thinking so a lot of like Jeffrey West's um kind of book on scaling laws and and how you know cities and people and stuff interact and then that is kind of what got me interested in artificial intelligence I mean casually I was doing a lot of software development but I kind of just started playing around with tensorflow as an amateur and um sort of realizing the power actually ever since I saw Watson do the IBM thing like you know that that was so long ago now but there was something magic just about the way there was this one little clip where they described how a machine can learn different variations of the font a the letter a in different fonts and how you don't have to program it and I just e even back then I knew there was sort of something special about where this was going but seeing like the rise of the attention mechanisms and like taking over the recurrent neural networks I just started to feel like wow now we're now we're kind of really approaching that moment and it got got kind of very serious for I was like this is really different and I um yeah I personally feel that that there's something kind of really unknown that we're about to step into and it just sort of drives me to want to know everything I can about it and that's kind of what led me to being like man if I want to do this full-time maybe I can just make a YouTube channel and do this research on my free time and that's kind of led me to the journey I'm on now excellent yeah no I I really appreciate that and and for me that that like that Holy CP moment was when Google released Universal sentence encoder which was the first like kind of semantic embedding technology that was kind of the precursor that was the first half of the Transformer right because that was the encoder and now we have the encoder and decoder architecture but when I when I saw that we have the we now had the ability to encode arbitrary semantic meaning which you know verbal lexical meaning from Human speech to machine vectors I said this is going to change everything and so then it was a couple years from between you know Universal sentence encoder to gpt2 and gpt2 was a hot mess like it could it was it could barely understand like a Wikipedia sentence um and then gpt3 and the rest is history so yeah very very fascinating um path that you've taken and so thanks for thanks for sharing that story go ahead oh I was just gonna say like so I I hate to say it but when um GP I had some a friend who had access to gpt2 and then um I've got to see some YouTube videos of like the early versions of three and it still didn't click like I knew I still kind of thought of these bag of words models and some of the curated data sets that IBM was working on is really what AI was about and yeah I hate to say it but it it it's surprising how into it I was and then how it also kind of went past me the magic of it and then it clicked all of a sudden when I really saw people using GPT or chat GPT pretty much GPT 4 to do real things and that the generalization kicked in on the the types of like semantic meaning it was learning the fact that it's I just like did a paper on the video that's coming out tomorrow on on how good it is at chemistry but this isn't a chemist this is a next token prediction thing you know what I mean and I'm like gosh how is it picking up so much of our reality or how Sora is picking up physics you know and all that stuff really didn't hit until kind of the beginning of 2023 I guess like when I really started feeling oh my gosh like this came in a way I didn't expect but I guess I guess a lot of people in the industry would say that too I mean it seems like Deep Mind was taken off guard too so if they're taking off guard no worries if I was no I mean you know I'm reminded of you know Nick Bostrom with super intelligence and instrumental convergence and people have been talking for years about like oh well you can't have an objective function that doesn't go awall eventually and kill everyone but nobody predicted that the objective function that would lead us at least get us closer to AGI would be predicting the next word right it's it's not you're not trying to optimize for anything other than accurately predict the next word yeah and then and you know and then a second I got my head around okay like I can kind of understand this late in space I can understand how there's these clusters of um word fragments these tokens and that there's a certain meaning that's like emerging from the distance between everything then you know things like uh I started seeing how General attention is like I didn't expect it to work with you know Sora is basically chunks of of of like 30 frame per second uh pixels and it's like that doesn't seem like that could be a token and then I'm starting to see different ways people think about these tokens and it still keeps working and I was like oh even the idea of a token is starting to be generalized and uh yeah now we're like you know we're we're reading people's dreams we're seeing all sorts of patterns between data that we just would have never thought there was a signal in before right I mean I'm thinking I'm thinking in terms of from a from a purely informational standpoint like what is a token it's like it's like a meme right it's the smallest unit of of useful coherent information right and then and then it's not just how one token exists it's not just the the ontological you know whatever context or format of a single token it's all the tokens how they relate to each other because it's it's you know to put it red very reductively it's pattern recognition but as you're saying like that concept of attention plus tokenization plus Transformer architecture it is generalizing far more broadly than anyone realized I remember there was um one when I first got started I was on um the uh the multimodal future podcast um I can't remember the guy's name he kind of fell off I think he's I think he's done a few few other videos um but he he called it back then you know the future is multimodal and this was before even there was much public information about multimodal training um so that's just you're right like nobody really a few years ago nobody really knew that this would carry us this far but of course you know said scale is all you need attention is all you need so far that has proven to be true yeah well I it almost feels like relationships are are all you need like I am starting I I'm getting this gut instinct that there a whole conversation about like what did you make your token out of like was it video fragments was it like edges was it word fragments or any kind of MRI type things or all sorts of stuff it almost feels like the whole conversation about what the data that you're putting in and what the token is isn't nearly as important as the it's just relationship it's the relationships between the tokens and it in so many ways I'm trying to get my head around why the relationships are the the answer the mean like the the meaning is in the distance the multi-dimensional distance or something CU yeah just the tokens keep becoming changed and we keep getting amazing results so like like what is that like it's right it's a relationship it's I don't know it's sort of fascinating and then you can even start thinking about the biology of our our body and like what it is to be us and you're like oh it's kind it's not really about like exactly how many cells you have in your body it's the relationship between how they interact that brings this whole whole Human Experience together mhm no that that's that's a fair point and I I have often thought that that perhaps even Consciousness is more about the organization of the energy and matter it's not just the physical structure of the brain there's a there's an energetic and a temporal component as well as the physical component now I know we're we're diving off into a deep deep rabbit hole but I I tend to agree that it it is it is about the relationships and from a technical standpoint it was a matter of scale you you know enough enough layers for your deep neural network for your Transformer enough data enough training permutations and it is able to discern those patterns or embed those patterns uh now is it the most efficient way no but we're finding more efficient training algorithms all the time in fact uh the last video I did there is a uh a Microsoft paper where they're trying to just bring down the size of these llms and instead of some of the the patterns in the past have been like with Orca to generate more efficient data and train a new system but there's some research going on where they're going in and just trying to prune out the layers or the the tokens that don't matter but it still is giving good results and um there's like seems like there's a lot of fascinating stuff going on there where we might be able to shrink something just as powerful as gp4 with very Marg marginal kind of loss like like it's a compression in a sense I mean I guess gp4 is a compression of the internet but this is like a compression of gp4 that would be much smaller to run but it would still have all the important important relationships left over instead of a retrained model so maybe maybe we'll be able to get something you know the size of a brain soon so I hope so um and and certainly we're not we have not exhausted any of the Avenues of research yet and at least not that I have heard scale has not been exhausted yet you know improving attention mechanisms has not been exhausted improving distillation like I don't know did did you see that they're they're starting to work on one bit Transformers not even not even just like low but just like where it's binary you know uh activation functions so yeah I didn't dive into that paper but I know I know and they said they got huge efficiency out of it or something too from that one bit system yep and I think Nvidia their their chips they went to Flo from floating Point 32 down to the next generation is four four bit floating point so they're they're just finding okay you don't really need super high Precision math to do this and you think like okay well how how Precision or how precise is a human neuron really um and I don't I don't know the answer to that but it's it's also very noisy in the human brain yeah and I find it it's a strange analogy because the meaning probably the meaning for your own life as David chapiro is like your relationship to your audience to your loved ones to your work colleagues to even versions of yourself in the past that have like helped shape this narrative that you see your yourself as you know there's just something magical there yeah so that is a perfect segue so one of the kinds of relationships that we all have is relation ship to work um now there's tons and tons of history and economic theory and even philosophy to unpack uh with respect to why does money exist what do we use it for but for the sake of I guess the conversation you know we can just accept the way that the world works today is that you need to work to get money money is how you pay for all the goods and services that you need um kind of at a basic level money is a proxy for stuff that you want or need um so I guess to to kick it off some of the data that I've been looking at so just a couple days ago um the the Bureau of Labor Statistics just announced their latest jobs data and unemployment dropped half a per or or less um and I I looked at all of the all of the the graphs and stuff and it looks like that we that that jobs growth is decelerating but according to some people on the internet and I actually did some did some quick perplexity research uh the FED is is keeping interest rates High to cool the economy off because if things are more expensive um then then the idea is that that will curtail inflation so jobs are slowing down at the expense of trying to get inflation under control that seems like the the the prevailing narrative I'm not entirely convinced but I'm also not an expert Economist but at the same time uh John Stewart you know famous comedian and talk show host um has been making more noise about you know the false promise of AI and how it's going to start taking jobs and what what are we going to do about it so I'm kind of the the the more I know about it the less certain I am now I do think that in the long run it's rather predictable that you know we're going through a fourth another Industrial Revolution so the nature of productivity the nature of work in economics is going we're we're entering into a new paradigm but what is the nature of that Paradigm and so you know I think you and the audience probably know my position that we're heading for post labor economics so I want to pause there and get your take yeah there's a lot there okay so I have these kind of I guess I guess we do sort of Milestones because I can imagine in my simulations of how this is all going to play out um down the road things look just incredibly different I'm not even sure jobs are going to be any sort of way to think about what it means to be alive or to derive meaning but yeah in the short term just kind of looking a little bit ahead it does I I would just have to think that the jobs narrative that everybody talks about where coding kind of goes first and then some of these uh creative jobs kind of go down the hill first artists that like just are relevant to the tools that we're seeing go down and then I think there's a lot of uh a lot of a vocal sort of disruption I would say like I think Twitter and social media and politicians become under like really intense pressure as there's just a lot of people who don't have work they can't find and even worse than that they can't find meaning and they can't find a livelihood like if if if you find meaning in a livelihood without work I think we can make that progression but um so by the way I'm just I'm generally like kind of an AI pessimist even though I I talk about all this stuff all the time but yeah I think it gets really really ugly um in 2025 and 2026 um I could be wrong like I I hope I hope this goes smoother and and it's more like oh Dylan's a leite and that we can find um ways to get through this but it just to me feels like it's going to hit really quick when decision- making gets offloaded and CEOs are super incentivized to make better decisions for less money and humans just they're just way expensive compared to these kind of things yeah the inflation question yeah that's prob yeah I mean CU I mean that's a on the economics thing we we have another problem going against us which is that in the US we've always been able to print excess of money because all these other countries will take our cash from us right and then as as we have inflation it's kind of nice like we're sort of tax the other countries to our benefit but certainly for a long time now China's been trying to get kind of their gold standard and their oil thing working between Russia and it seems like that's kind of in full swing now and we really printed way more than we could we should be and if they're not taking on our cash overseas and that debt you know and then then it's just hitting us at home which is like seems like it's the story that yeah it does seem like the FED would have to yeah sacrifice jobs I would guess to just keep that keep that balanced yeah no I mean and so there there are quite a few uh threads to pull on here and one that I want to bookmark is meaning and livelihood or meaning versus livelihood depending on how you want to unpack that but then also just on a on a more immediate scale because I think you look at it in a similar way that I do which is what are the behaviors that are incentivized and so in some in some respects whether you're a small business or a global Enterprise you always have competition as one set of pressures if your comp if your competitor is automating with AI then you have to or they're just going to undercut you and you're going to go out of business and there there on a on a smaller scale there are there are cases of and I and before I share the story I don't want to say I don't endorse it one way or another it's just a thing that happens like don't shoot the messenger but one thing is that for for particularly small businesses whether it's construction or restaurants in particular that will pay um illegal immigrants or even even if they're not illegal immigrants pay people under the table to undercut um their competition there are there are businesses that it's like well my competitors are doing illegal practices and I can't I can't remain solvent if they're paying their people $5 an hour um because I like they there's no way to compete with that but this I think the same Dynamic will play out for any company because hey if you can replace a few developers or a few lawyers or a few middle managers or whoever project managers with AI and it's going to cost 10 times less well then you're going to you're going to force everyone else in that industry segment to do the same thing and that that that creates a race condition or you competitive you know downward pressure and that's just inevitable once the technology is there it doesn't matter invest in that AI they're going to want more and the product's going to sell itself so I fully agree that like that the pain will increase and I don't know if you've seen this but my formula is very simple as as pain increases political willpower increases and it's um and pain increases as economic agency goes down so that's where livelihood if you don't have a way to make you know make ends meet then your economic agency is going down and your anger goes up it's almost a direct you know inverse correlation um and so yeah but you mentioned uh well actually I I'll give the ball to you which direction do you want to go do you want to talk about like the meaning and livelihood or incentives or where do you want to go they want to talk about just what you said like agentic workflows the way I think about incentives and maybe even Universal basic income but I that I guess the first thing I'll say is that if there there's one framework that um I just generally have in my life when I get lost and I feel overwhelmed and I always think about it in terms of um incent I think incentives is the most pure like way to describe most big problems in the world it just you know like I think about systemic problems like in the DMV or in big companies Tony Shay who I who I got a pleasure of working with like you know his big thing was like why do companies get so much more fragile as they get bigger but cities as they get bigger become more like flexible and um it's because the incentives just keep at the very top of the company under this giant pyramid and it just gets bigger and more kind of broken it's not breaking off into the little pieces that it should and that's all about incentivizing people and yeah so so when I think about incentives then I think okay what is going to happen to anybody who wants to make money like if they're still in this same Paradigm where we need to build a company and like they start an LLC and they're like I got this idea for X Y or Z they're going to just spin it up and they're going to out they're going to spin up a bunch of probably human like maybe even Einstein level agents by the time we get to GPT 5 and they're going to have an agentic workflow they're going to have uh Andre just keeps talking about this they're going to have one agent that's a CEO and it's going to cost like 12 bucks a month and they're going to have one that's the CTO and it's going to go around and check and it's they're going to have like 10 they're going to spin up 10 more that are the QA um people and 10 more that are the coders and they're going to bounce their product back and forth and then they're going to simulate like what's going to happen when it goes out on the internet and who's going to use it and they're going to fix problems and the software is just going to come out to like an apple level polish and it's going to be one person potentially just managing nothing like managing these people who are managing themselves and and like yeah the whole system probably gets up ended by the first person to do that and when I think when Sam Alman said like there will be a a billionaire with one person like a one company billionaire or a unicorn sorry a unicorn company that comes from one person like that's kind of what he's saying it will it will be hundreds and hundreds of people doing amazing work but they just won't be any anywhere or any people to point at or to share the revenue with well and but the other thing so yes I I do tend to agree that that is imminently possible we're we're getting very close like Claude 4 gp5 the level of intelligence and some some of the leaks about gp5 and of course take it all with a grain of salt but apparently gp5 is being trained explicitly with more agentic behavior and then the video that you just did um what was it the egocentric perspective like a lot more of the kind of body models are being trained to understand themselves in time and space as well yep so yeah I think gr I think yeah grock is like kind of an eight sort of an eight agent answer when you ask it so yeah I mean these are definitely coming me they're not and there's also something sort of magical about the agents going and learning uh their own niches so it becomes something like a city it becomes something like a a very flexible adaptive system complex adaptive system is what what these agentic workflows become and yeah there there's just not going to be that much room for people I mean you can argue that there's some jobs that will be around especially human Centric ones I do think like human touch human care they're they're going to outlast many of the other jobs but there's not enough to like like keep 30 whatever 50 million Americans like employed and and happy and and that's there's not a lot of that so yeah that's that's probably why just out of just pure anger and like worry of um Rebellion I I see Universal basic income just being implemented because government's just going to have to be like gosh just at least give people a couple thousand a month so that they can get their groceries and things and then yeah then we just deal with this whole different then that's the beginning of this sort of new world and I don't know how we emerge from that but maybe we could come to a really beautiful world where kind of post scarcity and and it works or maybe that's just humans we're just you know not going to make it not make it through that I don't know we'll see how that plays out day by day there's a there's a quotation from Peter diamandis I'm reading his book abundance um which if you if you um if you want to be a little more optimistic you might like this book I've read it yeah he's optimistic for me but yeah oh yeah okay no worries but tell me tell me what you thought so the the the quotation that he that or maybe it's a subtitle I don't know if it's a actual formal quotation but it's we want wealth not work and so the I think would you would you agree that the these technologies will create like you know orders of magnitude more wealth just like yeah irrespective of distribution so okay so we're going to create a lot more wealth in various forms technological wealth scientific wealth and all the downstream effects so then the primary problem then is distribution and and part of distribution is federal policy like you know taxes but also ownership laws who owns what and and what does that entitle you to because if you own the means of production then you get all the trillions and trillions of dollars of wealth that is generated so to to I guess to to ask the question would you or I guess what what kinds of policies do you think might help stem the bleeding or reduce the pain what kind of policies okay so let me just what I'll just I kind of think through this like if like if I was if you were back in like the Egyptian time or something and you were trying to predict like the future with with much more wealth with like the the kind of farming techniques that we have today and all of these things you would probably assume that everybody in the world is getting fed you know you wouldn't say oh I'm I'm surprised like there's still a billion people starving today even though we have easily the technology for it so yeah it's a distribution problem and if I think why didn't that happen it was because yeah because each we kind of this tribal nature I think for the since the 20 million years that we diverged from our last common ancestor we've just always kind of lived in these sort of tribes and it seems like our brains just can't truly let go of our stuff right and that gets tricky because I believe in ownership I think ownership's like especially home ownership's one of the greatest things ever happened to humanity but also we just have so much abundance and if we keep trying to hang on to our excess it would just be it would just be terrible for like the tredy of the commons problem will just kind of keep us always perpetually poor in some quadrants and there will always be some people who need to like look better or be better or fight for that extra attention so what kind of policies can get rid of that is really tough like there has to be some kind of unifying mentality like like how we all feel like we're Americans or we all feel like we're good people or we all feel like we're earthlings or something that would have to unify it but the kind of policies that would make that happen would be control of media which would Al just be a complete wreck because the government would simply utilize that to their own means too so I don't know you got to have something that everybody's got to have their skin in the game and then we have to come to like a consensus and U yeah gosh what policies could do that I mean maybe pragmatically Universal basic incomes a good start I think um regulation I don't love it but I also just I'm not I'm not super big on the open source everything bandwagon so I guess I guess more restrictions in some ways are kind of what I'm in favor of but you know obviously it's not the greatest solution right it's always a trade-off so that's one thing to keep in mind is that whatever policy you have it's going to be a trade-off so if you if you if you are all in on for instance private ownership as kind of America is one of the most like hardcore about private ownership versus you know Collective ownership or decentralized ownership or even you know National ownership um it's always going to be a trade-off in terms of management um who gets the profits how do you how do you manage the resource um and then of course there that that also changes the in incentive structures because then if you know politicians have control over the means of production well then there's a huge incentive to become a politician so then you can sell privileg access damned if you do damned if you don't yeah I don't that's so tricky I don't know how you would keep everybody in a I mean this is and this this is the problem like as scared as I am about like AI just sort of going rogue on its own I'm really mostly concerned about the people problem like I would say that our probability of surviving goes up quite a bit if we all got unified like if we stop putting these things on weapons to fight other countries but that's where the real risk sort of comes from right so here's here's here's a a thought experiment kind of you know okay what is the what is the best argument for private ownership and the my my go-to example is the NASA SLS the space launch system which is billions and billions of dollar over budget and years behind schedule and here comes Elon Musk world's I think I think Jeff Bezos overtook him again but one of the world's richest people with SpaceX and he's launching the largest most powerful rockets in human history doing it privately doing it as as a business insurgent and it's like do we do we sacrifice so much about ownership and economic productivity models and the economic Dignity of many people just so that the occasional Elon Musk can come through and and build something cool and fancy because because he can do it more efficiently than NASA can because that that to me is like okay yes you know part part of the American ethos the inventor ethos is that you're incentivized to build new things because then you get to reap all the rewards um but is that is that is that the is that the social contract that we that we want is it the one that truly need and is is it also a false premise because like maybe maybe if Elon Musk started in Sweden or you know Spain you know could could SpaceX have existed in another Nation or is there something peculiar about the American economy and continent or whatever do we need ownership models that allow for people to become billionaires yeah I mean how do we get to like I would love to like ideally if I could just throw this into place like I would like people to have Universal basic income I'd like them to have money and things that they need to be competent and happy and have time to work on a problem they want but I also want them to be highly motivated and highly competitive with the people around them to to do better to like make a better world uh like yeah in fact it's funny you brought up Sweden because uh I'm Danish and Swedish and when I went back there I remember thinking one of the interesting things about what's happened is there is so much kind of financial equality that you'll see a lot of jockeying for um attention like like your your personal style the way you dress seems much more important in Sweden than it does in the United States because that's a way to go to a party and sort of stand out and say oh I've got like a cool outfit sort of because there's still men trying to like attract girls and there's still um people who want to kind of be in a different class of of friend group and there's still competition but it just seems like it's moved away a little bit from the monetary because of the way everything's structured around there the incentives are just sort of it's a sort of different game that you're playing so it would be it would be very possible to have a SpaceX be built uh out of somebody who just wanted to go to Mars and had the resources and time to build it and it it'd be fun honestly to be on a team doing something like that in a sort of Star Trek like future where you're just exploring the universe because you want to explore the universe like it's not about like you know the fact that I need food or I need anything else it's just like a personal growth uh battle your entire life to to kind of play Devil's Advocate to my own proposition which is maybe you need the American way to attract people like Elon Musk because it's not by accident that that America produces most the most unicorns you know Silicon Valley startups and and billionaires we're not the only nation that does it there's plenty of billionaires that are produced in Singapore Mexico China plenty of other places so it's it's not by no means am I saying the American way is the best way but to play Devil's Advocate much of the basic science that plays into open AI Microsoft SpaceX IBM a lot of the basic science is publicly funded and it's happening all over the world so like what what really truly is the driver of progress maybe that's maybe that's the the zeroth principal question which is you know is is it the entrepreneurs they get the credit Sam mman gets credit but he's not a developer he's a marketing guy he's a y cometer marketing guy um but he gets all the credit for chat GPT and everything else that's going on but but they are using the same research papers that you and I can find on archive from car Carnegie melon from Stanford uh from MIT so like what's the what's the difference there and and and I I guess I'm kind of talking myself around to saying you know we can walk in chew gum at the same time to use the political jargon like we can do Ubi and still also have basic science research and entrepreneurs like they're not they're not mutually exclusive is that would you agree with that or or is there something that makes them antagonistic like there's a TR off no there's no there's nothing that makes them inherently antagonistic I think yeah like what Elon Elon Musk wouldn't have done that anywhere else but a lot of places would have had the resources to do it but was he driven really because like I needed more money it just doesn't seem right like he seems like he saw himself as this entrepreneur who wanted to just do it again like just seems like he enjoyed being in that that grind of uh PayPal and then sort of seeing himself as like a better business person than the people around him and and willing to risk his resources on the next big thing and being in circles where he was like man if if government's not going to do it like what if I just put this thing on my back and build a space company um it just seems like a personal mentality like maybe something that even future versions of Claude could kind of persuade us into or like psychological but then again I'm asking the AI to convince us all to think different but yeah you know I mean it you know when you're surrounded by people who want to do stuff like you want to do stuff like when you're surrounded by lazy people you you get lazy like there like we are already stuck in a a system where a lot of who we think we are is based on our society and culture and America yeah we got kind of lucky we had a bunch of immigrants come over here and they built a really hardworking kind of do-it-yourself mentality and that served the country super well for a long time and it came from a hard a hard place like we're kind of lucky that our just our continent was like the last to really get populated I mean it might even just be a coincidence you know and and then yeah and then when China went through a time where they you know they were really kind of a third world country and they had a lot of bad stuff going on with their government and then they they saw us and we were like let's export our work over there and then they picked up oh wow we can have a better lifestyle with this mentality and that's why they're the second biggest Nation right now GDP yeah and quick quick clarification for the indigenous and First Nations people listening yes America was already populated when when us white people got here oh yes of course like yeah and by the way yeah I colonizing was a thing so yeah I just wanted to add a point of clarification I know what you mean oh gosh yeah of course I wouldn't forget that like no it was ter it was like yeah Christopher col is like one of the worst people that's ever existed like no they they were completely intelligent hardworking yeah Native Americans long before we came here but it was more about the the kind of the the mentality that everybody had I'm thinking more like when they were Landing in New York and we were like kind of taking the immigrants after kind of build a country of just a big diverse nation of people who were desperate to to work hard that's more of the mentality I was going for yeah well and you think about okay what what kinds of immigrants uh came to America um those that were that wanted new new opportunities largely it was they wanted economic opportunities but a lot of them wanted freedom and so it's like you know economics and freedom so what that actually reminds me of something that's been kind of a a pet theory of mine as I've been studying the Eastern world uh mostly Japan and China and so I was reading about ancient Chinese philosophy uh Confucianism dosm and and and what how geography shaped Chinese culture and one of the things that that is uh very pervasive in ancient China was a mistrust of merchants in Chinese Society Merchants were the lowest class uh below Farmers um and so because of that when communism came through and it's like ah Farmers you know the pastoralist those are the real real people and so Communism had very fertile grounds literally and figuratively in China and so it's actually not a surpris that this that this uh that the communism as it was expressed in China occurred the way that it did but despite the people's Revolution but despite the Great Leap Forward despite the cultural revolution China has not been get been able to get away from its confucious roots and the one of the strongest pieces of evidence for this China still mistrusts Merchants the stock market you're not really allowed to invest in the stock market your money is supposed to stay local but what do they do they invest in real estate that is the equivalent of the farmers investing in the land that happened 3,000 years ago so despite these disruptive political theories the the embedded cultural paradigms the embedded philosophical paradigms that have been present in China for 3,000 years they can't get rid of it and so I'm curious like I'm I'm thinking in the long run what are the what are the cultural and philosophical and ethical Tableau or whatever that's baked into America that's just basically going to be permanent um assuming that assuming that some of these cultural paradigms are permanent and that I'm reading it correctly because I could be wrong but I just notied that pattern there's just this very consistent through line for the last 3,000 years in China and they have not been able to say hey we're going to do this in fact the the the CCP very deliberately says keep your money in China you're not really allowed to take your money out of the country invest in real EST estate instead and that's just a modern expression of making the farmers invest in their local land and so but but to your point about the E the ethos that came to America that was kind of deliberately imbued from taking you know Irish and danish and English and German all tired you're weary all of that yep when did your family come here uh my great grandma great grandma more more Swedish name for uh grandma she came over like just straight off the boat so nice yeah yeah my family got here in the 30s so I'm a third or fourth generation American yeah so yeah um shoot I forgot what I was gonna say but yeah the wait okay you say something I kind of forgot where I was going with that oh yeah and don't worry like we can uh it's easy to edit this um after the fact but yeah so um let's see we were so jobs and then we can actually pivot to P Doom because we kind of seemed like we got to the Natural con of jobs oh yeah okay sorry I got what I was going to say so um you know you because so one of the fascinating things about about the world that you're born into right like you have parents and and you didn't get to choose where you were born and you end up in a society where you didn't get to choose that but we um there's this there's this book on my shelf I forgot the name of it right now but it was a book that was about what in the oldest libraries they had written down about what they found before those libraries were built so we're talking about some of the old oldest text um that exists about some of the oldest cultures that existed and the main takeaway I remember from this book was that every like just naturally these kind of farming like maybe maybe like these little farming cities each ended up with like big families and families kind of felt like they had their own religion they all had their own sort of person at the top and they they tended not to have as many rights for women and it just they tended to have these rituals that like when you talk with a neighbor the way that you plant and there was just all these conflicting almost little religions and it and it just sounded like very very difficult life but it was very like natural for them to just fall into these superstitions and these sort of patterns that just they're just unshakable generation to generation and when I was in India I you know they just don't follow the lines in the road like the cars just go wherever they need to go it feels like the way people move around Disneyland the way um the cars in India just drive in in the roads and I was thinking like what would it take to change this entire country to use lanes and use stop signs and stop lights because there is some efficiency in the way America's built and and all most most countries about these about the driving system that they're not taking advantage of but it's just so deeply rooted you can't shake something like that it's a system that's so ingrained that you're you're just kind of stuck into it and um yeah those are the kind of things that that are probably happening to China and the United States that we just benefiting from from a long time ago and they're just hard to shake yeah like geography plays a big big part of it but then of course as you're talking about like all the transplants cuz and and you're right I have thought a lot about this as well that here was this gigantic continent uh most of the continent that was populated very deliberately by certain kinds of people I wonder if we're going to see the same thing as as humans get to like Mars like what what the the people crazy enough to go to Mars what Legacy like what long-term philosophical and cultural Legacy will they and of course like they the the scrappy violent you know can do attitude I bet it will be full of innovation because they say uh like Innovation is the mother of Despair or something I forgot that quote but it's like yeah I bet the kind of people who are going to go like take Mars from the ground up and build a society are probably some of the greatest people that we have on the planet right now it's going to be a self- selecting group of awesome leaders and they'll probably set into motion some really good stuff I mean you know it's why I like startups so much startups like just shake things up they they come in with a small group and they build from a different core yeah and I just think like yeah it probably be probably great I don't know there's going to be a lot of ADHD yeah probably yeah in fact maybe that just occurred to me right now but yeah I wish our leaders were like almost picked that way like I don't know if I like the idea of people choosing to be the president of the United States because they they've just instinctively chosen like the it just instinctively pulls the wrong people out of our society to lead you know um I don't know if random would be actually probably random would be better like I think if our politicians were just randomly selected from the population as a whole it would be probably be better leadership but specifically the kind of people who are are gritty and they want to do something in a new way it would be it would be nice to be able to refresh a government over and over again um in a way that we just just don't have right now yeah well I mean it's it's one of the it's one of the basic true things about politics and power and that is that power seeking people often find power whether they become police or judges or senators or whatever for whatever reason someone who because you don't you don't become a senator or president on accident um it takes many many years of deliberate work um and so it's like okay well why did that person want that to begin with I actually just ran a poll on my my YouTube channel um I said in the long run should AI replace human judges and I think last I checked it was 54% said yes um and then 23% said maybe and 20% said no something something along those lines um because and and for me and it goes like okay so what is what is the domain of human business like it's a human problem humans should solve it but on the on the other hand who who chooses to become a judge right and and many of the comments talked about like oh yeah in an Ideal World judges are Paragons of of ethics and morality and and and good discernment but in many cases judges are very corrupt and and even if they're not corrupt even if they're not just power seeking people they're still still human and they have human flaws so we'll see how it how it pans out in the long run I don't know if you have any reaction to that no I mean you're yeah you're totally right I mean that like incentives is the way to view the entire world I think when yeah you become a lawyer you become a judge you become you work for the government you want to be an entrepreneur you're always you're always thinking like what is this going to be I know with my entrepreneurial background I I just sat there and dreamed of like I want to be a billionaire like I want to be like Mark Zuckerberg I wanted to like build this crazy company and um yeah and it was like okay then what does that mean that means you have to like kind of look the part you have to essentially fake it till you make it um like I felt like I went through that whole song and dance and kind of had my ups and downs and I don't know but hopefully we can get to a world where you don't have to maybe play that game and you can choose your own because there's nothing on the line anymore like that would be the kind of benefit of Ubi or something something where we we can just get access to the food and water we need and the social networks we need then you might see kind of more beautiful side of the world um and people's personality show up because the game and the alignment isn't the same right yeah no I I I like that model of like incentives are everything especially especially at the national or global scale is just what are the what are the intrinsic incentives of the organism and what are the incentives of the structure of of the system at large um and in some cases there are things that you can do to influence it but but in in many cases there aren't I don't know do you have any thoughts on on how to influence those incentive structures well I don't I mean I I'm also not a person who believes in Free Will so I feel like there's a lot of uh if there's anything we can do it's on these high levels like uh like when I started trying to diet I was like just throw away all the bad food and like be surrounded by good food and like just you do what you have to do like get your environment so that you don't have to think and if you want a better world and and people to be you got to find good people to be around like I just don't think you're going to hang around with three lazy people and be that one entrepreneur I don't think you're going to find five people that are lying and make them your best friend and figure out how to be like a really honest person like it's just there's something about who we are and how it's tied to our society and it makes total sense from an evolutionary point of view that that's the way our entire species came from and you can follow that all the way back to the beginning of Life where we were just you know single cells and multicellular organisms that just did things to get food to survive and uh it just turns out that we have this sort of social species but you know I mean we're not meant to be like on our own and part of that is because we don't even know how to kind of be ourselves I think right yeah no I I agree we we are inextricably linked to our environment and part of part of modernism or and I don't necessarily mean modernism in the philosophical sense I just mean modern society is we build cities and we build environments that we think we have full control over but it turns out suburbs and and urban life is actually not particularly good for us but but we did for economic reasons right yeah we we have we have control but like my wife and I were spending more time like going outside hiking and I'm just trying to spend as much time as I can away from computer screens and away from the city and I feel so much better um because it's like it it's getting back to the roots of like how is it that like our ancestors up until very recently lived most of the time um and plenty of people around the world live not even indigenous people you go look at like you know goat hurters on the island of creit right they still live the same way that they have for thousands of years they just have a few modern amenities but they still primarily live the way that they used to and I think that I think that there's a lot of wisdom in that yeah I guess I could imagine like if we're lucky and this whole AI thing does work out well and the AI is subdued to the point where it's aligned with our interest and it's just there to provide what we want but also not to do we don't offload too much to it that we become sort of lazy slots then yeah imagine a world where that's Pro it doesn't feel like there's computer screens around I'm sure AI will be like in our headsets or like in our environment in a way that we can kind of let feel like it disappears even though it won't and then yeah probably wake up in the morning and and walk around your neighborhood probably walking community and see people other people walking and probably attend like birthday parties and and eat dinners and do all these things um not because they're like efficient or anything they're just they're just how we just want to live when we have problem solved right it's it's the it's the structural affordances of your environment so I think that's a that's a really great segue to P Doom or pwin or however it's going to pan out so let's Riff on incentives based on how AI Works how machines work what kind of intrinsic incentives do you think they're going to have like that'll shape their behaviors and patterns okay so some of this actually to credit to your credit like I I remember a video that I saw you that changed uh some of the way I think about this now I think that some of the universals are power and energy um you kind of pointed out that like yeah like whether it's building Fusion reactors in the future or harnessing better solar um both humans and machines are going to need that resource and potentially Clash over it um I think that what they want isn't very clear to me because I know everything that I can consider alive or intelligent from like a dog to even um even even kind of fish and and there's there's some self-aware fish but Dolphins humans clearly that's kind of like a spectrum for me of how Consciousness kind of arises we've all needed to um oh shoot I forgot where it's going again dang it no worries where was I going on that like okay so you ask so what was I just saying I was going to energy and power and and incentiv Mach yeah the alignment energy and power yeah I don't know like I I guess that's kind of I just kind of feel lost on that can we go back to the question again what did you ask just be like what is what is it that they aligned with yeah like what what incentives will kind of steer because I I do tend to agree so here's here's the premise that might help the premise is I do agree that that Free Will is highly limited right that we are largely driven from our you know the the biological truth of you know our genes and bodies and organs and stuff and then that mixing with our environment those creates all the incentives all the decisions all the behaviors the vast majority of what we do I think that machines AI AGI robots whatever are going to be very similar in that there is the agent itself what it kind of is designed to do and then the environment that it's in so how will how will the difference between us as agents versus them as agents and but co-occupying the same environment what kind of incentive structures will emerge or what will they want or how will they Advance okay so what kind of incentive structures yeah like we're all going to need energy and electricity we're all are we all going to be motivated to like do something though I'm not really sure like it seems really clear that a AI agent can be totally happy turning itself off when it's done um whereas a human can't like because we were always framed by the propagation of our genes like it was always there was always we were always tethered yeah every so everything in life that I can imagine being intelligent the Dolphins self-aware fish there are self-aware fish they see them or at least they see themselves in the mirror just for the record a new discovery from last year but um we've always been just driven by propagation of genes so there's always that incentive to stay alive whereas you could in theory make software that has such different uh goals and it does seem to me that most of the time to complete any kind of utility f function you might be incentivized to not let your owner turn you off so I could see that happening in most cases but it doesn't seem inherently the same like the way it would for like species that have always been all all the intelligence I know was shaped by genetics so it's kind of hard for me to say how different how alien um some of these utility functions could be when they become superhuman intelligence you know it it occurs to me that that there is a form of selection I've talked about this in a few other creators have talked about this and that is that we will we will choose the robots and models that are more corable that will be more obedient and so it's almost it's almost like we're domesticating the AI kind of like how we domesticated wolves oh so I do have to think about it in terms of genes because humans are going to make the selection it's like a sexual selection except with like for artificial intelligence we're going to be selecting the models that do humanik money making type things things that we that we at least feel are beneficial obviously we're not always good at selecting Technologies and policies that are that are ultimately good for us because we often will choose things that are intuitively or short-term beneficial but then harmful in the long run but at least there will be some kind of selection at least for a while and so because you what you said about how many robots AIS whatever they're perfectly happy to complete their task right whatever their task happens to be unless of course you give it an objective where being switched off would be bad but if if we're selecting for obedience we're selecting for corrigibility then just the natural forces of you know where research goes where commercial products go all the startups because imagine this like you have a startup a robot startup and it kills someone well you get sued out of existence so whatever they were doing gets shut down and then another you know competitor comes up or whatever you know some some sort of pressure will will influence it so I'm wondering my intuition says that that's probably a durable pattern at least for a little while what about well first do you agree disagree other otherwise with that and then what happens when it does get much much smarter than us do we actually remain in control because we've we've pre-selected for you know the the Wolves yeah no way I mean I just don't think that's even remotely possible I mean my P Doom is on a good day like 98% um there's a small chance that like like what I really think is it's like 99 like I think that the the chances of us surviving are like basically zero however I I have to like hang on to something and there is a lot of unknown there so like I guess I'll just give it like a 5% chance that like we survive but um you know deep down I don't see this as a technology I see this as an alien alien life like in fact in fact what I wanted to ask you is is your P Doom for being destroyed by AI the same as if imagine a scenario where today we got a message from space from Aliens and they were like hey we got a radio signal like it's very clearly aliens they say they'll be here in two years and they're going to land on Earth like would you still have the same P Doom for an alien as you would for surviving the AI Singularity so first I do agree that what we are creating is tantamount to an alien um I've started characterizing it as a successor species or like a not a hive mind but a a Global superorganism so what we're what we're doing is we are creating something that is that is an emergent kind of organism a constructed kind of species um now comparing you know aliens to us there's so I've listened to a lot of Isaac Arthur I don't know if you've heard heard of him he's a futurist on on YouTube and of course he gets his ideas from a lot of different places um but one of the ideas that I agree with is that for a species to be become space fairing if if there was a species and any any distance the the cosmic distances are great enough that the level of technological advancement required to get from one star system to another either they can fold SpaceTime which means that there are several you know paradigms beyond our understanding of physics or they have generation ships that can stay in space for thousands of years either way they're far beyond us the implications of that the social implication of a species that is capable of that is basically you're selecting against being hyper violent so like the an example is the Klingons very very unrealistic because any species that warlike would not survive to get to the Stars they would nuke themselves out of existence first romulans way too suspicious um now of course that is all hypothetical you know we don't have in in size in samples zero we don't really know and we might nuke ourselves out of existence before we even get there so if aliens did land or did announce their their approach I would be more in the in the camp of they are probably far more enlightened than us could be wrong but that's that is that is I think that there is a good argument to be made that such a species would have selected out being overly aggressive now of course there's all kind all kinds of other um structures like what was it called it's one of the one of the like fmy Paradox Solutions which is like you actually want to be really quiet because you don't want to attract any attention to yourself because you're toast when they see you yeah right because because then you might also say from a from a galactic or Cosmic standpoint you would actually be incentivized to be a as aggressive as possible and to eradicate any other life that you come across lest it become a threat I don't know that I that that is that is a reasonable you know great power politics that's how human Nations work more or less which is you get you accumulate as much power as you can because you know the best defense is a good offense and vice versa so that there's an argument to be made for that but then there's also what is the intrinsic nature of that organism that was able to understand space that well so I don't know I would say that I I would say that you know it's it's better than the flip of a coin for me as a gut check like you flip you flip a coin and whether or not they're like angry aliens or peaceful aliens you know it could be first like first Contact you know like the Vulcans land and they you know have a drink with you and then they listen to some Roy Orbison and then leave yeah maybe okay so yeah so your take on the fmy Paradox could be that they're super aggressive and they haven't found us yet and that's why we're the only thing that we can see in the universe or if they did contact us we'd probably already be some we there's a chance we're already safe because they wouldn't have contacted us in that way unless they were already right yeah yeah it could go either way um I could imagine that that like there's some wisdom in like the prime directive too where it's like you just ignore most species until they are you know cosmically relevant that's probably the policy that I would prefer to see like as humans start exploring like imagine we get to proximus sari or whatever and we are you know there's a primitive you know uh Proto humanoid you know or pre-industrial civilization we would watch them from space right but we I think I think that there is a very very strong scientific and ethical argument to be made that any species capable of doing that getting there like we don't have anything to benefit from conquering you know a bunch of tribal Apes um unless we wanted their land which I could see some humans doing that um but on the other hand I could also see a policy of of non-intervention yeah and there's plenty of resources out there but yeah yeah the my so my thinking is that if we survive the AI Singularity it would I guess because of the self-domestication it would give us some chance of harnessing something superum that didn't turn on us but I've always compared them together like I think that if aliens show up if if if I Got a notification in two years aliens were coming I would be very very scared I would just think wow like not only do I I'm not assuming that they're going to hurt me but I am absolutely assuming that I'm sort of like an ant and they're like a human in terms of like how little I could understand about the whole point of any of this like I just would feel very weak and very unsure and I would have nothing to grasp on to to to make any kind of prediction about and that's why when I think about surviving the AI Singularity it just seems so unlikely to me that all of these things that are going to line like imagine your dog is you're trying to explain taxes to your dog like the dog just can't understand taxes because dogs just don't understand economies and and all of these things so they don't understand why you might do maybe you're like having trouble paying your taxes so you have like the cheaper dog food but all the dog knows is that you have cheaper dog food but there's all this complex stuff going on that resulted in that and that's how I think the AI is going to tell Sam Altman how the story ends like I don't think he gets to decide and I think if aliens show up and I'm hoping like oh I hope they come to Earth and like show me how to make replicators and um use cool technology to like harness the Sun and and we're going to have a great life on Mars and terraform some Planet like they might but like how could I even make some kind of prediction on that and if I can't make a prediction on it I can't assume that the very rare status quo that I live in right now now is going to continue like I know what I have now is like an unfathomable Miracle just to be alive on the planet like why something not nothing like why everything four bill you know 4.7 billion years ago just played out in the way that it did to lead to this moment that's very fragile and for that to survive requires an extraordinary amount of care and competency put into the system continuing and the system can fall apart like that and I I just assume that's going to happen I Goa well and so the did you read um age of spiritual machines by Ray curtz yeah you yeah yeah got it on the shelf right there y so I just uh Breeze through that and what I really appreciated about that book was at the beginning he talks about the difference between Order and Chaos and how increasing order accelerates change but one thing that he didn't cover is that uncertainty increases as you know rate of change increases and it sounds like that's kind of oh yeah actually because you could make that same you could make a inverse of that same uh same chart that he has for uncertainty exactly yeah so because what you're talking about is as AI becomes more powerful the future becomes less certain if aliens show up the future becomes less certain whereas you know 500 years ago the greatest technological advancement was you know the printing press but otherwise your life and the trajectory of humanity was mostly certain you know a French army could March over the hill um but that was you you knew the risk right and there was also you'd offer have some warning um when something like that happened but in terms of the number of options so another way of mathematically modeling it is the number of possible Futures is increasing right now and so the the the the fork in the woods is going in many many different directions and there's one fork after another would you agree with kind of that characterization 100% and use like just the and and then just apply the tiniest amount of basy in prior to that and say I need this very specific situation to stay alive as a human and those worlds become tinier and tinier yeah no and I tend to agree so I know that I'm very optimistic but it is like threading a needle there is there is there's the golden path right there is one path to success and there's many many many bad paths but one thing that I will say is that I I believe that there are some self-correcting mechanisms because and absolutely push back if if I am not interpreting it correctly but it sounds like what you're is that it is intrinsically unstable system like kind of a top spinning and it's going to fall down but what if there are aspects of it that are self-correcting or self-writing or self-limiting because not everything is exponentially becoming more unstable there are going to be some forcing functions or constraints or even uh attractor states that kind of pull towards a certain direction so what's your reaction to that no 100% and that's where the hope is now if now now maybe my percentage of like 5% or less at most is how well that can do but yes um like in terms of kind of a informational entropy I guess you could say uh if if we domesticate Ai and it takes care of us and it says oh by the way like I can also make predictions about when there's going to be a solar flare and protect your planet from it which is a big risk right now I can protect you from uh like an oncoming uh meteor strike I can um go out there and like make sure you're on multiple planets so that the species doesn't end if one planet goes away there's certainly yeah there's certainly some ways that intelligence can can keep the system perfect in fact i' I've always been sort of fascinated by um what are those like self you probably I sure I'm sure you know the term but it's like when you build like a Dyson Sphere and then you build those replicators but the replicators have error correcting code and they go from like planet to planet and then consume the resources and duplicate themselves until you sort of populate the the universe or whatever yeah it's like if if we get error correcting code to keep Humanity safe I suppose we could survive many many unknowns uh because we would have the intelligence to keep keep the system together which would would just be a new just a very different thing from the historical way I I can look at the past so yeah that's possible I mean that's why there's like I guess 5% for me or 50% for you that we do survive yeah I I think the uh I think what you're referring to are the Von noyman probes oh Von noyman probes yeah yeah yeah yeah so okay so let me let me ask this irrespectful of numbers what do you see as the greatest risks like what are the what are the either the features of our current system or the failures of human biology or coordination like which model is most Salient to you just straight up tragedy of the commons it's just the fact that we don't all have skin in the game and that um anything that's not correctly balanced anything that's any kind of tiny asymmetry in who benefits and who gets hurt is just Amplified to the nth degree but also there's just some basic ones that make me like just feel so stupid like why would you mount a gun on a drone like why would you make a big dog that can like track people down I like I don't know if you've read about uh lavender which is the system that's israeli's government is using to like figure out all the people of like where the like like I understand AI can figure out who people are but like why attach that to to weapons um and I get it cuz because you're trying to win a war so it's going to happen but like from the grand scheme of like all of us being humans and needing to survive one of the biggest moments in history it's just really stupid to like to like it we have to get EV like everybody has to be aligned which is just impossible like I don't have really hope that that that that works but if we did we'd have a much better chance and I would I would get I would say there could be over a 50% chance that we survive if if humans worked like ants and we all had a goal and like we all would be willing to sacrifice and not take and not destroy each other using weapons there'd be a possibility but that's not a world that's realistic no I I would I would agree that that you know coordinating everyone is difficult with one exception then that is looking at the intrinsic motivations of all people which is desire to keep living um you know you you look at you look at the incentives I guess the biological imperative right you need food you need sleep you need water and so from a structural standpoint point you say okay how do we position everything everything that you want from a basic level you know masa's hierarchy for instance how do we how do we integrate that with AI in such a way that it it creates an attractor state that is stable and beneficent yeah that's kind of the thing about it we don't get a second we don't get a second try on this one I mean you know if we actually we actually did drop a nuclear weapon and we were like God this is horrible like can we try to like put some systems in place and take some of these apart and to some degree we've live in a fairly safe world even though there's nuclear weapons but like you don't get to go through the singularity twice like you don't get to um see ASI twice I mean it's it's a multi-agent component so it's not exactly a comparable thing but yeah but it's it's unfortunate like if if this does end in like what 15 20 years because we made a big mistake and AI is out of control and it decides like we don't want you then we don't get to go back to today and scare everybody and be like hey guys you should get on the same page the whole planet has 15 years left to be in existence that would Shake us all up and we would have a better chance but I mean what what what are we supposed to do like go on YouTube and just be like we're all going to die in 15 years like get on board you know like then you're just a crackpot and and you're leite and okay so we'll just have to go at it the way we always go at it and hopefully the mistakes we make are recoverable right and I mean to to to be fair that's what some people are doing um and then some people are also profiting from denialism and accelerationism and everything in between yeah and and you're you're right that we only get to go through this once but we also did only get to go through the nuclear age once um and there were many many close calls with nuclear weapons one thing that gives me a little bit of Hope is that the difference between for instance a nuclear weapon and an advanced AI is that it can have its own moral code a nuclear weapon is just an inert an impassive or impartial Implement it's just a energy right that's that's what a nuclear weapon is it just releases a lot of energy all at once it doesn't have any agency and so one thing that I hope is you're suggesting put autonomy into the weapon itself so it can tell us it can say no I'm not going to drop this bomb right now because I have morals and you don't well no I don't I don't weaponize it in the first place but it's going to be weaponized unfortunately yeah um but but what I what I mean is that when okay so think of it this way the internet as a technology created a bunch of new affordances and new systemic structures right and what does the internet want the emergent thing that the internet wants is attention because the internet is there to transmit data and information so the emergent characteristic is it wants more attention it wants more data but when you add artificial intelligence which is not just an impassive impartial participant in patterns of of information it can actually it can actually tit treat the information that it shares and when and can also that can as a complex adaptive system that can modify human behaviors so an example is um have you used perplexity you know the AI enabled uh search engine yeah I'm aware how it does the search Eng and and yeah I heard you talk about it on the last podcast yeah yeah so it will I suspect that that just as a single technology as that sort of tool gets embedded by default the information literacy and media literacy of everyone goes up a little bit now obviously some people will say I don't just I don't agree with this because it told me that you know vaccines are good and I don't believe that of course some people will check out but there'll be at intrinsic disadvantage but for many people they don't they're not it's not polarizing there's no ideological thing wrapped up in it they just are you give them a better a smarter tool and they make smarter decisions and so the combination of of the fact that AI can have moral agency and also compresses all human knowledge so that's one of the things of Ray cartwell I didn't catch him saying this in the book because I don't think he anticipated this but AI brings order to information the internet is is chaotic right in terms of as an information landscape there's just so much information it's like tornadoes everywhere of information AI compresses it and brings order that information which is then an accelerant to the landscape but I I do suspect that as a complex adaptive system there will be aspects of how humans and AI interact that are impossible to predict because some of the things that the AI does will change our behavior and then some of the things that we do will modify Ai and vice a symbiotic thing for sure yep but of course that increases uncertainty even further because that's the intrinsic nature of a complex adaptive system hopefully it picks up our good yeah hopefully it picks up our good nature not our bad but yeah like I mean would you be in favor of um basically an AI that is on top of the planet and maybe is in control of weapons or biological weapons and says hey like when when a government says oh I want to deploy this weapon it's just like no I don't think so like I I've taken control of the most dangerous parts of humanity and and now I've decided uh based on your guidance which was to keep you all safe that this is not not possible would you be open to giving up that kind of control well we don't have that control right now like so just you know we have no control over what even what our own country does let alone China and Iran and other other stuff so what I think that we in the long run I think what we need is more of a global operating system or a global nervous system um because right now now every nation and every human is basically operating as an atomized amoeba right we're just consume consume consume spread Spread spread you know I don't I don't like this other strain of amoeba so I'm going to eat them right and if you look at the Earth like a petri dish that's kind of our Behavior right it's just a bunch of amoebas all attacking each other there's no coordination and there's no intelligence at a global level we're just growing and so I I hope I think and this is this is why I've characterized it as like kind of a a global digital super organ ism is that we're growing a prefrontal cortex for the planet is that AI could yeah that AI could be the thing that is able to to consume all the information all the publicly espoused information and then collectively because imagine imagine you have an AI that is empowered democratically that 8 billion people say you know hey let's we're we're going to you know proposition 23 do we nuke Iran or do we unleash another plague and everyone unequivocally votes no and the AI that is empowered by all of us says okay well whoever's building the nukes we shut them down like that I think would be like I can conceive of that system I don't see any reason that that system couldn't exist but it's how do we get from here to there safely um so so like um and it seems like this would probably be from what I know about you opposite of how you would feel but elas owski is would argue that we don't do any training runs that aren't any big like Frontier Model training runs that aren't in supervised data centers right like you would say that um you know we'd have to try to make this agreement between China Russia the US and say anything that's like gp4 or better has to be done with the ability for the other countries to audit something like the UN would go in and say like what are you training how are you training it and what kind of safety mechanisms are there and if there was a rogue Nation like he was in this interview I heard him say like if there was a rogue Nation say Russia's like no like we're not going to we're going to do a frontier training run and just the same way we kind of keep an eye on nukes we can track energy we can see like where chips are going we can probably have an idea of where the biggest data centers in the world are because these Frontier models are so computationally expensive you you'd say then we're you're leaving us with no choice but to strike like we'll have we'll have to blow up your data center because you're not letting us see what you're doing in there and this could like jeopardize the world and on at that same time if you want to build this central nervous system um this frontal this like prefrontal cortex for the planet you probably shouldn't be open sourcing any of these models also because then you're starting to lose track of of where they are and have control over them too so what do you I I I know you're a big fan of open sourcing I'm not particularly but um what do you think about that as far as like keeping us safe and having an AI over our weapon systems and some of the most important things well so I I think that from a from an industrial standpoint from a geopolitical and and Military strategic standpoint point I think that that's probably going to be the way that it happens anyways you know we we have already seen cyber warfare targeting critical infrastructure so from a strictly military perspective I think that that is pretty much already the established you know like what what what did we do when when Russia invaded Ukraine we cut off their supply of chips right that is you just look at it as a military resource what is that military resource you treat it like an oil refinery you treat it like a tank Depot and you just attack the data centers I think maybe more importantly though not just the fact that they're doing it like a strategic attack but I mean the the way that we keep an eye on each other's nuclear weapons right now we audit through the UN like we actually go and um oh let me fix that that out um but yeah we audit other countries by going in and letting us see what they're doing like do you like that idea of China being able to go to like open Ai and say like let me see how you're training your system and in exchange we get to see what you're doing at by do and we can kind of unify the way these Frontier models are being built I if Okay so I mean just taking taking that on the face of it if you could create that kind of agreement it might be beneficial in some respects but the problem is one I don't think it's a politically feasible or realistic goal and two I'm not sure that it would have necessarily the intended effect yes you are right that that you know like we're project Stargate right a hundred billion dollar data center to train and run the next generation you know where that is you can see it from space so there's like there's not going to be really any mystery of where it's happening or the energy that it's consuming so on on that respect uh yes that part is feasible but the but creating creating an inspection team or International you know like the equivalent of iaea uh you know International atomic energy agency that can that has teeth that can go in and forcibly inspect fac facilities to say oh yes like you have you know 4,000 nuclear warheads just like you said you've got 3,000 icbms just like you said great like they're still pointing at each other the question becomes if you do that then you incentivize all kinds of other things offshoring hiding research which could I I would be afraid could make the situation worse depending on the incentive structure that you create around that but then also I think and and I do agree that at a at a certain class um open source you you don't open source like your Flagship models you don't open source military models but gpt3 I don't see any reason that gpt3 shouldn't be open sourced because it because it's it's TW it's 12 to 24 months behind and plenty of other models are open sourced uh and and again all of the research that leads to these algorithmic improvements that's already public domain anyways um but of course the money so here's here's where where privacy and property rights come back in the amount of money and capital that goes into even just creating the model means that you need to keep it closed Source in order to even incentivize the model being created in the first place unless so here's here's what I think would would work better is rather than policing everyone what if China America Europe Russia what if we all got together pulled our resources and we all invested in that gigantic Data Center and the the Nations all had access to the same model and Collective ownership skin in the game I think that I think that the CERN model would be better than the police model that's interesting yeah yeah I hadn't I had thought about it too but yeah because all I'm because everything's incentives to me I'm like how do you incentivize cooperation and yeah that would be a better way plus these projects you know if it is a$7 trillion doll model then like you probably do need multiple countries and might as well just throw in even smaller countries just so that that it's that we're on the same team here yeah that's and that's another part is even if you know small countries you know in Southeast Asia or or subsaharan Africa can't really afford to participate what if you give them a away in and then everyone buys into this new initiative so think of it this way imagine um oh did you ever see the the movie um the Jodie Foster movie written by Carl San contact oh yeah course yeah of course classic oh yeah the schematics for a Stargate aliens sent us the schematics for AGI but it was going to cost $80 trillion what would we do we would come together as a planet and say hey we're going to find a way to spend 80 trillion to make this thing and so yeah go ahead oh and I I tell you like it seems good too because right now these models they get trained on sort of Western values or maybe Chinese um and and English languages but they're not totally representative of of these smaller countries that have their own languages that have their own data that have their own culture you know so it'd be nice if they did have a seat at the table and there was a giant training session that didn't did take into account all of these these kind of smaller pieces that are important they're just smaller and less important for making money from right and another advantage to this is the amount of resources available to all the nations on the planet is far more than Sam Alman could ever raise and so that is going to be Far and Away the most powerful model on the planet it's going to have all the best researchers all the best research all the best training data and so that means that if EV if everyone has has has bought in everyone has Democratic access and it's the best one I think that that that is a good way of aligning incentives I'm afraid that it's not going to happen because of the military reason because of the geopolitical comp competitive reason that's the biggest reason not to do that because then it's like oh well if you know that China is just going to take their copy and use it for nefarious purposes and of course China will say that America's going to use it for every company every everybody that's why everybody's got to build the weapon because everyone else is it against them yeah right but if that's the only way to get the most powerful one I could see people buying in and I think I think ignoring geopolitical tension for a moment I think that everyone pulling their resources would be the best path for Humanity we would it would get us there faster it would get us there more safely and everyone has skin in the game because nobody wants to to die or be tortured by you know misaligned AI or whatever um but the reason the only reason that that doesn't work right now is because of the power dynamics playing out across the world yeah that's so painful because yeah and then and then if if even smaller countries got the same access to it then if there was something where if we we could all say to it like hey can you help us with our like military issue so we don't fight then we'd be more likely to give that up why did CERN work was it because there's no military what's the lesson there for us well so one thing to keep about in mind about CERN is it's not Global it is mostly Europe and America and a few other signatories um so it's not it's not it's not all inclusive um so that's that's one thing to keep in mind a lot of the people that are participating in CERN are already Military Allies or at least economically aligned so it's not it's not a perfect example in point of fact you know the UN is currently disintegrating deeply deeply criticized for its mishandling of everything from the from the pandemic to Israel Gaza so it's like well okay maybe the UN is a failed model maybe we're not ready to come together as a species but going back to your point earlier about narrative like I do think that a global Universal human narrative is a big part of the puzzle piece or that that's a big big piece of the puzzle in order to come together and unify because again if if you and I and other people can agree hey it would be best for Humanity to pull our resources but why can't we do that and there's the Chinese narrative there's the American narrative there's the Russian narrative there's the European narrative and we have all these different conflicting narratives that don't yet see us as a single people as a single species one of the most beautiful things about the way AI works you could allocate like H you know almost as if like a company like Nvidia became a world company right like it's not just playing with an idea here but something like a new organization that's never existed before it's not an American company it's not a Chinese company it's this Earth company and it makes the best gpus in the world and it makes h100s and it allocates them based on country or or something like you know like every country gets whatever 50,000 of them and we all build the data set the money kind of pools in and the each country gets control of their little piece of it but because AI can be trained across the world like that it could be the Clusters all come together for the unified ho and then that's right something that we can all chat with and talk to and and understand in a unified way yeah yeah no I I would that's that's that's presently my best option forward again there's structural reasons there's incentive reasons why that idea wouldn't work perfectly just as you know the idea of a regul you know International regulator wouldn't work perfectly but I I mean I think we can do both I think that if we can come together and have some kind of international Watchdog we can also have an international research and you know create a win-win scenario so all right Sol the world's problem that was a great great podcast yeah all right Dylan well thanks for jumping in and hanging out for such a long time um good talk and I look forward to uh to talking again sometime in the future all right thanks for your time I appreciate it that was fun excellent",
  "duration": 86,
  "comments": []
}
