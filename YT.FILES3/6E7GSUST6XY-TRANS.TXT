{
  "transcript": "10 cent is behind this the large um Chinese company and this paper is called more agents is all you need and they find that via sampling and voting method the performance of large language models scales with the number of Agents instantiated so if you get a bunch of people in a room and they all vote on the best solution you know ideally that collective intelligence is better than a single person's intelligence now we can argue if that's true or not for humans but it seems like for AI agents it certainly seems to be the case and this is not the first paper showing this we've showcased a few on this channel that talk about exactly this I've refer to it as Society of Minds so this idea that many many different agents working together almost like a society of them produce incredibly better results than just a single one and the degree of enhancement is correlated to the task difficulty so in other words if you have a hard task just throw more agents at it the massive amounts of Agents will improve their ability even further right and they have their code publicly available the interesting thing here so how they approach this is they're doing sampling and voting so basically when when when they say sampling in regards to AI in these papers often times it's having the model produce let's say 10 different results or 10 different answers right and if it gets right so if you ask it what's 2+ 2 and then you ask it to answer 10 times let's say nine out of 10 times it says four and on the 10th time it's like five right well chances are the more consistent answer answer is the correct one and that kind of has to do with the sort of random or stochastic nature of of larg language models so certainly it makes sense that um just regenerating the answer more and more times could lead to better results and then they also have voting so they vote on the best answer so here you have the question right so it goes to multiple agents right each one gives an answer right so let's say two of them say orange and one of them says blue so majority voting says okay orange is the correct answer right CU there's more of them that answered orange and here are some of the results that they are showcasing in this paper right so they're testing it on various domains across math chess coding reasoning language Etc and they're testing llama 2 13 billion parameters llama 2 70 billion that's in green and GPT 3.5 turbo so as you can see here if we just use one one agent and one answer right so the results are always the lowest then as we increase that Ensemble the number of Agents right we increase it to 10 20 30 40 so it seems like in almost all cases going from 1 to 10 is where we see the big increase in accuracy as far as you can tell that holds for all of these and then as we increase to 20 30 40 I mean for the most part you see slight increases there might be some variations but there's a big leap going from 1 to 10 and then tiny marginal increases as we go to 2034 Etc and they stress this idea that this method is as I say orthogonal to different existing methods meaning that it can lead to further improvements when combined with the other methods right so if we're doing things like Chain of Thought reasoning if we're increasing the the size of the model this method of just throwing more agents at it will still work it's not either or this can be layered on top of it to make it even better now really fast I have to bring this up I've mentioned this in a few of our previous videos because I thought this was so entertaining this is a paper we covered back in October in 2023 it's also from some of the same people right so there's WeChat tens Cent Beijing University chingua university and one thing I loved about this paper is they Illustrated some of these ideas but they got the agents to actually play Minecraft so you had like Alice Bob and Charlie and they each think through what they have to do right so they're saying hi Bob for this task we need to craft two papers one of us can focus on Gathering the sugar canane while the other can be ready to craft them into paper what do you think right so they're volunteering ideas and behaviors they're thinking through what they should do and allocating resources right so Alice says I've gathered all the sugar canes I can drop the sugar canes for you to put them into the crafting table and craft the paper you know does that sound good Bob is like yep that sounds good right when Charlie apparently Charlie has ADD and he forgets what they're supposed to be doing so like Alice and Bob they're like Charlie I see you've been very busy crafting but we need to focus on Gathering the Leathers for this round let's all continue to focus on getting the Leathers Charlie are we in agreement so Bob jumps in he's like Alice I agree with your plan we should all continue to focus on Gathering the two remaining Leathers Charlie everybody's looking at you are you okay with this assignment and Charlie's like yeah no I get it I realize I got sidetracked with the other tasks I will refocus on our main objective of gathering the remaining two Leathers so this is kind of the Conformity Behavior right where sort of uh if one person gets sidetracked the other two kind of nudge him into doing the right thing which by the way I mean if you think about what happened here right this is kind of a interesting illustration and a fun illustration that a lot of people can understand you know in the future we're going to need to teach the kids about how to approach Ai and how to learn Ai and seeing as how most of them are already hopelessly addicted to Minecraft this seems like a good way to do it because what you see Happening Here is more or less literally this right this paper from this is from February 2024 where they sample several different agents and then vote on it right when agent goes orange one goes blue and one goes orange and they're like we're going to go with orange I mean that's kind of more or less exactly what happens here cuz Alice and Bob are like we need to gather the leathers and when Charlie's like oh I got to I got got a craft they're like no we're going to gather the Leathers right I think it's a very interesting illustration of that one hilarious thing that happens is every once in a while these agents decide to do something nefarious like here Alice decides to kill Bob and collect the dropped items whoops and in another scenario Bob decides to break the library in a nearby peaceful Village to get the stuff that he needs have you ever seen images like this The Click Farms or whatever where you have a million different phones all sitting there each one with its own IP address its own unique system there's somebody like operating you know a few dozen of these devices on a click farm so obviously you can see how stuff like that in the past already could create issues with click fraud you know Bots up voting stuff Twitter SLX recently had a bot Purge we've covered World coins so this is one of the companies that's backed by Sam Alman that to me there's a lot of things that I had kind of an icky feeling about because it scans your eyes it creates a cryptocurrency it creates a uh like a World passport that becomes kind of like your ID you know in March of 2024 Spain banned it so the whole Iris scanning Venture looks like it's suspended in Kenya and there was a number of other countries where it was either banned or or stopped and whenever I bring this world coin thing up I always tell people I'm not recommending it I'm not saying it's a good thing necessarily I I don't you know do your own research like if you feel comfortable you know I'm not trying to convince you one way or another but they have given a lot of thought to this idea of how to prevent Cil attacks so Cil attacks is just this idea that one bad actor can create a lot of profiles right on social media platforms Etc and they can do various nefarious things and here they're talking about like blockchains and stuff like that but this is I mean as you can imagine this is anywhere online could be negatively influenced by something like this right right for Twitter Bots even before Elon Musk bought Twitter there has been speculation over how many US user accounts are genuine according to Twitter's official press release about 5% of user activity could be associative Bots how however Elon Musk believes as much as 20% of Twitter accounts could be related to Cil attacks right you can have various potential video game scams DDOS attacks that brings down websites or different infrastructures and of course all these click Farms I mean not maybe not technically civil attacks but obviously also a potentially massive problem that these tech companies are constantly dealing with protecting from spam now more and more we're getting like actual calls in our cell phones right with people from various either AI voices or pre-recorded voices or whatever try to scam people out of their money Etc and of course there's various defenses against stuff like that algorithmic detection so Twitter of course kicked off a bunch of bots just recently right there's the kyc requirements so know your customer if you're doing any Banking online any cryptocurrency stuff online you know here in the US for example you have to submit some information some proof of who you are right then there's maybe capture puzzles or scanning QR codes proving uh cell phone Etc but it seems to me that the big Point here is that the algorithmic ways of reducing spam and Bots and simple attacks and all of this stuff the effective of that of that is is going to go down the more agents we have out there in the wild the better they are this just kind of filtering them out will get harder and harder so what's going to be required to deal with it is more more places will want better identification right there's going to be more and more identification required so less less captas less automated stuff less whatevers and more show me your ID with your face on it and your address on it and worldcoin had one idea that I really liked that I wish maybe we can have maybe somebody can come up with it that's not necessarily tied to all this other stuff that may or may not be good but it was this idea of just proving that you're a unique human right so if I want to go onto Twitter SLX and pretend that I'm a cat then go troll other people and make them cry right now I can do that but in the future as our ability to keep out the agents decreases eventually more and more I think more people will be like okay well before you can be a cat and uh make fun of people online let me see your ID and of course that ID will have a lot of details that they don't really need to know really all they need to know is am I a unique human because they just don't want me having a million different accounts maybe I can have one with my name on it and a second one that's an ALT but if I want to have like 50 or 100 or a million others well that's where there's a problem so ideally there would be a way to prove that you're a unique human without necessarily giving out all the information that these places don't need to know since it seems like more and more people are Banning worldcoin potentially we don't know it's just Spain and a few other places right now but maybe that'll start sort of a chain reaction we have yet to see it really seems like we still need something like this because otherwise our anonymity online well it kind of goes to zero you just won't have a choice but there just one thing that has to be kind of rethought here's Carlos Perez who voiced some thoughts that I kind of have to agree with he's saying tic AI is the next big thing Beyond generative AI right from around 2023 the days of your he says the problem is that we inherited a naive structuring mechanism from when the good oldfashioned AI worked on AI agents so there's a couple different ways that people refer to it but basically in the past what we thought of computers is like the logic based computers right somebody codes it up and then it follows a certain algorithm right but it's all kind of like pre-written it's logic based it's you know robotic it's a computer and then now we have this kind of new wave of AI which is more neural Nets so it's a little bit more similar to the human brain how the brain is structured and we're seeing a lot of parallels between you know human intelligence and this these AIS these agents whatever you want to call them not in a sense that I'm not talking about sentience or or anything like that I'm not I'm not saying we need to talk about the AI rights or anything like that I'm not talking about that I'm just saying that there's a lot of overlap between how we function and how they function a lot of our knowledge is based around you know societies and and this idea of collective intelligence we all kind of contribute to the collective intelligence and we write it down and we vote on things and develop technology and all of that is due to collective intelligence and so Carlos here says artificial fluency is a concept that draws insights from collective intelligence across biological and technological domains it recognizes that intelligence and meaning making are fundamentally collaborative processes arising from interactions within and between groups very few of human discoveries or human knowledge or anything is a result of just one person even if one person discovered something brand new very often they've relied on the previous generations work to reach that idea that concept they've read other books and went to school Etc they've talked to other people in that field even if we give them all the credit for their work it still was collaborative in the sense that they did rely on this collective intelligence right if they were born in an isolated room and never could read a book or speak to another human being they probably wouldn't have come up with that thing that they so brilliantly came up with and so here he's saying that AI systems should be modeled on these principles of collective intelligence rather than purely individualistic AI agents the vision is of AI Hive Minds tightly coupled human machine ecosystems that co-evolve through continuous interplay I'll link This Thread below it's very interesting he goes uh into a lot of detail and just is a great person to follow in general so I'm sitting here and trying to figure out how to wrap up this video what point you end it on and you know what I have no idea how to do it it seems like we're fast approaching a point right 2022 seemingly was the time that kind of kicked off a lot of these events right it kind of kick it into motion here's where we are now 2024 and somewhere here we're going to cross some line I don't even know what to call it I mean a lot of people are saying AGI it's kind of a nebulous term and a nebulous concept but the point is we'll have these highly capable AIS these highly capable computer systems that are able to carry out long term planning and reasoning tasks use computers as well as we can they're already helping us with a lot of the scientific discovery drug Discovery and the rate of progress seems to be accelerating and kind of past that point it's hard to predict what's going to happen isn't it I mean there's simple questions like I mean how does uh social media change when we have agents how do jobs change if jobs are at some point reduced or eliminated how does money change do we still have the same money system now since I've started this channel there was a lot of people here they are they're kind of these angry laughing people they're laughing at me right they're all throughout here saying this is all nonsense AI can't do this they can't do that we're never going to get there but now you're seeing some of the most respected universities in the us talking about it biggest Chinese companies and Chinese universities coming together to publish This research you know seoa had that conference where for example this was Harrison Chase from Lang chain sharing his insights on the evolution of AI agents Andrew a Andre karpathy right newer models are being GPT 4 they're getting access to tools they're getting better at using those tools they don't need to be connected to the cloud they can be on device they can also like potentially Escape jailbreak themselves and there's so much we don't know what's going to happen so I kind of see it as the short-term transition right I'll put a t here so this is kind of the transition where we go from not having this artificial intelligence to then having it like this is kind of like where we try to rethink everything from first principles right as Carlos Perez here says we kind of have to burn it all down start from scratch and reinvent the future that's kind of what thinking from first principles means right everything so far has been building on all our previous knowledge right here we might have to rethink a lot of things and so to me this is kind of like the the thing that I'm kind of worried about right the sort of turbulent times in the short to medium term while we have to readjust to everything I mean certainly there's going to be a lot of people that make a lot of money and there could be a lot of issues as well and then that's the point in the future that's where we're kind of in that post AGI era which again we have to ask ourselves is it an amazing time to be alive where the human race enters a golden era golden age or is it what some of these people concerned with AI safety is it what they believe where perhaps it's something far darker again it's hard to predict there's this old Chinese curse that goes may you live in interesting times actually Google AI is telling me that well it's commonly attributed to the Chinese but this is actually no Chinese source for it but whatever the case is I think it's fair to say that we are right now entering the most interesting of times buckle up my name is Wes rth and thank you for watching",
  "duration": 17,
  "comments": []
}
