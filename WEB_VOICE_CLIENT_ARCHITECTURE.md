# HAL Web Voice Client - Architecture Documentation

## Overview

The HAL Web Voice Client is a **zero-installation, browser-based voice and text interface** for the HAL AI system. It eliminates the need for client-side Python installations, library dependencies, and platform-specific configurations.

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Client (Any Browser)                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  index.html + client.js (Pure HTML/JavaScript)         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Captures microphone audio via Web Audio API         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Streams audio chunks to server via WebSocket        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  - Displays responses in beautiful UI                  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                            ‚Üì                                 ‚îÇ
‚îÇ                      wss://hal.lcs.ai                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              HAProxy Reverse Proxy (ubu6)                    ‚îÇ
‚îÇ  - Terminates SSL (wildcard *.lcs.ai certificate)           ‚îÇ
‚îÇ  - Routes HTTP requests ‚Üí Windows Server:8080                ‚îÇ
‚îÇ  - Routes WebSocket upgrades ‚Üí Windows Server:8768           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Windows Server (10.1.34.103)                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Port 8080: HTTP Server (Static Files)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Serves index.html, client.js                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Simple Python http.server                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Port 8768: Voice Gateway (WebSocket + Processing)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Receives audio streams from browser               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Detects wake word (openwakeword)                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Sends audio to Whisper for transcription          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Routes queries through Query Router               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Returns responses to browser                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Port 8745: AI.SERVER (QM Integration)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Handles built-in queries (time, date, hello)      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Integrates with QM database                       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Ubuntu Server (10.1.10.20)                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Port 8001: Whisper STT (faster-whisper)             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Transcribes audio to text                         ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Port 11434: Ollama LLM                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Processes general queries                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  - Model: llama3.2:latest                            ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Key Components

### 1. Web Client (`voice_assistant_v2/web_client/`)

**Files:**
- `index.html` - User interface (chat display, input, mic button)
- `client.js` - Client-side logic (WebSocket, audio capture, UI updates)

**Features:**
- **Zero Installation**: Just open URL in browser
- **Cross-Platform**: Works on Windows, Mac, Linux, iOS, Android
- **Audio Capture**: Uses Web Audio API to capture microphone
- **Real-Time Streaming**: Sends audio chunks as they're captured
- **Beautiful UI**: Modern, responsive design
- **State Management**: Connected/Disconnected/Listening states

**Browser Requirements:**
- Modern browser with WebSocket support (Chrome, Edge, Firefox, Safari)
- HTTPS required for microphone access
- Microphone permission granted

### 2. Voice Gateway (`PY/voice_gateway_web.py`)

**Responsibilities:**
- Accept WebSocket connections from browsers
- Receive streaming audio data
- Perform server-side wake word detection (openwakeword)
- Detect end of speech (VAD - Voice Activity Detection)
- Send audio to Whisper for transcription
- Route queries through Query Router
- Send responses back to client

**Key Features:**
- **Server-Side Wake Word**: No client-side processing needed
- **Session Management**: Tracks multiple concurrent users
- **State Machine**: PASSIVE ‚Üí ACTIVE ‚Üí PROCESSING ‚Üí RESPONDING
- **Context Tracking**: Maintains conversation history per session

**Dependencies:**
- `websockets` - WebSocket server
- `openwakeword` - Wake word detection ("Hey Jarvis")
- `webrtcvad` - Voice Activity Detection
- `numpy` - Audio processing
- `requests` - HTTP calls to Whisper/Ollama
- `query_router` - Intelligent query routing

### 3. Query Router (`PY/query_router.py`)

**Routing Logic:**
```
Query ‚Üí Intent Detection ‚Üí Route to Handler ‚Üí Response

Intents:
‚îú‚îÄ builtin (0.95)    ‚Üí AI.SERVER (time, date, hello)
‚îú‚îÄ home_assistant    ‚Üí Home Assistant API
‚îú‚îÄ database          ‚Üí QM Database queries
‚îî‚îÄ llm (default)     ‚Üí Ollama LLM
```

**Intent Detection:**
- Regex pattern matching
- Confidence scoring
- Built-in queries have highest priority

### 4. HAProxy Configuration

**Location:** `/etc/haproxy/haproxy.cfg` on ubu6

**Key Configuration:**
```haproxy
frontend https_in
    bind *:443 ssl crt /etc/haproxy/certs/wildcard.pem
    
    # ACL for hal.lcs.ai
    acl is_hal2 hdr(host) -i hal.lcs.ai
    use_backend hal2_backend if is_hal2

backend hal2_backend
    mode http
    option forwardfor
    timeout tunnel 3600s
    timeout server 3600s
    
    # Detect WebSocket upgrade requests
    acl is_websocket hdr(Connection) -i upgrade
    acl is_websocket hdr(Upgrade) -i websocket
    
    # Route WebSocket to port 8768, HTTP to port 8080
    use-server hal2_ws if is_websocket
    server hal2_http 10.1.34.103:8080 check
    server hal2_ws 10.1.34.103:8768 check
```

**Why This Works:**
- SSL termination at HAProxy (wildcard cert)
- HTTP/2 support for browsers
- WebSocket upgrade detection
- Long timeout for WebSocket connections (3600s = 1 hour)

---

## Data Flow

### Text Query Flow

```
1. User types "what time is it"
2. Browser sends via WebSocket: {type: 'text_input', text: '...', session_id: '...'}
3. Voice Gateway receives message
4. Query Router detects 'builtin' intent
5. Routes to AI.SERVER (port 8745)
6. AI.SERVER returns current time
7. Voice Gateway sends response: {type: 'response', text: 'The current time is...'}
8. Browser displays in chat UI
```

### Voice Query Flow

```
1. User clicks üé§ button
2. Browser starts capturing audio (16kHz, mono, 16-bit PCM)
3. Browser sends audio chunks: {type: 'audio_stream', audio: [int16 array]}
4. Voice Gateway:
   a. Converts to float32
   b. Runs through openwakeword model
   c. Detects "Hey Jarvis" (score > 0.5)
5. State changes to ACTIVE_LISTENING
6. Continues receiving audio chunks
7. VAD detects silence (1.5 seconds)
8. Combines all audio buffers
9. Converts to WAV format
10. Sends to Whisper (POST /v1/audio/transcriptions)
11. Whisper returns: {text: "what time is it"}
12. Query Router processes (same as text flow)
13. Response sent to browser
14. Browser displays in chat UI
```

---

## Advantages Over Python Client

| Feature | Python Client | Web Client |
|---------|--------------|------------|
| **Installation** | Install Python 3.13, pip, 10+ libraries | **None - just open URL** |
| **Dependencies** | pyaudio, openwakeword, webrtcvad, pygame, websockets, etc. | **Zero** |
| **Platform Support** | Windows only (tested) | **Any device with browser** |
| **Mobile Support** | ‚ùå Not possible | ‚úÖ **Works on phones/tablets** |
| **Microphone Issues** | Driver conflicts, PyAudio errors | **Browser handles everything** |
| **Updates** | Reinstall on every PC | **Automatic from server** |
| **Deployment** | Copy files + install libs | **Share URL** |
| **SSL Certificate** | Self-signed warnings | **Real wildcard cert** |
| **Processing Location** | Client (limited power) | **Server (unlimited power)** |

---

## Security Considerations

### Current Implementation

**SSL/TLS:**
- ‚úÖ Wildcard certificate (*.lcs.ai)
- ‚úÖ HAProxy terminates SSL
- ‚úÖ No self-signed certificate warnings

**Authentication:**
- ‚ùå **NOT IMPLEMENTED** - Anyone with URL can access
- ‚ö†Ô∏è Internal network only (10.1.x.x)

**Data Privacy:**
- Audio streams NOT recorded or stored
- Session data in memory only
- No persistent logs of queries/responses

### Production Recommendations

**If exposing to internet:**
1. Add authentication (OAuth, API keys, or basic auth)
2. Rate limiting (prevent abuse)
3. Session timeout (auto-disconnect idle users)
4. Audit logging (who accessed when)
5. Content filtering (prevent malicious queries)
6. CORS restrictions (limit allowed origins)

---

## File Structure

```
HAL/
‚îú‚îÄ‚îÄ voice_assistant_v2/
‚îÇ   ‚îî‚îÄ‚îÄ web_client/
‚îÇ       ‚îú‚îÄ‚îÄ index.html              # Web UI
‚îÇ       ‚îú‚îÄ‚îÄ client.js               # Client logic
‚îÇ       ‚îú‚îÄ‚îÄ cert.pem               # SSL cert (not used - HAProxy handles)
‚îÇ       ‚îú‚îÄ‚îÄ key.pem                # SSL key (not used)
‚îÇ       ‚îú‚îÄ‚îÄ serve.py               # Simple HTTP server
‚îÇ       ‚îî‚îÄ‚îÄ generate_cert.py       # Self-signed cert generator
‚îÇ
‚îú‚îÄ‚îÄ PY/
‚îÇ   ‚îú‚îÄ‚îÄ voice_gateway_web.py       # WebSocket + Wake Word Detection
‚îÇ   ‚îú‚îÄ‚îÄ voice_gateway_web_secure.py # SSL version (not used)
‚îÇ   ‚îú‚îÄ‚îÄ voice_gateway_with_http.py  # Combined HTTP+WS (not used)
‚îÇ   ‚îú‚îÄ‚îÄ query_router.py            # Intent detection & routing
‚îÇ   ‚îú‚îÄ‚îÄ llm_handler.py             # Ollama/OpenAI/Claude integration
‚îÇ   ‚îú‚îÄ‚îÄ home_assistant_handler.py  # Home Assistant API
‚îÇ   ‚îú‚îÄ‚îÄ database_handler.py        # QM database queries
‚îÇ   ‚îî‚îÄ‚îÄ ai_server.py               # AI.SERVER (port 8745)
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ router_config.json         # Query Router configuration
‚îÇ
‚îî‚îÄ‚îÄ Documentation/
    ‚îú‚îÄ‚îÄ WEB_VOICE_CLIENT_ARCHITECTURE.md (this file)
    ‚îú‚îÄ‚îÄ WEB_VOICE_CLIENT_QUICK_START.md
    ‚îú‚îÄ‚îÄ TODO.md
    ‚îî‚îÄ‚îÄ ERRORS_ENCOUNTERED.md
```

---

## URLs and Ports

### Production URLs
- **Web Client:** https://hal.lcs.ai
- **HAProxy Stats:** http://ubu6:8404/stats (admin/apgar-66)

### Internal Ports (Windows Server - 10.1.34.103)
- **8080** - HTTP server (static files)
- **8768** - Voice Gateway (WebSocket)
- **8745** - AI.SERVER (QM integration)

### Internal Ports (Ubuntu Server - 10.1.10.20)
- **8001** - Whisper STT (faster-whisper)
- **11434** - Ollama LLM

### HAProxy (ubu6)
- **443** - HTTPS (frontend)
- **8404** - Stats page

---

## Configuration Files

### HAProxy Backend (`/etc/haproxy/haproxy.cfg` on ubu6)

Key sections:
1. **Frontend ACL**: `acl is_hal2 hdr(host) -i hal.lcs.ai`
2. **Frontend Routing**: `use_backend hal2_backend if is_hal2`
3. **Backend Definition**: See architecture section above

### Query Router (`config/router_config.json`)

```json
{
  "llm": {
    "provider": "ollama",
    "ollama": {
      "url": "http://10.1.10.20:11434",
      "model": "llama3.2:latest"
    }
  },
  "home_assistant": {
    "url": "http://homeassistant.local:8123",
    "enabled": true
  },
  "database": {
    "enabled": true,
    "default_account": "HAL"
  }
}
```

---

## Development vs Production

### Current State: **Hybrid**

**Production-Ready:**
- ‚úÖ SSL with real certificate
- ‚úÖ Domain name (hal.lcs.ai)
- ‚úÖ Reverse proxy (HAProxy)
- ‚úÖ Server-side processing
- ‚úÖ Cross-platform support

**Still Development:**
- ‚ö†Ô∏è No authentication
- ‚ö†Ô∏è No rate limiting
- ‚ö†Ô∏è Internal network only
- ‚ö†Ô∏è No monitoring/alerting
- ‚ö†Ô∏è Manual startup (not systemd services)

---

## Performance Characteristics

**Latency:**
- Wake word detection: ~50-100ms
- STT (Whisper): ~1-2 seconds
- LLM query (Ollama): ~2-5 seconds (depends on query complexity)
- **Total end-to-end**: ~3-7 seconds (voice) / ~0.5-1 second (text)

**Scalability:**
- Current: Single server, single process
- Limit: ~10-20 concurrent users (based on Whisper/Ollama capacity)
- Bottleneck: Whisper transcription and Ollama inference

**Resource Usage (Windows Server):**
- Voice Gateway: ~200MB RAM
- Wake word detection: ~500MB RAM (model loaded)
- Per session: ~10MB RAM

---

## Future Enhancements

### Short Term
1. Fix WebSocket connection issues (current priority)
2. Test wake word detection with multiple users
3. Add systemd/Windows service for auto-start
4. Improve error handling and user feedback

### Medium Term
1. Add authentication layer
2. Implement session management
3. Add TTS (text-to-speech) for voice responses
4. Support multiple wake words
5. Add conversation history persistence

### Long Term
1. Multi-user support with separate contexts
2. Custom wake word training
3. Plugin system for custom handlers
4. Mobile app (React Native wrapper)
5. Offline mode (local Whisper/LLM)

---

## Testing

### Manual Testing Steps

**Text Mode:**
1. Open https://hal.lcs.ai
2. Type "what time is it" ‚Üí Should get current time
3. Type "tell me a joke" ‚Üí Should get LLM response
4. Type "hello" ‚Üí Should get AI.SERVER greeting

**Voice Mode:**
1. Click üé§ button (should turn red)
2. Say "Hey Jarvis" clearly
3. Wait for acknowledgment
4. Say "What time is it"
5. Should hear/see response

### Automated Testing

**Not yet implemented** - Future work:
- Unit tests for query router
- Integration tests for voice pipeline
- Load testing for concurrent users
- Browser compatibility testing

---

## Troubleshooting

### Common Issues

**"Microphone access denied"**
- Browser requires HTTPS for microphone access
- Check browser permissions (Settings ‚Üí Privacy ‚Üí Microphone)
- Ensure hal.lcs.ai is in allowed list

**"Connected/Disconnected loop"**
- Check Voice Gateway is running (port 8768)
- Check HAProxy routing configuration
- Verify WebSocket upgrade detection in HAProxy

**"No response to text input"**
- Check Voice Gateway logs for errors
- Verify AI.SERVER is running (port 8745)
- Test query router independently

**"Wake word not detecting"**
- Speak clearly and loudly: "HEY JARVIS"
- Check microphone is not muted in OS
- Verify wake word models are downloaded
- Check Voice Gateway logs for detection scores

### Log Locations

**Windows Server:**
- Voice Gateway: PowerShell window output
- HTTP Server: PowerShell window output

**Ubuntu Server (HAProxy):**
- `/var/log/haproxy.log`

**Ubuntu Server (Whisper/Ollama):**
- Check systemd journal: `journalctl -u whisper -f`
- Check systemd journal: `journalctl -u ollama -f`

---

## Maintenance

### Regular Tasks

**Daily:**
- Monitor HAProxy logs for errors
- Check disk space on servers

**Weekly:**
- Review query router performance
- Check for library updates

**Monthly:**
- Update SSL certificate if needed
- Review and archive logs
- Update LLM models

### Backup Strategy

**Critical Files:**
- HAProxy configuration: `/etc/haproxy/haproxy.cfg`
- Query router config: `config/router_config.json`
- Web client files: `voice_assistant_v2/web_client/`
- QM database: (per existing backup strategy)

**Backup Command:**
```bash
# On ubu6
sudo cp /etc/haproxy/haproxy.cfg /etc/haproxy/backups/haproxy.cfg.$(date +%Y%m%d)

# On Windows Server
git add -A
git commit -m "Backup: $(Get-Date)"
git push origin main
```

---

## References

- [OpenWakeWord Documentation](https://github.com/dscripka/openWakeWord)
- [Faster-Whisper Documentation](https://github.com/guillaumekln/faster-whisper)
- [Ollama Documentation](https://ollama.ai/docs)
- [HAProxy Documentation](https://www.haproxy.org/documentation.html)
- [WebSocket API](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)

---

**Last Updated:** 2025-12-03
**Version:** 1.0
**Status:** In Development - Core functionality implemented, troubleshooting WebSocket connectivity
