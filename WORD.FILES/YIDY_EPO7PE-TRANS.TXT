{
  "transcript": "Agency swarm can now browse web literally\u00a0 like a real human being with gpt 4 vision. \u00a0 It can not only extract content\u00a0 and click on links and buttons,\u00a0\u00a0 but also fill out forms, input fields, scroll\u00a0 up and down, go back a page, and more. \u00a0 This is the most advanced web browsing agent\u00a0 currently available, but the best part is\u00a0\u00a0 that you can easily combine it with other\u00a0 agents using my framework agency swarm.  \u00a0 I will demonstrate exactly how you can\u00a0 do that at the end of this video. \u00a0 But for now, let me just show\u00a0 you this incredible demo. \u00a0 Okay, so for those who don t\u00a0 know, my name Arsen and my goal\u00a0\u00a0 is to automate my whole AI agency with AI. Recently me and my team launched our first public\u00a0\u00a0 product called OAI Widget, and guess what, we\u00a0 needed a QA test engineer, who would test staging\u00a0\u00a0 and production just in case, before we go live. So check this out, my agency will consist of just\u00a0\u00a0 two agents, a quality assurance manager and\u00a0 a browsing agent. The task itself will have\u00a0\u00a0 8 steps that we used to do manually from\u00a0 logging in as a user and creating a new\u00a0\u00a0 widget to sending a test message and ensuring\u00a0 a response. After I send the instructions,\u00a0\u00a0 the QA manager immediately communicates the first\u00a0 step to the browsing agent, which is to login with\u00a0\u00a0 my provided credentials. Don't even try it. The\u00a0 browsing agent then opens the landing page and\u00a0\u00a0 encounters the first problem. The login screen\u00a0 is not there. However, it automatically analyzes\u00a0\u00a0 the page and clicks on a login button,\u00a0 which takes us to the login screen. \u00a0 Now when the browsing agent tries\u00a0 to enter the credentials again,\u00a0\u00a0 it succeeds this time and reports to the QA\u00a0 manager that we are in fact logged in. After that,\u00a0\u00a0 the QA manager sends the next step, which is\u00a0 to create a new widget. This is the cool part\u00a0\u00a0 about using Agent Swarms is that you do not have\u00a0 to instruct your browsing agent on every single\u00a0\u00a0 step. The QA manager will do that for you instead.\u00a0 The browsing agent again easily performs this task\u00a0\u00a0 with the click element tool that highlights all\u00a0 the buttons and then QA manager sends the next\u00a0\u00a0 step which is to expand the OpenAI section. I\u00a0 found that providing exact step-by-step process\u00a0\u00a0 allows your agents to complete it faster. However, alternatively, you can provide more\u00a0\u00a0 general goals and instructor manager agent to\u00a0 break them down into step-by-step process for you\u00a0\u00a0 instead. After our agent expands the OpenAI tab as\u00a0 instructed by the manager, it enters the test API\u00a0\u00a0 key and selects Test Assistant which were the next\u00a0 two tasks. Then it saves the widget by clicking\u00a0\u00a0 on the save button which was the following task\u00a0 and reports back to the manager. Now, only two\u00a0\u00a0 final steps left. The first one is to send the\u00a0 hello message which it again executes smoothly\u00a0\u00a0 with the send keys tool and the second one is to\u00a0 ensure that the response has been received. The\u00a0\u00a0 QA manager then finally reports back to me that\u00a0 the tests were performed without any issues which\u00a0\u00a0 means that our production is not broken and I can\u00a0 safely go back to sleep. Pretty cool, right? Now,\u00a0\u00a0 before I explain how these tools are implemented\u00a0 in Agency Swarm and how you can create such a\u00a0\u00a0 system yourself, I wanted to clarify that this\u00a0 idea of GPT-4 vision-powered web browsing belongs\u00a0\u00a0 to a YouTuber named Unconventional Coding. AI Jason also showcased this in his video later,\u00a0\u00a0 but he only changed a few lines of code just\u00a0 some configuration and got 10 times more views.\u00a0\u00a0 So I just wanted to clarify that Unconventional\u00a0 Coding was the one who created this script that\u00a0\u00a0 marked the elements on the web pages with bounding\u00a0 boxes allowing GPT-4 vision to decide which one\u00a0\u00a0 to click on next. However, that script, in my\u00a0 opinion, had several large limitations. First,\u00a0\u00a0 it was not fully written in Python and it\u00a0 required Node.js, which made it hard to run\u00a0\u00a0 and deploy. Second, that script couldn't use\u00a0 any input fields. It could click on buttons,\u00a0\u00a0 but it was not able to type into search fields\u00a0 or log into websites. And third, it was a closed\u00a0\u00a0 and non-expandable system, meaning that there\u00a0 was no way to connect more agents and it acted\u00a0\u00a0 essentially as a stand-alone chat application. All of these issues are now fully resolved in\u00a0\u00a0 Agency Swarm with the browsing agent that is fully\u00a0 written in Python that can click, type and scroll\u00a0\u00a0 pages and that you can easily combine with other\u00a0 agents yourself. So let's take a look at how it\u00a0\u00a0 works and how you can use it. Essentially,\u00a0 browsing agent is just a collection of seven\u00a0\u00a0 tools with some special instructions. All of these\u00a0 tools use Stealth Selenium browser with Chrome,\u00a0\u00a0 meaning that you can bypass bot protection on many\u00a0 websites. Read URL, scroll and go back tools are\u00a0\u00a0 pretty self-explanatory, but the rest of the tools\u00a0 like click element, analyze content, send keys and\u00a0\u00a0 select drop-down is where it gets interesting. All of them use GPT-4 vision under the hood to\u00a0\u00a0 perform various actions. For example, the\u00a0 analyze content tool takes a question from\u00a0\u00a0 the browsing agent, such as what are the contents\u00a0 of this web page. And then it takes a screenshot\u00a0\u00a0 of the current browser window and answers it\u00a0 using GPT-4 vision. Tools like Send Keys and\u00a0\u00a0 Click Element act in a similar fashion. They\u00a0 take a description of the action that needs to\u00a0\u00a0 be performed on the current web page and then\u00a0 perform it with GPT-4 vision. The cool part\u00a0\u00a0 about these tools is that they use JavaScript to\u00a0 create bounding boxes and labels around relevant\u00a0\u00a0 items directly in your web browser window. Therefore, there is no need for any additional\u00a0\u00a0 libraries. Say, for instance, the browsing agent\u00a0 sends a task to this tool, such as enter an email\u00a0\u00a0 and password. The bounding boxes then will be\u00a0 only created around the input fields. However,\u00a0\u00a0 if the task is to click on a login button, a\u00a0 different tool will be used and only the buttons\u00a0\u00a0 will be highlighted for GPT-4 vision. In case if\u00a0 the element is not located the prompt instructs\u00a0\u00a0 GPT-4 vision to give the browsing agent a better\u00a0 idea of where to find it. Of course there are\u00a0\u00a0 some things that could be improved especially\u00a0 if OpenAI releases a few more features which I\u00a0\u00a0 will discuss in just a bit along with some cost\u00a0 implications as many people have requested. Now\u00a0\u00a0 let's see how you can make an agent swarm with\u00a0 browsing yourself. So the first step is to install\u00a0\u00a0 Anaconda or MiniConda from the official website.\u00a0 Then clone the Agency Swarm repo from GitHub and\u00a0\u00a0 navigate into the root directory. Create a\u00a0 Conda environment with the following command,\u00a0\u00a0 then activate it and install Jupyter. Go into\u00a0 the notebooks folder and run Jupyter notebook\u00a0\u00a0 command. You should see a window pop up in\u00a0 your browser, then click on the web browser\u00a0\u00a0 agent notebook and run the first cell to install\u00a0 some additional packages. To run my example you\u00a0\u00a0 can explore the following cells. However, keep in\u00a0 mind that if you want to test OEI widget you need\u00a0\u00a0 to create your own account and provide your own\u00a0 credentials in a task description. What's funny\u00a0\u00a0 is that sometimes your assistant might refuse\u00a0 to handle personal information but it happens\u00a0\u00a0 only rarely and you can typically fix it just\u00a0 by adjusting the prompt. Now if you want to\u00a0\u00a0 create your own agent swarm scroll down a bit\u00a0 to the next section and import the packages. \u00a0 I recommend starting with just 2 agents and\u00a0 expanding your system as necessary. The more\u00a0\u00a0 agents you add, the more tasks they will be to\u00a0 handle without your direct supervision. However,\u00a0\u00a0 keep in mind that this will take longer and\u00a0 also increase the costs. I'll start from the\u00a0\u00a0 report manager agent which is responsible for\u00a0 the oversight of the browsing agents operation.\u00a0\u00a0 A good practice is to instruct your manager agent\u00a0 to break down tasks into step-by-step processes\u00a0\u00a0 and try to resolve any issues along the way before\u00a0 reporting back. As for the browsing agent itself,\u00a0\u00a0 you can now simply import it with a single line of\u00a0 code. However, I will also add an additional line\u00a0\u00a0 to its instructions with my LinkedIn credentials,\u00a0 just in case if he needs to use them. \u00a0 The next step is to create your agency. In\u00a0 this scenario, I will simply allow the report\u00a0\u00a0 manager to communicate with the browsing agent,\u00a0 but not vice versa. In shared instructions,\u00a0\u00a0 I will put a couple of goals with some context\u00a0 about my task at hand. Now, the last step is\u00a0\u00a0 to simply run the demoGradio method and send\u00a0 your initial command. Let's test it out. Say,\u00a0\u00a0 I want to compile a report on myself from the top\u00a0 three sources on Google. After I send this task,\u00a0\u00a0 the report manager breaks it down and communicates\u00a0 the first step to the browsing agent, which is\u00a0\u00a0 to pull up the Google search web page. Then it proceeds to instructing the browsing\u00a0\u00a0 agent to analyze the top three sources one by\u00a0 one, starting with LinkedIn. After it logs in\u00a0\u00a0 and finds my page, it extracts all the contents,\u00a0 sends them back to the report manager and then\u00a0\u00a0 gets the next task, which is to analyze the\u00a0 second page from the AI Accelerator Institute,\u00a0\u00a0 where I took part as a speaker at one of their\u00a0 generative AI conferences. Again it easily crawls\u00a0\u00a0 this page and extracts the relevant content and\u00a0 then gets the final task which is to analyze my\u00a0\u00a0 github profile. After that's done as well and the\u00a0 report manager has all the required information\u00a0\u00a0 it finally compiles a complete and comprehensive\u00a0 report on basically everything that I do. It's\u00a0\u00a0 quite surprising how much information it has about\u00a0 me already just from the top 3 search results. \u00a0 Honestly, I might even try to deploy this\u00a0 system in a cloud and run it every time somebody\u00a0\u00a0 schedules a consulting call with me to prepare.\u00a0 So make sure to schedule if you are interested\u00a0\u00a0 in agents swarm spying on you. The total cost for\u00a0 this entire scrape were around $0.67. And for the\u00a0\u00a0 OpenAI widget test, the costs were around $0.80.\u00a0 This might be considered a bit high, but in my\u00a0\u00a0 opinion, if your use case is valuable enough or\u00a0 if you already have someone performing this exact\u00a0\u00a0 process, it more than justifies the means.  However, it is possible to significantly drop\u00a0\u00a0 these costs if OpenAI releases\u00a0 a few more features.  \u00a0 First and foremost, currently you cannot use\u00a0 the vision model in the Assistants API, which\u00a0\u00a0 means that the browsing agent is still somewhat\u00a0 blind and relies on external tools to interpret\u00a0\u00a0 the website It works really well, but when OpenAI adds\u00a0\u00a0 this model to assistants and allows us\u00a0 to call functions directly with GPT-4v,\u00a0\u00a0 it will change everything. Secondly, there may be additional\u00a0\u00a0 tools required. For example, I noticed\u00a0 that it sometimes struggles with pop-ups,\u00a0\u00a0 so if someone could contribute a \"close pop-up\u00a0 tool,\" that would be extremely helpful. \u00a0 Lastly, this system could benefit from\u00a0 some form of cookie transferring mechanism,\u00a0\u00a0 that would allow users to transfer cookies from\u00a0 their own browsers. This would eliminate the need\u00a0\u00a0 for the browsing agent to log in each time. Once again, all contributions are welcome\u00a0\u00a0 on github. In the next video,\u00a0\u00a0 I will attempt to create an agency that generates\u00a0 other agencies because, to be honest, most of\u00a0\u00a0 the code for the browsing agent was already\u00a0 written by ChatGPT rather than by myself. \u00a0 So it s the only logical next step And if you want to deploy your agent\u00a0\u00a0 in production one of the easiest and most\u00a0 effective ways is to embed it as a widget\u00a0\u00a0 on your or your clients website. You can easily train it to answers\u00a0\u00a0 customer support tickets, generate\u00a0 leads or even recommend products. \u00a0 For this make sure to checkout my\u00a0 previous video here where I show you\u00a0\u00a0 how to do exactly that with our new product\u00a0 [oai-widget.com]\u00a0 Thank you for watching, and\u00a0 don't forget to subscribe.",
  "duration": 11,
  "comments": []
}
