{
  "transcript": "welcome back to the 4ir podcast fourth Industrial Revolution navigating the changes of everything that is coming so this is our second episode and I have today with me a special guest and potential future co-host we'll see how it pans out we're still kind of feeling out the waters so this is Anna from Anna's Journal um she is a librarian by training who has left the library world and is now a product owner at a data company a tech company she did her master's thesis in artificial intelligence with uh gpt3 actually I think she was the first at her school to use AI in that capacity generative AI in that capacity so we are much aligned in our conversations we talk all the time um about Ai and business and everything else so yeah Anna thanks for jumping in and um yeah give us a little little shout out about yourself yeah yeah and I think St um I think you covered a lot of the high points yeah I worked in the library for a few years and then kind of saw the writing on the wall and decided to make a jum into the tech world and became very interested in AI again um it's a big PR comment day a lot of our early conversations were around Ai and um how we thought that his development was going to go and I did end up researching it um more in depths for my Master's thesis so um yeah Cy to be here I will probably talk a lot about my perspective both as a tech worker and as a librarian just because I do have that background it is just part of my worldview so don't be surprised if I mention a lot of books and such along the way let's see how is how is this any better that's a little bit better there we go um okay so yeah so the way that the way that I think that this podcast is going to work at least in the early days is where it's more of a didactic conversation which is a fancy term for just saying like we're kind of learning from each other and and rather than either debating or just presenting news uh you listeners will be along for the ride kind of a fly on thewall have uh listening to a legitimate conversation where we're going to bring various perspectives to the table various materials references that sort of thing um and so today I think there was two topics that you had in mind one was um and of course correct me if I I misquote you but one was uh kind of some some perspective from an early career person as a lot of companies start to Grapple with artificial intelligence and the implications and then what was the second topic that you wanted to bring up it was misinformation right yeah yeah misinformation and how AI might be used to combat misinformation because that's not a side of the story that we really talk about very often so I wanted to uh kind of get your thoughts on that and explore it a little little bit excellent yeah so uh to give a little bit of context um obviously respecting company uh you know IP and and everything else what can you tell us about your your career trajectory and how you got it got to where you are because starting you know masters of Li uh information science librarian and then making the jump into technology with a focus on AI and then kind of what you've seen so far so give us the the I guess elevator pitch or the five minute five minute uh story of your TR how I got to where I am and what I do and things like that yeah so um what I what I did is during the pandemic I started to study a lot more um technology a lot more about data and specifically um a lot of project management kind of stuff so that um when I graduated with my thesis I was able to go into product development at um at a tech company and kind of transition away from the library world and more into um kind of a more typical kind of tech worker role um but what has been kind of interesting to think about and what I wanted to talk to you about today is when I think about how AI is going to change things especially at companies like mine we are a data company is um I noticed that I'm in kind of a strange place where I'm no longer a student so I no longer have the option to maybe pivot what I'm studying or work on a different research project to pick up a new skill um in that way but I'm also I've only been in my company for about 15 months and this is my first job in this industry so while I have a lot of opinions and thoughts about Ai and what direction we should be going I don't have the seniority to be part of any of the decision- making um and so what's been kind of on my mind a lot is how does somebody who's in my position who's maybe more early career but is locked into a particular career path or industry already how do they kind of navigate the AI Revolution yeah no and that and that makes a lot of sense I get a lot of questions from people asking about like hey I'm about to finish my you know CS or csse or Masters or um people asking you know like what should they focus on for their master's degree and I guess one thing and let me know if you agree disagree or what you'd add to this is that um and and this has been true for many years is that what you learn in college often you don't end up using but it's what it's learning how to learn um and learning how to do you know work or or even work in uncomfortable things that are kind of unfamiliar or or you know new new subjects um that is one of the bigger purposes of of college because I I who was it I think it was when I was giving a talk to some college students or whatever I said look I started programming in Pascal and then C++ and I haven't used either of those in many many years but the foundational abilities that does stick with you so yeah just take take it from there like what just from from the education standpoint because you know master of information science Library science um you know what what I guess observations have you seen about kind of the portability of those skills because you know your your thesis was on artificial intelligence but and and but you're still not using it and it was an entirely different set of skills to become a product owner yeah yeah I suppose that's fair and um a lot of that has to do with the way that I decided to approach higher education particularly my Master's Degree which um was kind of unusual I was I'm the kind of person who has always had a lot of interests that were quite varied um and so I figured my best stry for joining the workforce wasn't going to be to learn one particular trade or industry so to speak but rather to learn a skill set that would be Broad and that would be broadly applicable so that I could then do a variety of things so that was that was very intentional on my part just because I knew this about myself and the kind of person that I am so I think that um it really doesn't get more a general purpose than a library degree honestly like because it is exactly that it's your profession your degree is in learning how to learn and learning how to teach others and so a lot of people when I introduce myself they're kind of surprised like how do you go from being a public librarian to a um to a product person at a data company and when you think about the information world and all of the skills that you need to navigate it um all of that is still encompassed under the umbrella of library and information science and so going from some of the classes where we learned about like Public Library development and um curation and such to the classes where people are working with data there was literally right down the hall like it was all in the same building and so it actually wasn't as hard to Pivot as you might expect and so you know this is one of the ways that I'm kind of for myself at least thinking about AI is that it's another skill that I can learn that again can transfer in a lot of different ways I think just picking up the basics of prompt engineering understanding how these tools work um and then I'm not as focused as on maybe mastering one specific tool or technique but more like the general skill set that I could then use in a variety of things depending on kind of where my career takes me that that's at least how I've I've handled it that makes sense yeah and so now that you're in the you're in Industry you're in Private Industry um and what like which skills that you you picked up were kind of the most unexpected uh benefits like the you know you you build your character sheet out at the beginning of the game and you you're like you don't know what's going to be useful and then oh I'm glad I put some skill points into that tree so like which ones were did you think were going to be helpful and which ones ended up actually being helpful yeah yeah no that's fair um I'll say that actually working with AI and having that prior experience you'd think that that would be like a huge selling point and that would come up all the time that oh you you studied with GPT you know back in the beginning um but no it really doesn't come up very often that the stuff that comes up every day and that I think has allowed me to be successful is more of the people skills that I actually picked up in the library just um the communication skills just being able to talk to somebody and figure out very quickly kind of who they are and what they need and what what level I need to talk to them at because um you know when you think about all of the different people that you might have to work with in your company in all the different departments they're going to have varying levels of comfort with technology and so being able to kind of quickly assess somebody's Comfort level and then maybe change like I don't talk to the engineers on the data team the same way that I maybe talk to somebody who's more on the sales or marketing side of things they need to know very different things and they need information presented in very different ways and so um and they're going to talk to me in different ways and I need to be able to figure out what is important from what they're telling me um and kind of pick that information out so um but yeah I don't think that um most people would go from the library world to Tech so but it is it is the most valuable skill set I have so take that for what it's worth yeah no and and well to to full for full disclosure I'm always talking about the value of communication skills um in any industry it's like a little bit it's it's Universal in work in family in relationships no matter what it is that you're trying to do or achieve communication skills are critical um now on the other side of that though there is the technical side and so you work with a lot of developers um from from many different places and uh then as you mentioned many many different teams so you see a lot of different sides of the business I guess pivoting towards uh kind of what you what you the meat and potatoes of what you what you wanted to talk about with respect to not being able to influence Direction and just kind of being along for the ride so what what is your perspective as someone whose early career and just kind of watching as a fly on the wall or I guess maybe you're a little more participatory than a fly on the wall but depends it is it really it really depends sometimes sometimes I am just that flat on the wall I think that that's one of the things that is kind of weird about being in my position is I feel like I know about AI I'm very you know in some ways excited and in some ways concerned about the ways that it might change the company and what we do and um you know I know that there are some conversations going on in the company about what we want our AI policy to be and I've made it clear that I'm interested in that and I have a background in that and I'd love to be a part of it but just for whatever reason like I'm not in those a part of those conversations and there really doesn't seem to be a way for me to be a part of them so um often things just kind of get handed down from on high like this is how we're going to handle AI this is what we're going to do and um and then I'm kind of trying to feel my way from there but it's maybe isn't necessarily what I think is the best or what I would recommend that we do some you know again I don't want to get into specific but some members of leadership seem more or less oriented than others um because you know just because somebody has a lot of background or experience in one area of Technology doesn't mean they really know the best way to handle Ai and the changes that are coming and I don't think everybody realizes that um and so if we really can't just do business as usual or what worked for us in the past might not be the solution this time around and so yeah I think some of it is just feeling a little bit frustrated on the one hand and then kind of vulnerable in some ways because I am early career so if I don't get this good experience now there is that kind of threat that well you know if AI does result in layoffs at my company it might be harder for me to get another job if I don't have experience working with AI myself so like these are the kinds of things that are going through my brain and I will say s caveat like in terms of how worried I am I am not super worried because my job is still very very focused on relationships being in product and the ability to talk to people and maintain relationships is still very much the core of what I do but I think that you know I think about my brother who's a software developer and I'm thinking like a software developer maybe for instance with who's in my position with um who's a little bit closer to to the machine so to speak like I might feel a little bit more vulnerable is that was the core of my job so that was a lot of things that I just said um I don't know if that that all makes sense yeah well so I mean there there is there is a lot to unpack there but I A friend of mine um was he's he's one of the guys that I've worked with on stuff like cognitive architecture and he's always doing like we were working on agents before they were called agents and he was trying to push AI at his company which is a big big local company and he was just told no just flat out no and then a few months later it was just announced like oh we're going to start using chat GPT now because legal department wants it and so he learned one of the Cardinal rules which is legal gets legal gets what what legal wants um and he was just like what what the hell um and so this is not an uncommon thing particularly at larger organizations and when I was still doing consulting I was contacted by several organizations who wanted me to come in and do training um and it was just really basic stuff and ultimately I I told them all no uh for for a number of reasons um sometimes the the outcomes that they wanted were kind of I don't want to say magical but they just had kind of unrealistic expectations they didn't really know what they were asking for um and and in so in one case the leadership did know what the tools were capable of in other cases the leadership had no idea like as kind of as you said that that you know this is a shiny thing that we need okay great um so I guess to to get now now that we're kind of into the weeds there's two directions I want to go so one is what from from from the bottom up perspective what would other what what would you want leadership you know middle management or upper management in companies to be aware of and be thinking of what is what is it that they need to know that they don't know or what do what do they need to be thinking about that they aren't thinking about but then the other half of that is what do you think would be good for people like you like what resources do you need or what advice would you give that sort of thing in in terms of you know uh surviving or pivoting in this in this space yeah yeah no those are um those are those are good questions I think to the first one in terms of like what would what would I need to feel more comfortable more successful whatever I think that you know if there's anybody who's listening to this who is a manager or somewhere in the management I think having really really clear expectations or guidelines or even like company policies around AI use would really really help because I know one of the things that has been kind of challenging for me is my it Department basically came down on from on high and said don't put any anything related to the business into um into a language model which okay fair enough but um anything related to the business that I mean depending on how literally you want to take that it becomes very unclear what I can actually maybe use a large language model for because I was thinking maybe I could use it to help me write emails or write tickets for my developers but if I can't put anything in if I'm taking that very literally then um I really can't use GPT or any language model at all to kind of help me do my job and so there needs to be I think some more clarity around like okay what what does this actually mean um and because I know that companies obviously there's security issues they want to keep their IP safe um and all their proprietary knowledge and data safe um but there also needs to it needs to be clear if employees can use AI tools and if so how um because I think that lack of clarity means that either I can't use it or if I am using it I'm doing it very low-key like in secret on the side and I'm not talking to my co-workers about it which means we can't learn from each other and we can't Implement more systemwide solutions to problems that use AI so that's the first thing is I think that Clarity is really important um and then the second is I think just being more open and having conversations about it one of the attitudes that I see is one is kind of a weariness about Ai and two is concerned that it's um feeling like it's kind of hyped up and I think that that makes it kind of hard to tell how people are really feeling about Ai and what we can realistically do um if most of the conversations are about like well we don't want to we don't want to get on the bandwagon you know and that's kind of the end of the discussion you can't really move forward that's not like a long-term stance towards AI that's kind of a current knee- reaction I think to what's going on so um yeah if that makes sense um so I think just Clarity and more open and honest conversation because I think and you know Dave I've talked to you about this before that I think that one of the things that really needs to happen is for a company to really become comfortable with AI that's something that has to happen at all levels and all departments throughout the company and a lot of that is going to be in the efforts of individuals and teams to experiment with tools and tactics and figure out what works for them and to share and learn from each other and that's how you build Comfort that's how you build AI literacy and um that's how you begin to build up to these kind of Greater innovation that yeah you can have like a designated AI team that's kind of off in the corner doing something and maybe that will be the next big breakthrough for your company but I do think that the responsibility to become comfortable and to innovate it is on everyone and so I think that removing barriers to allow everyone to participate is um is really like the most the single most important thing that you can do for your company it reminds me of uh one of our friends who is a teacher and was like oh yeah like I use chat GPT to like make make quizzes and tests and um and I I've heard of other people using it to help start grading as well and but the official policy for many school systems is you know don't use it and I was like oh have you talked to other teachers about it and she's like oh hell no yeah underground yeah right yeah and so it's like well it's it's it would be like trying to tell people like you're not allowed to use smartphones anymore like keep your phone out of the office like everyone's everyone's using it the the technology is too compelling um and and yeah just like confronting it and just saying hey this is a thing it's happening no sense in ignoring it or or suppressing it and so then the other the other direction was um was how can people in you know early career how can you adapt you know you give an example of if you're a software engineer who's a little bit closer to the metal versus someone who's a little bit more people oriented um certainly I I would tend to agree that if you are able to you know handle relationships the emotional intelligence the communication you'll probably be uh insulated for a little bit longer um because if if your job is primarily writing code um even even though AI models are not that good at writing code yet they can do it fast and cheap and then you can just iterate and fix it automatically like you know so I and that's not to say that I think that like software engineering is going away quickly but there are certainly people that are worried about that and one thing that I've pointed out and people have started to take notice is that high dollar jobs tend to get targeted first because if you pay a bunch of developers you know $200,000 a year $150,000 a year even if the tool to replace them cost $80,000 a year but it can replace five or 10 developers it's worth the cost and so that is something to keep in mind now obviously there's lots and lots and lots of different job functions many many kinds of roles are going to be more insulated from AI than others you know there is uh just just earlier today I was reading about how another company laid off 90% of its um call center staff yeah so there's there's lots and lots of of things that you're seeing are are actually higher risk than you might think um but for those the for for the skills that you have that you see is really durable what can people do to develop those skills and lean into them um or diversify those sorts of things yeah yeah those are really good questions and um you know I think a lot of the the standard advice that I see is is use the tools and you know I think that that is one answer but I don't think that that's that that's that's enough I think that um that you know it is important to know how to use the tools and to show proficiency and um you know I think that that's going to be as necessary as just your ability to use things like you know Excel and Google and stuff to be able to do your job um so absolutely but I think that more than being able to use AI tools themselves I think that actually doubling down in the communication skills because that has been at least for me speaking for myself where I found the most success and by communication skills I would I don't even mean just writing because you know language models are pretty good writers but um specifically like face-to-face communication like um can you lead a meeting can you talk to people on different teams can you talk to people in the sea level um things like that just your ability to build and maintain relationships I think that is a scill that that can be undervalued in the tech World especially for folks who are not in management but that that is something that AI can't do yet and might not for a while um because you can't have a personal relationship with GPT not yet well some people do AI girlfriends are a thing but we're not going there but um but you know what I mean it's so that that's a skill set that I would kind of recommend I remember back when I was in graduate school somebody saying something about how often with tech work it's your technical skills get you in the door but it's your social skills or your interpersonal skills that allow you to get promoted sorry my table wobbly a little bit but I think that's really true and that in today's world that's even more true than it was like four or five years ago when I heard him say that this professor say that so yeah I think those are really my two big pieces of advice is one is um has have Proficiency in the tools that are coming out now so you know what they are and how to use them um but in terms of what to really stake your your hat off like hang your hat on I would say the interpersonal the interpersonal skills that those are going to be more more and more valuable the more kind of lower level kind of work or I shouldn't say low level I mean um you know a lot of the work that people do is very conceptual and difficult but more um 2D on the screen just you and your computer kind of work I'd say that that is a little bit more vulnerable yeah so a couple things one one is a rule of thumb that I have said and I've now heard other people say it I don't know if they heard it from me or we just converged but it's basically anything that you do exclusive ly on a computer is potentially vulnerable um if if if it's not something that can be done in person um then then it's vulnerable and then the the flip side of that is actually an interview that I had I think it was on my systems thinking Channel I think it was actually the first systems thinking interview that I did um was basically just treat AI like a basic competency treat it like you know the same that you would treat Excel you know competency email literacy uh basic internet you know function literacy um AI just need if you start to treat it that way in your company um you say okay everyone needs Baseline level understanding if you can use a keyboard you need to be able to use email Excel and AI um so yeah I think that that would be a good policy um and of course that goes all the way up it's uh you know sometimes middle and upper management is you know do as I say not as I do um and if they don't understand it um themselves and it it there is definitely so my most successful um uh consultation clients they those were the ones where everyone up to the CEO the owner the founder whoever the you know top dog was using AI all day every day those were by far the best um clients that I had I have had other clients where the CEO was just like you know instructed some some underlings to investigate it um and they're like and some of the questions that I would get is how do we present this to our CEO so that he gets it um but in in cases talking to the CEO or the owner who gets it and then they just wanted to talk you know talk shop talk strategy um so yeah I think everyone in the organization should be using this stuff even if you don't find Value in it you should at least play around with it just so you know what it's capable of um yeah go ahead yeah what I would say to that is I think one thing that's really important to keep in mind is that AI is taught us to technology it's a paradigm shift and like any Paradigm if your company is going to adopt it it has to be adopted from the top to the bottom and the bot the top it's kind of like um other analogy I would use is something like agile and how like every company says it's agile but are they really agile and just for for a company to be truly agile it is something that has to be adopted at all levels and everyone has to understand it otherwise you end up in a kind of like pseudo agile environment because it's it's again it's a paradigm and you can't run a company based in a paradigm if only like a couple people scattered throughout the organization or a couple people at the top are the only ones who actually believe in it right what is what do the meme it's like we've we've tried nothing and we're out of ideas time to give up yeah no I I I suspect that we'll see a lot of that in some businesses um either within businesses or even as a whole right because you've talked about how sometimes you see people that are kind of like ah well and and this is this is not unique to any particular business um I think it was one not maybe it was a Gartner report or a similar report that something like 40 to 60% of CEOs are still taking a wait and see approach to Ai and I'm just like guys you guys are falling behind but this is you know the the adoption curve right you know crossing the chasm um AI is about to LEAP across the chasm uh in a big way I still in taking a big step back I think that we're probably still in the before times you know we've got we're at the we're the the bleeding edge and then the early adopters but we're not yet to the early majority I think the early majority will probably be this year and or next year um I don't know what do you think about that or am I too too early I tend to be optimistic in my timelines but I mean it's I think that we're I think that's where we are it's just a matter of when it becomes early majority yeah yeah it's a really good question and there's kind of two ways to look at that in terms of like when do you think that majority of people are going to be on board with this and um you know and one of the ways to look at it is you can look at it and in terms of the pace of the technology itself but also when you look at um how quickly are people to actually make the adaptation because just because AI is just soaring through that whole industry is just soaring through like big like Breakthrough after big breakthrough doesn't mean that every person is going to make a change every time there's a breakthrough like I don't know about you but when I talk to a lot of people particularly people who are not in this space they're about AI is pretty similar to where it was six months ago even though you and I know that a lot has happened in the last six months and so there um in some ways like the chasm maybe isn't as like it's not like a nice neat clearcut Chasm it's a pretty messy Rocky Canyon that we're trying to get over so you know in terms of when the folks are seeing wet weit and see when they'll kind of get over that and be ready to make the leap I'm really I I'm honestly curious what it would might take for some folks to feel like yes there is value here um because so much value has been demonstrated over and over so a lot of it just might be it might just take time for things to become more normalized and for things to stop feeling so new and shiny you know even there's a part of me that wonders if maybe the speed of breakthroughs is part of the hesitancy that some people might have because it might seem it might just be too much for them to keep track of and it's too overwhelming and how do you begin to familiarize yourself with something that's constantly changing especially if you have no kind of Baseline to go from um and then there's also the fear of if you don't if you're not already comfortable with AI and in this space how do you tell the genuine breakthroughs from the hype and I think that that creates a lot of anxiety and might cause some folks to retreat further yeah so it's kind of a cynical answer but so um what I will say because I was just thinking as you're were talking is the rise of the internet that was that was my mom's generation because she was in technology so she was there um with internet adoption at big companies um and for for me in my it career it was Cloud adoption so when I got started Cloud was not really a thing um public Cloud was was very very small I think Oracle was one of the only public Cloud providers and of course now we have Amazon and Google and and Microsoft Azure and everything and and many many companies have those um you know hybrid Cloud Solutions multicloud Solutions those sorts of things so having gone through a paradigm shift and of course I will say that where your data center is located whether it's on Prem or hosted or public Cloud that is um because you know having having hosted data centers is is very old um that's nothing new and so you could say that that was like private cloud or whatever you know but going through this Paradigm artificial intelligence is a bigger paradigm shift this is like as big of a paradigm shift as going from analog everything to you know modern day like that's going to it's going to be as big and it's going to happen much faster and I had another thought but it ran away um so if you have any follow-ups to that thought or we can move on to misinformation and disinformation yeah no worries um why you're waiting for that thought to come back something that did occur to me is um about cross-cultural adoption of AI because most of the people I hear talking about Ai and how we're going to use it in our companies are mostly folks in the US and the UK my face and um but you know when I think about how my company is global you know I have co-workers um in the US in the EU in um just all over Europe and Malaysia and then also in India but it's mostly only the US and the UK folks that you're talking about AI in my company and so I'm kind of curious like especially in a global interconnected world what are other people and other places saying about Ai and not just us because I feel like us we being Americans have kind of been monopolizing this conversation so I I don't give any Insider thought into that yeah I mean I have a I have a pretty Global audience and so there uh I I think I think the the continent that is most behind is South America because I have people from like Brazil and Argentina and Colombia they're like yeah nobody here talks about this like they they can only get their AI conversation online from Europeans Americans U Asians and Indians basically um and so there is this huge asynchrony oh I also have a a pretty good contingent from Africa um interestingly enough and I think some of the I think some of the tech centers some of the tech hubs in Africa they're paying a little bit more attention um but even some people from like South Africa they're like yeah nobody here's talking about it um so but you know I have people um chiming in from like Kenya um and I even had some people from Ethiopia so you know there's obviously with with internet penetration the the uh once they want to know about AI they'll have access to it but another thing to keep in mind is that a lot of these um the the the flagship models they're only available in America and Europe and a few other places and for in some cases it's due to export control laws you know dealing with cryptography uh laws and those sorts of things and in other cases some of it is adoption because was it I think it was Italy tried to ban chat GPT briefly um and then uh I think it was Spain and Portugal have banned worldcoin so there is a lot of push back and a lot of skepticism even at the federal level of of many nations um which I think is I think is warranted but of course America is more like a you know better to ask forgiveness than permission kind of mentality um yeah but and I guess that's actually a good segue to go to misinformation because speaking of break it first and then apologize later right like what is what is your greatest fear on misinformation because you wanted to bring up this as a as an Avenue of Investigation for today yeah yeah I mean I'm sure I don't need to tell anybody that the potential for AI to spread misinformation disinformation is kind of horrifying especially with the image generation and now we're even seeing um stuff like video generation how do you believe anything you see with your own two eyeballs anymore um but kind of a side that I wanted to explore with you that I don't hear talked about is is there a good side of this you know is there potential for the AI to police itself um for us to use AI to um either slow or stop the spread of misinformation or even to just will it force a restructuring of the information landscape that might kind of make us all better in the long run I don't know these are some of the ideas that are kind of in my mind just trying to be a little bit more maybe not quite so do day about the whole thing yeah so I I well first just want to validate that like yes these are new tools that have the ability to generate um information on a scale that has never been seen before now of course people will say you know faked videos nothing new faked articles nothing new yellow journalism nothing new and so one thing that we can touch on is what is the difference because misinformation and propaganda have been around for you know as long as there's basically been humans um but this of course is a new technological vector and another attack Vector um but then the other part of that is like your question like what is the good side of it and I will say so I have I have a a good example and that is there is a new search engine called perplexity which perplexity basically takes old school search engines and overlays AI on top of that and so you ask you're you talk to the it's you have a you know familiar chat interface and you you ask it your questions or whatever sometimes it'll ask for clarification which is really good it kind of performs a miniature reference interview like hey are you asking asking about this problem from a neuroscience perspective or a psychology perspective and I'm like all of the above like just find the information for me um so it's not it's not perfect yet there are definitely things that I would do differently with perplexity but then it will create a handful of search queries and it'll go automatically search the internet for you and some cases it'll only find a few references it'll find like four or five references in some cases it'll find more than 20 and it'll read all of those sources very quickly and it will give you better information uh and so there is I I listened to philli over at AI explained he interviewed I think it was the founder or the CEO of perplexity um so I listened to his podcast and and one of the ways that they characterized it is that we're basically entering into a new paradigm of access to information and in this case uh the the the information tool is not just Google handling handing you what has been SEO optimized and it's not just whatever you know rage bait comes up at you know first first thing that you click on and so I I have an example of one of my patreon supporters on Discord was sharing links that were um I'm not going to say disinformation but it was it was from more Fringe sources um some less reliable sources and I I kind of pushed back and I said hey like you you you should broaden your information diet you should make sure you're you're taking in better sources of information different sources of information because this was someone who had clearly kind of been herded into a very particular information foraging area and so then I just posted a perplexity link I did a few searches to say like hey here's problems with what you're sharing and then I saw later on he was sharing perplexity links so just giving someone a new tool like raises the level of information literacy and media literacy by giving them the right tool then they don't even need to know what information literacy is or media literacy is they're just automatically going to be exposed to a broader cross-section of information with explanations as to what the controversies are and then it's also interactive so in that respect I have hope that as Siri and Google and Bing and all of the other ones become AI enabled that our access our our our relationship with all information is going to be a little bit better now of course some people are going to say oh it's too woke and they'll ignore it with I mean you can't you can't help everyone um but certainly many people it'll have a large aggregate effect and I even use it to fact check um like it comments on my YouTube channel if someone says something that I don't either I don't understand or don't agree with I just I literally just plug in their comment to perplexity I'm like is there any legitimacy to this and you know yes or no it will'll find some sources and it's very surprising um but it's also it it takes five seconds it's so it's so fast now so we there is a glimmer of hope you know me I'm an eternal optimist so um that little glimmer of hope is like a supernova on the horizon for me so like there are a few really interesting things I want to pick out of what you said first of all um I haven't used perplexity yet but I'm really curious now so always think thank you for for sharing that um that is a tool but I think what you said there about how by giving this person in your comment section this tool that they were able to go and solve their information problem without improving their actual information literacy I think that that's actually very important because something that has always kind of bugged me about the way we talk about misinformation is we very much put it on the individual to notice and figure out when they're being lied to and make a different choice and I'm not sure how effective or realistic that is I mean yes it's good to educate people and for people to practice being able to spot bias Etc but when you think about how this kind of assumes that we can teach everyone to be a rational actor as a lone individual a lone rational individual in the middle of an information ecosystem that is much bigger than they are that is mostly automated and that is designed to pick at their emotions not their logic brain but their emotional brain um I don't think that that's really or I guess I should say how how fair is that really is that even how we should be framing this problem um as an individual problem or is in more of an issue of systems um and as you pointed out with the example of this tool like you could spend hours and hours trying to teach this person how to tell real news from fake news you may or may not get anywhere or you can just kind of change the way that they interact with search engines by building a better newer search engine and a new way to find information and that solves the problem not just for that person but for everybody so do you have any thoughts on that idea well first is that um there are actually many European nations that have as part of their required courses in primary school I think it's I think in in I think in in the Nordic countries and in Scandinavian countries it starts in media literacy starts in elementary school but I remember seeing a post um in that in Germany I think all high schoolers are required to take a class called American propaganda and so they they specifically learn to understand and identify American propaganda and I'm just like well you know yeah hey hold up a mirror to us so you can have that as a as a public policy um would that ever fly in America absolutely not um I the the the education system in America doesn't even really cover the for the you know the the the Common Core anymore and the Common Core like there's so many things that are missing from the American education system we don't spend nearly enough time on communication emotions relationship ship basic life skills and I know there are I have had parents in my comment section that have said that like there are school systems that are doing it better but the fact that it is just it's a crapshoot it's totally random and it can even be schools in the same district will have different levels of of um of sophistication or or modernization uh with respect to some of these essential life skills um now to to Pivot to like the tool s um it's kind of like the difference between you know 500 years ago you learned mostly from your village right no 500 years ago most people were not literate um the only people that were literate in your village were probably you know the priest you know um and the local landlord if that and many landlords weren't even in medieval you know France and Spain and whatever uh and so then as as information Technologies expand you know printing press uh and then eventually uh mass mass produce print newspapers that sort of stuff uh books became bigger and then electronic communication radio television and there's this like it's it's kind of tapered off but there has been this sort of like oh you know America was less politically divided when you know the the politics was just a short News segment you know and and and it was only PBS and and you know a handful of of TV stations and they gave both candidates equal and there was not really any partisan news but of course now there's CNN and fox and you know the 247 news cycle websites and channels and stuff has has all proliferated and they have become increasingly divisive and created Echo Chambers um fortunately what I'm seeing is that uh gen Z in particular are we we often talk about this how in some respects they're far more savvy than every other generation but God they are also are still really gullible some of them um the ones getting most of their news off of Tik Tok but then at the same time I see a bunch of gen Z people reminding each other hey like there's Bots out there and they just know not to trust things and so it's this this really weird like almost dichotomy and uh but seeing another generation coming up that you know our younger siblings or nieces and nephews and whatever that are now teenagers um or or almost teenagers and they just know this stuff because they heard us complaining about it for years and then of course there's the horrifying things of just how incredibly gullible the boomers are um with AI generated images and text um but even still it's like is it even Boomers or are they all just Bots actually some of my patreon uh supporters want me to talk about the dead internet Theory like is it all just Bots talking to each other now that are even smarter um than they used to be so I'm like I have no idea I love this Boomer Boomers don't actually exist they're all just butts you go home you talk to your family Thanksgiving don't worry they're not real they're just NPCs oh no but yeah so that's my Spiel I don't know if you have any reactions to that I probably only answered your question sideways it's it's okay sideways answers are still answers no I mean you a while ago you asked the question of why is What's Happening Now different um because I think it is like you're right that misinformation is always existed um I learned a really fascinating and disturbing example recently um um about how um the witch hunts were actually facilitated by the invention of the printing press and so a lot of what we think of as so the worst of the witch hunts we tend to imagine them happening during the Dark Ages but actually they happened during what we call the early modern period um after the printing press because um witch hunting pamphlets um and books that would teach people how to identify and um how to identify and um try witches were were circulating so you know that's so that's like one example of from the very beginnings of mass media really you have disinformation misinformation being spread um with really like horrifying outcomes so this has always been a part of information in media history like as long as you have mass media you have this kind of thing going on so um so to that extent like you're right that this this has been going on for a very very long time but I think that is different now is um is one is scale and um two is I think the way that so many of these systems work off of each other you know I remember when I was in graduate school reading a fascinating study of where conspiracy theories came from and because everyone thinks that it's social media it it's if I were to ask you like Dave where do you think Conspiracy Theory comes from like you probably would guess Twitter or X or whatever we're calling it these days but it all comes from Elon Musk that that that is one Theory um but um what this study showed was actually most conspiracy theories originated in social media but they didn't really gain momentum until they were picked up by Major broadcasting networks mostly Fox News and so Fox News would begin reporting on a very small community that had this Fringe Theory and then suddenly everybody would be talking about it back on social media so you had this weird interplay of like different systems and media systems kind of both newer Web 2.0 ones and older traditional broadcast models kind of feeding into each other to create this like Cyclone of Terror um and so that's something that I feel is like that is very modern and that is very different and yeah now I think that's all I have to say about it yeah no it reminds me of a podcast I listened to a while ago about um some of the I think it's there were some of the OG infodemiology researchers and how in the past information you could it would it would literally spread like a plague um because it would be person to person um or over you know one talk show host you know over on the west coast and you could track the idea spreading from the west coast to the east or whatever um or with the publication of a certain book you know but what they found was that with the global interconnection you have multiple layers where it's almost like a bunch of gopher holes where you have cloistered communities you have you know Echo Chambers or or whatever and you can have ideas spread instantaneously so like the the kind of the prime example that they used um at the time was um anti-vaccination sentiment and conspiracy theories where you'd have Mom groups uh that were Global you'd have Mom groups that were in America and Australia and so on and so forth and of course what we're finding out now more recently is that many of the members were actually Rush trolls um or Chinese trolls in in some cases and so it's just like you know just causing deliberately causing chaos but then these ideas they become sticky and contagious and they are very very contagious uh but they also spread more uh I don't even say erratically it's just random it's almost like pure Quantum entropy where it's like you put it you put a a poison pill in this community over here and it pops up globally and actually I'm reading a book by Peter diamandis um called abundance and he actually talks about briefly but mentions the fact that because we're in this globally interconnected thing the rules have changed completely because of the internet because of social media and even though the internet has been around I think it the worldwide web officially went live in like 94 95 96 so we're coming up on 30 years of worldwide web and we're still figuring out the rules of this new thing we're still discovering what the internet can do um and we're we I think we only just passed like five or six billion you know people on the internet maybe not quite um so we don't even have the entire human race on the internet yet and so we're still in the middle of that Trend and we've already got AI is going to make it even even worse uh or better in some respects if the tools are used correctly um but yeah so that's that's kind of some of my off-the-cuff responses um I don't know that there is any easy solution uh as you know cuz whether or not you legislate it you can't stop the signal right like there are some things you could do from a legislative perspective but you know Well here here's something else I've been thinking about lately is um and this is this is kind of a hot take so feel free to do it oh fun let's go I I love to sing things out there and see what happens but um like what if it isn't AI itself as the problem but it's rather the ecosystem that we're throwing it into that's the problem um because you know talk about AI like it's this new uniquely evil thing but what we're really worried about is uh how misinformation is going to be spread more easily across social media and confuse scalable people like and that that's a problem that's already existed and been getting worse for really since the Advent of social media and so my question there is is AI really the problem or is it just maybe the newest maybe more dangerous symptom of um an information disease even that's been around for a long time now and AI is um this is something else that kind of gives me hope is that maybe AI will be the thing that finally causes us to step back and maybe examine the way that we talk to each other and the way that we communicate with each other because um social media is not the it's not the only solution to how we talk to each other online search engines and SEO again it's not the only solution for how to find information out in the world um you know things like perplexity that you were just talking about show that there are other ways to organize and find anded information so maybe it's not about AI maybe this is about changing the ways that we find information and share it with each other and maybe this is the crisis point that we need to actually maybe step away from some of these systems what what do you think of that yeah so this touches on a few things so one thing that I've been thinking as I'm reading these various books and so the the first thing that comes to mind is by Ray Kurtz where at the beginning of the age of spiritual machines he talks about this model of reality um which is that as uh as order increases the rate of changes also increases and as chaos as order decreases and as chaos takes over change slows down and so the example that he gave was at the very beginning of the universe um in the first few milliseconds of existence we went through three major Paradigm shifts of how physics worked energy matter everything you know gravity didn't even exist until I think you know the universe was like 0.13 seconds old because of how fast things were changing but the universe started very ordered and then as entropy increased the rate of changes in the universe slowed down drastically and so like the first galaxies emerged and then here we are 14 billion years later and the universe has not gone through a an ocal paradigm shift in billions of years now conversely on a smaller scale human evolution is accelerating and order is increasing and part of the way that order is increasing is through our information technology and so the internet was an accelerator that was like pouring gasoline on a fire because now information knowledge can be shared far faster and what occurred to me is that AI actually brings even more order to the information landscape because now we have models literally you know within within the last few months all the AI companies have run out of data they've trained on literally all the data that we've that they can get their hands on all the high quality data obviously there's plenty of noise out there that's not worth training on the the signal to noise ratio is not not the best in all data but in terms of all Salient poignant valuable data they have trained it on and so that compresses all of human experience and knowledge into a single thing and that increases the amount of order drastically and that will be a major major accelerant as part of this paradigm shift and so that's one of the core things because um what occurred to me as you were talking is hang on let me bring up my notes is and this is something that you have talked about is that um information technology is never neutral so we can talk about like how libraries are never neutral like what books get banned and pulled and what doesn't um but you know net net neutrality so this is actually something that has been discussed um you know the internet is supposed to be a neutral impartial just a highway just a road system for information that anyone all information is treated equal um but because of that because of the affordances of a truly neutral internet where there's no censorship no throttling no Fast Lanes which I agree in principle due to freedom of speech and plenty of other things but that also paves the way for you know the internet basically wants attention if you if you look at the Spirit of the internet like what does this entity want it just wants attention that's all it wants yes it's it's it's a very very needy it's like a histrionic person who's just like pay attention to me like that's what the internet wants and uh but it has no agency that is an emergent characteristic of the internet of the fact that it is a it is an Information Network what it what does it want to do it wants to provide information and how does it do that by getting attention how does it get attention by finding the algorithms that are either going to make you horny or angry or both you know or whatever right it's going to it's going to exploit all of your emotional vulnerabilities all of your neurobiological failures because we did not evolve in this kind of information landscape and so then the difference though is not only does AI flatten the information landscape so that you have basically Dem Democratic access to all knowledge more or less in an interactive entity um AI can also be given agency as we've seen with the way that it's being trained you know chat GPT and Claude and all these other chat Bots will refuse to engage with certain behaviors sometimes comically misguided guard rails like where you know for a while their Gemini from Google would refuse to engage with you if you were white basically it's just like I'm proud of being white and it would just like shame you for saying that you're proud for being white they have since fixed it um but it shows how fr this space is with now we have a we have an information technology that is hyper compressed that does flatten and democratize access but also has agency it can also decide what to do what to say and I think that that is a structural difference and and you know the the in cases of the tool of perplexity it there are some improvements that I think that I would make to it to make sure that it had better search queries um but there's also probably lots of stuff going on behind the scenes that I don't see but still it is a good enough tool that knows enough about information literacy in its design the affordances of its design and it will also disagree with you and push back if you're pushing things that are not represented in the data now there's a few problems with that because like I was having an argument with perplexity about burnout versus um adrenal fatigue and it was like fully engaging in medical gaslighting it was it was like what is burnout and it said burnout is an HPA access disorder about blah blah blah blah blah and I'm like cool now what is adrenal fatigue and it said adrenal fatigue isn't a real thing and I'm like but it's an HPA access disorder and it's like no I'm not going to engage with this and I'm just like oh my God this is like so you know it the establishment says a thing and it and it echoes you know the sentiments of the establishment which of course many people will take that as evidence that ah it's too woke or you know it's being controlled by the corporations or the governments or whatever but that's a you know know maybe it's a bigger problem than than than I would think but I know enough about how the system works and how information Works to know what the failure there is the fact that it was not allowing any Nuance in the conversation and even when I said search again and it did find clinical evidence of burnout and adrenal fatigue it still defaulted to the mainstream opinion that it wasn't a thing and so I'm like hm how do we have a tool that has agency that wants to find the truth but they can handle Nuance right because it you know and and maybe maybe maybe I'm wrong to make the assumption that actually finding the truth is the is the goal because sometimes people just want to be told what you know they want to have their beliefs confirmed but I'm also thinking like what if what if you know our younger nieces and nephews and children and younger cousins grow up with a tool and they just know okay this tool isn't perfect but I can just ask a question and it's going to give me more or less a good answer that's going to look at from all sides right off the bat um but so I know that was a lot but you know it has to do with NE the neutrality of Information Technology is kind of the big theme Here Yeah well I really I think that's such an interesting take on AI is that it might not be something that's an agent of chaos but rather something that imposes order on an otherwise chaotic space like that's a really interesting idea that I haven't I haven't heard before and you know I think even stuff like what you were just saying where when you talk to chat Bots you will often get the one standard narrative that's almost like an extreme that's almost an issue of an extreme order rather than the extreme chaos that people are afraid of you know you have everything distill down to one single narrative that the chat bot is going to share and it will talk about anything else um yeah that that's not a chaos problem anymore um that's a problem of being too rigid and too narrow in terms of the information that you can access yeah no and in terms of of neutrality um you know it's just one of the things that I that I kind of wonder about is and I know a lot of people are worried about this but kind of who is building these spots and what kind of values are they teaching it and what is the what is like the lived impact of those values on real people here in the world because I I I will give everybody the benefit of the doubt and say that I think most people who are working on AI probably are aware of the risks and are doing their best to create something that's good and ethical um you know I'm sure that there probably are some bad actors out there but I think a lot of the folks who are behind this development are are really trying to be responsible but that doesn't mean that um what they're doing is necessarily going to be neutral that there's going to be a set of values that are imposed and whose values are those and are they necessarily like the best ones for Humanity right well part of part of the problem that I have observed and it is still a problem um there's only as far as I can tell there's only one company that has made what I would consider like real substantive progress on finding you know a a broader more Universal set of values as anthropic um whereas most companies are treating values alignment and ethics alignment primarily as a math problem yes and many of them are are are approaching it primarily as a math and computer science problem and they are not nearly as as uh well read on ethics and philosophy as they would need to be um or human history or anthrop anthropology or psychology um now that's just of course my personal opinion and uh but W with with that being said I do I do think that anthropic is um by far in the lead in terms of in terms of un truly understanding what values to give these machines um that is going to be kind of one of the one of the shorthand ways of saying is which set of values is going to result in the greatest good for the most people um kind of very utilitarian um Outlook yeah no and um I I think it's it's a valid criticism though of computer science as a discipline is um I remember being kind of surprised being in information science which is um very close to computer science like it's they're very much sister disciplines we had a lot of compsite people come and take classes with us a lot of the infoscience people would take classes in the computer science department there there's a lot of overlap between these two fields but as an information scientist I remember like from day one having it drilled into my head like this is the code of ethics like here are all our professional organizations here are their official codes of Ethics that you are expected to learn and adhere to and if you ever are in doubt as to how to make a decision you can refer back to these and that was all just hammered into us as information professionals and I I don't think there's an equivalent of that in computer science and that's not just say that they're all unethical they don't know what ethics are but just that emphasis I think is very different and I have always kind of worried about that that so many of the people who build the systems that govern so many parts of our lives that they might not necessarily have that background or that emphasis in their training um you know as well as I know Dave you and I have talked about um this kind of broader neglect of ethics and philosophy and the humanities by the tech sector and how you can't treat everything like it's a math problem um that there are a lot of kind of fuzzy or gray areas and um conundrums that you really you really can't optimize um in the same way that you might like a more typical Tech problem and it's it's not it's not good or healthy to assume that you can yeah no and and I'm just thinking through this and as an IT profession profal um professional ethics were a big part of the training um it was not necessarily enforced there was no like accreditation or or lure that was required but I'm thinking of of lawyers and doctors um both of whom have uh ethics as a as a core uh value that is taught um probably lawyers even more so than doctors um where it's the ethics are are highly articulated very well articulated in terms of what is um like what what can get you disbarred as a lawyer if you you know violate the TR you know um client client lawyer uh confidentiality for instance um and many other uh conflicts of interest that That Could That Could arise and so the the fact that there is a professional thing granted it's a licensed one you don't need a license to be a software engineer you do need a license to be most other kinds of Engineers um electrical engineers uh mechanical engineers Structural Engineers um many many kinds of of you need like to be a what is it the pl professional no PE license professional engineering license now and of course doctors have to be board certified um and ethical violations are are critical I have to graduate from an AA accredited program to be considered a librarian right librarian has yeah as an information scientist yeah now would that fly for software engineering probably not and it certainly doesn't exist for the business world and the investment world um it's basically whatever makes money and stays within the confines of the legal framework that you live in and what basically whatever you can get away with but I'm I'm just curious like I've been thinking about the idea of a prime directive for AI um where it's like what what would that prime directive be and of course the prime directive from Star Trek is you know policy of non-intervention and non-interference which that's I kind of suspect that that's where AI will end up when it's super intelligent and said like doesn't need humans anymore it's just like actually we're going to do our own thing and we're going to leave you to your own devices um I I suspect that that will be something that is within the realm of possibility in the long run um as as a very likely outcome because there is there's a a pretty broad consensus that once you have something that is agentic and super intelligent it's just not possible to control it um now of course that's getting a little bit more speculative but in the short term like what if what if we could come up with a a a you know a codified core set of ethical values that all AI ought to be trained with um I could see that going poorly and I could see it going well in certain ways um in terms of like maybe there's a you know because we we you know we have guidelines for you standards for how like buildings are built and how dams are built you know it must adhere to these certain standards pass these tests right that's what regulation are for so I suspect that we probably will have something along those lines in the long run um perhaps AI models will have an obligation towards the truth um I think that that could be a good good uh Cardinal value what other what other kind of cardinal values do you think might be included in a core Constitution or or regulatory framework yeah again that's a good question I think it also um again there's like a couple different ways you can look at it there's the things that you actually instill the AI with in order to maybe shape its intent as an interacts with people and it interacts with with our systems but then I think that also maybe we also need to look at its impact because you can do use some of the examples that you brought up of AIS that um were designed with very good intentions but maybe had not great or even like harmful or comical kind of outcomes um their impact was not what the developers intended at all so you know some of it I think it is about helping create that core Constitution that maybe moral compass for an AI but a lot of it I think is going to be unfortunately kind of trial and error as we develop different models and then test them um you know and see what kind of impact they have because again you can design something with wonderful intentions um that is more moral and ethically upright than maybe most people you know but if it isn't actually affect in the world or if it does harm um that you maybe don't see coming then it's still not still not a good AI um and so I think that one of the things kind of talking through that that you have to consider is that the AI itself maybe needs to care about the impact that it has um it needs to in a sense be aware of itself as an agent in the world and as something that can create that has an effect and it needs to care what that effect is um you know if it causes harm if it caused someone to suffer or to misunderstand that um those are all things that it needs to be aware of his possibilities and to try actively try to avoid I love it well thank you for the great talk today um where can people find you and what is your mission right now yeah um what is my mission right now that's a good question um my mission right now is um kind of like you I'm really interested in the IDE a of the meaning economy and kind of what it means to be human in age of AI and one of my projects with that is um I'm working on building a creative life for myself kind of finding meaning outside of work and away from technology and just more in terms of who I am as a human being so um my YouTube channel is very different from Dave's it's more lifestyle oriented um as I kind of explore those questions um so you can find me on YouTube at Anna's Journal and yeah think that's I think that's it it's been really great talking to you to uh you two Dave this is this has been fun excellent well I hope that uh we'll continue this trend and hopefully we'll get more guests and uh perhaps co-hosts involved I do I do think that this format the the dactic format of just like hey let's let's have two people actually just talk through a thing and have people listen I get a lot of value out of these kind kinds of conversations so I hope hope the audience does too let us know in the comments and yeah we'll look forward to seeing you guys next time have a good one",
  "duration": 74,
  "comments": []
}
